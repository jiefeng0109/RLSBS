{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本脚本用于HDCNN进行对比实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1781377  | loss_wrt: 0.17256  | loss_unl: 0.19127  | learning_rate: 0.00050\n",
      "OA: 0.7773  | AA:  0.6040  | Kappa:  0.7450  | Time: 18.3\n",
      "[100,   201] loss: 0.2639935  | loss_wrt: 0.07480  | loss_unl: 0.10359  | learning_rate: 0.00050\n",
      "OA: 0.8528  | AA:  0.7184  | Kappa:  0.8312  | Time: 16.6\n",
      "[150,   301] loss: 0.1633430  | loss_wrt: 0.08098  | loss_unl: 0.10975  | learning_rate: 0.00050\n",
      "OA: 0.8530  | AA:  0.7354  | Kappa:  0.8319  | Time: 16.5\n",
      "[200,   401] loss: 0.0817260  | loss_wrt: 0.03255  | loss_unl: 0.06644  | learning_rate: 0.00050\n",
      "OA: 0.8472  | AA:  0.7432  | Kappa:  0.8246  | Time: 16.6\n",
      "[250,   501] loss: 0.0994483  | loss_wrt: 0.03112  | loss_unl: 0.05506  | learning_rate: 0.00050\n",
      "OA: 0.8631  | AA:  0.7447  | Kappa:  0.8437  | Time: 16.5\n",
      "[300,   601] loss: 0.0639250  | loss_wrt: 0.03752  | loss_unl: 0.05882  | learning_rate: 0.00050\n",
      "OA: 0.8084  | AA:  0.7111  | Kappa:  0.7768  | Time: 16.5\n",
      "[350,   701] loss: 0.0544738  | loss_wrt: 0.02382  | loss_unl: 0.04511  | learning_rate: 0.00050\n",
      "OA: 0.8861  | AA:  0.7752  | Kappa:  0.8693  | Time: 16.6\n",
      "[400,   801] loss: 0.0567178  | loss_wrt: 0.02178  | loss_unl: 0.04029  | learning_rate: 0.00050\n",
      "OA: 0.8708  | AA:  0.7603  | Kappa:  0.8519  | Time: 16.6\n",
      "[450,   901] loss: 0.0426319  | loss_wrt: 0.01114  | loss_unl: 0.03252  | learning_rate: 0.00050\n",
      "OA: 0.8930  | AA:  0.7748  | Kappa:  0.8774  | Time: 16.6\n",
      "[500,  1001] loss: 0.0270933  | loss_wrt: 0.01366  | loss_unl: 0.02343  | learning_rate: 0.00050\n",
      "OA: 0.8998  | AA:  0.7878  | Kappa:  0.8853  | Time: 16.5\n",
      "[550,  1101] loss: 0.0962617  | loss_wrt: 0.01603  | loss_unl: 0.04872  | learning_rate: 0.00045\n",
      "OA: 0.8866  | AA:  0.7777  | Kappa:  0.8698  | Time: 16.6\n",
      "[600,  1201] loss: 0.0516613  | loss_wrt: 0.01325  | loss_unl: 0.02441  | learning_rate: 0.00045\n",
      "OA: 0.9014  | AA:  0.7961  | Kappa:  0.8872  | Time: 16.5\n",
      "[650,  1301] loss: 0.0253009  | loss_wrt: 0.01223  | loss_unl: 0.02270  | learning_rate: 0.00045\n",
      "OA: 0.8923  | AA:  0.7841  | Kappa:  0.8764  | Time: 16.6\n",
      "[700,  1401] loss: 0.0204292  | loss_wrt: 0.00580  | loss_unl: 0.01489  | learning_rate: 0.00045\n",
      "OA: 0.8997  | AA:  0.7946  | Kappa:  0.8849  | Time: 16.5\n",
      "[750,  1501] loss: 0.0138034  | loss_wrt: 0.00746  | loss_unl: 0.01479  | learning_rate: 0.00045\n",
      "OA: 0.9006  | AA:  0.7972  | Kappa:  0.8860  | Time: 16.6\n",
      "[800,  1601] loss: 0.0180947  | loss_wrt: 0.00723  | loss_unl: 0.01453  | learning_rate: 0.00045\n",
      "OA: 0.8900  | AA:  0.7793  | Kappa:  0.8737  | Time: 16.6\n",
      "[850,  1701] loss: 0.0174840  | loss_wrt: 0.00453  | loss_unl: 0.01253  | learning_rate: 0.00045\n",
      "OA: 0.9060  | AA:  0.8006  | Kappa:  0.8924  | Time: 16.5\n",
      "[900,  1801] loss: 0.0196077  | loss_wrt: 0.00993  | loss_unl: 0.01611  | learning_rate: 0.00045\n",
      "OA: 0.8914  | AA:  0.7743  | Kappa:  0.8753  | Time: 16.5\n",
      "[950,  1901] loss: 0.0295346  | loss_wrt: 0.00470  | loss_unl: 0.01029  | learning_rate: 0.00045\n",
      "OA: 0.9057  | AA:  0.7962  | Kappa:  0.8920  | Time: 16.6\n",
      "[1000,  2001] loss: 0.0081344  | loss_wrt: 0.00566  | loss_unl: 0.01165  | learning_rate: 0.00045\n",
      "OA: 0.9149  | AA:  0.8036  | Kappa:  0.9027  | Time: 16.6\n",
      "[1050,  2101] loss: 0.0195137  | loss_wrt: 0.01820  | loss_unl: 0.00778  | learning_rate: 0.00041\n",
      "OA: 0.9010  | AA:  0.7825  | Kappa:  0.8865  | Time: 16.6\n",
      "[1100,  2201] loss: 0.0090094  | loss_wrt: 0.00440  | loss_unl: 0.01043  | learning_rate: 0.00041\n",
      "OA: 0.8843  | AA:  0.7865  | Kappa:  0.8677  | Time: 16.6\n",
      "[1150,  2301] loss: 0.0188579  | loss_wrt: 0.01714  | loss_unl: 0.01181  | learning_rate: 0.00041\n",
      "OA: 0.8910  | AA:  0.7721  | Kappa:  0.8749  | Time: 16.6\n",
      "[1200,  2401] loss: 0.0112193  | loss_wrt: 0.01034  | loss_unl: 0.00772  | learning_rate: 0.00041\n",
      "OA: 0.9048  | AA:  0.7964  | Kappa:  0.8909  | Time: 16.6\n",
      "[1250,  2501] loss: 0.0098996  | loss_wrt: 0.00288  | loss_unl: 0.00939  | learning_rate: 0.00041\n",
      "OA: 0.9032  | AA:  0.7909  | Kappa:  0.8890  | Time: 16.6\n",
      "[1300,  2601] loss: 0.0901202  | loss_wrt: 0.00963  | loss_unl: 0.01518  | learning_rate: 0.00041\n",
      "OA: 0.9108  | AA:  0.7992  | Kappa:  0.8978  | Time: 16.6\n",
      "[1350,  2701] loss: 0.0232351  | loss_wrt: 0.00756  | loss_unl: 0.01094  | learning_rate: 0.00041\n",
      "OA: 0.9056  | AA:  0.7851  | Kappa:  0.8920  | Time: 16.6\n",
      "[1400,  2801] loss: 0.0419368  | loss_wrt: 0.00484  | loss_unl: 0.01128  | learning_rate: 0.00041\n",
      "OA: 0.9046  | AA:  0.8007  | Kappa:  0.8907  | Time: 16.6\n",
      "[1450,  2901] loss: 0.0069140  | loss_wrt: 0.00329  | loss_unl: 0.00789  | learning_rate: 0.00041\n",
      "OA: 0.8936  | AA:  0.7948  | Kappa:  0.8781  | Time: 16.6\n",
      "[1500,  3001] loss: 0.0183429  | loss_wrt: 0.00323  | loss_unl: 0.01656  | learning_rate: 0.00041\n",
      "OA: 0.9084  | AA:  0.8161  | Kappa:  0.8951  | Time: 16.6\n",
      "[1550,  3101] loss: 0.0052901  | loss_wrt: 0.00612  | loss_unl: 0.00524  | learning_rate: 0.00036\n",
      "OA: 0.9032  | AA:  0.7933  | Kappa:  0.8890  | Time: 16.6\n",
      "[1600,  3201] loss: 0.0043908  | loss_wrt: 0.00152  | loss_unl: 0.00485  | learning_rate: 0.00036\n",
      "OA: 0.9037  | AA:  0.7956  | Kappa:  0.8895  | Time: 16.6\n",
      "[1650,  3301] loss: 0.0237242  | loss_wrt: 0.00461  | loss_unl: 0.00617  | learning_rate: 0.00036\n",
      "OA: 0.9025  | AA:  0.7867  | Kappa:  0.8883  | Time: 16.6\n",
      "[1700,  3401] loss: 0.0066605  | loss_wrt: 0.00166  | loss_unl: 0.00541  | learning_rate: 0.00036\n",
      "OA: 0.8792  | AA:  0.7681  | Kappa:  0.8618  | Time: 16.6\n",
      "[1750,  3501] loss: 0.0042604  | loss_wrt: 0.00178  | loss_unl: 0.00483  | learning_rate: 0.00036\n",
      "OA: 0.8854  | AA:  0.7702  | Kappa:  0.8689  | Time: 16.6\n",
      "[1800,  3601] loss: 0.0146670  | loss_wrt: 0.00329  | loss_unl: 0.00638  | learning_rate: 0.00036\n",
      "OA: 0.8993  | AA:  0.7909  | Kappa:  0.8845  | Time: 16.6\n",
      "[1850,  3701] loss: 0.0049272  | loss_wrt: 0.00178  | loss_unl: 0.00594  | learning_rate: 0.00036\n",
      "OA: 0.9051  | AA:  0.7982  | Kappa:  0.8911  | Time: 16.6\n",
      "[1900,  3801] loss: 0.0037118  | loss_wrt: 0.00217  | loss_unl: 0.00458  | learning_rate: 0.00036\n",
      "OA: 0.9062  | AA:  0.7947  | Kappa:  0.8924  | Time: 16.6\n",
      "[1950,  3901] loss: 0.0042999  | loss_wrt: 0.00217  | loss_unl: 0.00521  | learning_rate: 0.00036\n",
      "OA: 0.8972  | AA:  0.7922  | Kappa:  0.8822  | Time: 16.6\n",
      "[2000,  4001] loss: 0.0062431  | loss_wrt: 0.00170  | loss_unl: 0.00463  | learning_rate: 0.00036\n",
      "OA: 0.9041  | AA:  0.8008  | Kappa:  0.8900  | Time: 16.6\n",
      "Finished Training\n",
      "model saved\n",
      "[0.         0.89126853 0.87375887 0.91542289 0.78832117 0.97741935\n",
      " 1.         1.         0.41176471 0.65859564 0.97412554 0.86904762\n",
      " 0.90804598 0.99162791 0.99085366 0.51898734]\n",
      "0.9017221584385764 0.7980774498274779 0.8872654722006545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.799\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -3.48 | loss:0.803 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -3.74 | loss:0.791 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -3.85 | loss:0.800 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -3.82 | loss:0.801 | 100 bands | 4.4s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -3.91 | loss:0.800 | 100 bands | 4.5s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.88 | loss:0.786 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.04 | loss:0.779 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.93 | loss:0.790 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.91 | loss:0.791 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.09 | loss:0.793 | 100 bands | 4.6s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.86 | loss:0.782 | 100 bands | 4.5s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -3.82 | loss:0.785 | 100 bands | 4.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -3.73 | loss:0.787 | 100 bands | 4.5s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -3.72 | loss:0.781 | 100 bands | 4.6s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -3.69 | loss:0.785 | 100 bands | 4.6s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -3.50 | loss:0.793 | 100 bands | 4.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -3.46 | loss:0.776 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.53 | loss:0.785 | 100 bands | 4.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.52 | loss:0.778 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.44 | loss:0.781 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.47 | loss:0.781 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -3.59 | loss:0.785 | 100 bands | 4.7s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -3.83 | loss:0.779 | 100 bands | 4.8s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -3.53 | loss:0.778 | 100 bands | 4.7s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -3.26 | loss:0.765 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -3.02 | loss:0.783 | 100 bands | 4.6s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -3.00 | loss:0.777 | 100 bands | 4.7s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.10 | loss:0.778 | 100 bands | 4.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -2.99 | loss:0.769 | 100 bands | 4.6s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -2.96 | loss:0.761 | 100 bands | 4.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -2.85 | loss:0.753 | 100 bands | 4.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -2.69 | loss:0.782 | 100 bands | 4.6s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -2.79 | loss:0.790 | 100 bands | 4.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -2.54 | loss:0.772 | 100 bands | 4.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -2.58 | loss:0.767 | 100 bands | 4.7s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -2.60 | loss:0.766 | 100 bands | 4.8s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -2.50 | loss:0.765 | 100 bands | 4.7s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -2.49 | loss:0.760 | 100 bands | 4.7s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -2.67 | loss:0.764 | 100 bands | 4.8s\n",
      "r_max, 0.7543090606995975\n",
      "Done\n",
      "time :187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 13:33:44.141266: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 13:33:44.144114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 13:33:44.144273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 13:33:44.580067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 13:33:44.580164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 13:33:44.580213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 13:33:44.580406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.1758401  | loss_wrt: 0.14569  | loss_unl: 0.15034  | learning_rate: 0.00100\n",
      "OA: 0.9209  | AA:  0.7646  | Kappa:  0.9093  | Time: 18.0\n",
      "[50,   201] loss: 0.1186256  | loss_wrt: 0.05307  | loss_unl: 0.06664  | learning_rate: 0.00090\n",
      "OA: 0.9512  | AA:  0.8715  | Kappa:  0.9442  | Time: 16.2\n",
      "[75,   301] loss: 0.0538994  | loss_wrt: 0.03029  | loss_unl: 0.03858  | learning_rate: 0.00081\n",
      "OA: 0.9603  | AA:  0.8835  | Kappa:  0.9546  | Time: 16.2\n",
      "[100,   401] loss: 0.0297122  | loss_wrt: 0.01926  | loss_unl: 0.02670  | learning_rate: 0.00073\n",
      "OA: 0.9676  | AA:  0.8760  | Kappa:  0.9630  | Time: 16.2\n",
      "[125,   501] loss: 0.0200981  | loss_wrt: 0.01131  | loss_unl: 0.01672  | learning_rate: 0.00066\n",
      "OA: 0.9680  | AA:  0.8905  | Kappa:  0.9634  | Time: 16.2\n",
      "[150,   601] loss: 0.0134466  | loss_wrt: 0.01058  | loss_unl: 0.01328  | learning_rate: 0.00059\n",
      "OA: 0.9657  | AA:  0.8667  | Kappa:  0.9608  | Time: 16.2\n",
      "[175,   701] loss: 0.0373018  | loss_wrt: 0.01503  | loss_unl: 0.01776  | learning_rate: 0.00053\n",
      "OA: 0.9683  | AA:  0.9004  | Kappa:  0.9638  | Time: 16.2\n",
      "[200,   801] loss: 0.0126741  | loss_wrt: 0.00705  | loss_unl: 0.00992  | learning_rate: 0.00048\n",
      "OA: 0.9708  | AA:  0.9040  | Kappa:  0.9667  | Time: 16.3\n",
      "[225,   901] loss: 0.0086703  | loss_wrt: 0.00561  | loss_unl: 0.00930  | learning_rate: 0.00043\n",
      "OA: 0.9706  | AA:  0.9051  | Kappa:  0.9665  | Time: 16.3\n",
      "[250,  1001] loss: 0.0065761  | loss_wrt: 0.00411  | loss_unl: 0.00685  | learning_rate: 0.00039\n",
      "OA: 0.9712  | AA:  0.9052  | Kappa:  0.9671  | Time: 16.3\n",
      "[275,  1101] loss: 0.0053104  | loss_wrt: 0.00351  | loss_unl: 0.00570  | learning_rate: 0.00035\n",
      "OA: 0.9711  | AA:  0.8992  | Kappa:  0.9670  | Time: 16.3\n",
      "[300,  1201] loss: 0.0044724  | loss_wrt: 0.00320  | loss_unl: 0.00428  | learning_rate: 0.00031\n",
      "OA: 0.9705  | AA:  0.9005  | Kappa:  0.9663  | Time: 16.3\n",
      "[325,  1301] loss: 0.0036908  | loss_wrt: 0.00282  | loss_unl: 0.00398  | learning_rate: 0.00028\n",
      "OA: 0.9719  | AA:  0.8951  | Kappa:  0.9679  | Time: 16.3\n",
      "[350,  1401] loss: 0.0031834  | loss_wrt: 0.00222  | loss_unl: 0.00326  | learning_rate: 0.00025\n",
      "OA: 0.9715  | AA:  0.8795  | Kappa:  0.9675  | Time: 16.2\n",
      "[375,  1501] loss: 0.0027094  | loss_wrt: 0.00200  | loss_unl: 0.00281  | learning_rate: 0.00023\n",
      "OA: 0.9716  | AA:  0.8789  | Kappa:  0.9676  | Time: 16.3\n",
      "[400,  1601] loss: 0.0023500  | loss_wrt: 0.00168  | loss_unl: 0.00218  | learning_rate: 0.00021\n",
      "OA: 0.9712  | AA:  0.8724  | Kappa:  0.9671  | Time: 16.3\n",
      "[425,  1701] loss: 0.0020840  | loss_wrt: 0.00144  | loss_unl: 0.00232  | learning_rate: 0.00019\n",
      "OA: 0.9705  | AA:  0.8764  | Kappa:  0.9663  | Time: 16.3\n",
      "[450,  1801] loss: 0.0017594  | loss_wrt: 0.00122  | loss_unl: 0.00232  | learning_rate: 0.00017\n",
      "OA: 0.9711  | AA:  0.8701  | Kappa:  0.9670  | Time: 16.3\n",
      "[475,  1901] loss: 0.0015441  | loss_wrt: 0.00101  | loss_unl: 0.00126  | learning_rate: 0.00015\n",
      "OA: 0.9718  | AA:  0.8820  | Kappa:  0.9678  | Time: 16.3\n",
      "[500,  2001] loss: 0.0013966  | loss_wrt: 0.00117  | loss_unl: 0.00112  | learning_rate: 0.00014\n",
      "OA: 0.9710  | AA:  0.8829  | Kappa:  0.9668  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.51282051 0.95881384 0.99432624 0.99502488 0.93430657 0.99516129\n",
      " 0.70833333 1.         0.52941176 0.94794189 0.99760422 0.93452381\n",
      " 0.97126437 0.99813953 0.92682927 0.72151899]\n",
      "0.9709529276693456 0.8828762811805636 0.9668483244234529\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.4404046  | loss_wrt: 0.15415  | loss_unl: 0.18413  | learning_rate: 0.00050\n",
      "OA: 0.7154  | AA:  0.5512  | Kappa:  0.6746  | Time: 55.8\n",
      "[100,   201] loss: 0.3406643  | loss_wrt: 0.11249  | loss_unl: 0.13776  | learning_rate: 0.00050\n",
      "OA: 0.7915  | AA:  0.6713  | Kappa:  0.7627  | Time: 53.9\n",
      "[150,   301] loss: 0.1958805  | loss_wrt: 0.09249  | loss_unl: 0.10507  | learning_rate: 0.00050\n",
      "OA: 0.8633  | AA:  0.8073  | Kappa:  0.8448  | Time: 53.9\n",
      "[200,   401] loss: 0.1343908  | loss_wrt: 0.08400  | loss_unl: 0.08743  | learning_rate: 0.00050\n",
      "OA: 0.8223  | AA:  0.7489  | Kappa:  0.7954  | Time: 54.0\n",
      "[250,   501] loss: 0.0735833  | loss_wrt: 0.03414  | loss_unl: 0.05371  | learning_rate: 0.00050\n",
      "OA: 0.8685  | AA:  0.8152  | Kappa:  0.8506  | Time: 54.0\n",
      "[300,   601] loss: 0.0786657  | loss_wrt: 0.03022  | loss_unl: 0.05192  | learning_rate: 0.00050\n",
      "OA: 0.8821  | AA:  0.8301  | Kappa:  0.8659  | Time: 54.8\n",
      "[350,   701] loss: 0.1332941  | loss_wrt: 0.03859  | loss_unl: 0.06378  | learning_rate: 0.00050\n",
      "OA: 0.8652  | AA:  0.8231  | Kappa:  0.8471  | Time: 55.3\n",
      "[400,   801] loss: 0.0973147  | loss_wrt: 0.03446  | loss_unl: 0.06034  | learning_rate: 0.00050\n",
      "OA: 0.8835  | AA:  0.8235  | Kappa:  0.8675  | Time: 54.1\n",
      "[450,   901] loss: 0.0594206  | loss_wrt: 0.02094  | loss_unl: 0.03891  | learning_rate: 0.00050\n",
      "OA: 0.8835  | AA:  0.8336  | Kappa:  0.8676  | Time: 53.9\n",
      "[500,  1001] loss: 0.0439135  | loss_wrt: 0.01599  | loss_unl: 0.04255  | learning_rate: 0.00050\n",
      "OA: 0.8892  | AA:  0.8266  | Kappa:  0.8739  | Time: 54.1\n",
      "[550,  1101] loss: 0.0762075  | loss_wrt: 0.01992  | loss_unl: 0.04192  | learning_rate: 0.00045\n",
      "OA: 0.8850  | AA:  0.8197  | Kappa:  0.8691  | Time: 54.1\n",
      "[600,  1201] loss: 0.0354040  | loss_wrt: 0.01711  | loss_unl: 0.02743  | learning_rate: 0.00045\n",
      "OA: 0.8902  | AA:  0.8385  | Kappa:  0.8752  | Time: 54.2\n",
      "[650,  1301] loss: 0.0474524  | loss_wrt: 0.01741  | loss_unl: 0.02949  | learning_rate: 0.00045\n",
      "OA: 0.8850  | AA:  0.8479  | Kappa:  0.8696  | Time: 54.1\n",
      "[700,  1401] loss: 0.0609324  | loss_wrt: 0.01470  | loss_unl: 0.02570  | learning_rate: 0.00045\n",
      "OA: 0.8939  | AA:  0.8484  | Kappa:  0.8793  | Time: 53.9\n",
      "[750,  1501] loss: 0.0174004  | loss_wrt: 0.00738  | loss_unl: 0.02069  | learning_rate: 0.00045\n",
      "OA: 0.9003  | AA:  0.8472  | Kappa:  0.8866  | Time: 54.0\n",
      "[800,  1601] loss: 0.0132118  | loss_wrt: 0.00490  | loss_unl: 0.01389  | learning_rate: 0.00045\n",
      "OA: 0.9003  | AA:  0.8537  | Kappa:  0.8866  | Time: 54.1\n",
      "[850,  1701] loss: 0.0179796  | loss_wrt: 0.02136  | loss_unl: 0.02859  | learning_rate: 0.00045\n",
      "OA: 0.8976  | AA:  0.8329  | Kappa:  0.8836  | Time: 54.0\n",
      "[900,  1801] loss: 0.0217037  | loss_wrt: 0.00726  | loss_unl: 0.01484  | learning_rate: 0.00045\n",
      "OA: 0.8990  | AA:  0.8484  | Kappa:  0.8851  | Time: 54.0\n",
      "[950,  1901] loss: 0.0112121  | loss_wrt: 0.00376  | loss_unl: 0.01229  | learning_rate: 0.00045\n",
      "OA: 0.8978  | AA:  0.8571  | Kappa:  0.8837  | Time: 54.1\n",
      "[1000,  2001] loss: 0.0074266  | loss_wrt: 0.00375  | loss_unl: 0.01106  | learning_rate: 0.00045\n",
      "OA: 0.8997  | AA:  0.8510  | Kappa:  0.8858  | Time: 53.9\n",
      "[1050,  2101] loss: 0.0081735  | loss_wrt: 0.00366  | loss_unl: 0.00752  | learning_rate: 0.00041\n",
      "OA: 0.9024  | AA:  0.8464  | Kappa:  0.8889  | Time: 54.0\n",
      "[1100,  2201] loss: 0.0092496  | loss_wrt: 0.00339  | loss_unl: 0.00742  | learning_rate: 0.00041\n",
      "OA: 0.8972  | AA:  0.8498  | Kappa:  0.8831  | Time: 54.1\n",
      "[1150,  2301] loss: 0.0053734  | loss_wrt: 0.00202  | loss_unl: 0.00529  | learning_rate: 0.00041\n",
      "OA: 0.8661  | AA:  0.8248  | Kappa:  0.8479  | Time: 53.9\n",
      "[1200,  2401] loss: 0.0145906  | loss_wrt: 0.00511  | loss_unl: 0.00854  | learning_rate: 0.00041\n",
      "OA: 0.8899  | AA:  0.8237  | Kappa:  0.8748  | Time: 54.0\n",
      "[1250,  2501] loss: 0.0098335  | loss_wrt: 0.00287  | loss_unl: 0.00536  | learning_rate: 0.00041\n",
      "OA: 0.9014  | AA:  0.8453  | Kappa:  0.8878  | Time: 54.0\n",
      "[1300,  2601] loss: 0.0150125  | loss_wrt: 0.00601  | loss_unl: 0.00830  | learning_rate: 0.00041\n",
      "OA: 0.8987  | AA:  0.8444  | Kappa:  0.8848  | Time: 53.9\n",
      "[1350,  2701] loss: 0.0219153  | loss_wrt: 0.01292  | loss_unl: 0.00664  | learning_rate: 0.00041\n",
      "OA: 0.8989  | AA:  0.8620  | Kappa:  0.8850  | Time: 53.9\n",
      "[1400,  2801] loss: 0.0053036  | loss_wrt: 0.00198  | loss_unl: 0.00551  | learning_rate: 0.00041\n",
      "OA: 0.8999  | AA:  0.8456  | Kappa:  0.8861  | Time: 54.1\n",
      "[1450,  2901] loss: 0.0185539  | loss_wrt: 0.00425  | loss_unl: 0.00666  | learning_rate: 0.00041\n",
      "OA: 0.8891  | AA:  0.8365  | Kappa:  0.8739  | Time: 53.9\n",
      "[1500,  3001] loss: 0.0045146  | loss_wrt: 0.00166  | loss_unl: 0.00358  | learning_rate: 0.00041\n",
      "OA: 0.8999  | AA:  0.8394  | Kappa:  0.8861  | Time: 54.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0068134  | loss_wrt: 0.00428  | loss_unl: 0.00805  | learning_rate: 0.00036\n",
      "OA: 0.8924  | AA:  0.8358  | Kappa:  0.8776  | Time: 54.1\n",
      "[1600,  3201] loss: 0.0065429  | loss_wrt: 0.00181  | loss_unl: 0.00459  | learning_rate: 0.00036\n",
      "OA: 0.8977  | AA:  0.8376  | Kappa:  0.8836  | Time: 53.9\n",
      "[1650,  3301] loss: 0.0030427  | loss_wrt: 0.00101  | loss_unl: 0.00289  | learning_rate: 0.00036\n",
      "OA: 0.8907  | AA:  0.8387  | Kappa:  0.8757  | Time: 54.0\n",
      "[1700,  3401] loss: 0.0024633  | loss_wrt: 0.00075  | loss_unl: 0.00311  | learning_rate: 0.00036\n",
      "OA: 0.9002  | AA:  0.8379  | Kappa:  0.8865  | Time: 54.1\n",
      "[1750,  3501] loss: 0.0259826  | loss_wrt: 0.00326  | loss_unl: 0.00451  | learning_rate: 0.00036\n",
      "OA: 0.8859  | AA:  0.8357  | Kappa:  0.8703  | Time: 53.9\n",
      "[1800,  3601] loss: 0.0051314  | loss_wrt: 0.00179  | loss_unl: 0.00443  | learning_rate: 0.00036\n",
      "OA: 0.8943  | AA:  0.8379  | Kappa:  0.8797  | Time: 53.9\n",
      "[1850,  3701] loss: 0.0119976  | loss_wrt: 0.00455  | loss_unl: 0.00627  | learning_rate: 0.00036\n",
      "OA: 0.8933  | AA:  0.8528  | Kappa:  0.8788  | Time: 54.1\n",
      "[1900,  3801] loss: 0.0327993  | loss_wrt: 0.00265  | loss_unl: 0.00515  | learning_rate: 0.00036\n",
      "OA: 0.8971  | AA:  0.8430  | Kappa:  0.8829  | Time: 53.9\n",
      "[1950,  3901] loss: 0.0029078  | loss_wrt: 0.00139  | loss_unl: 0.00366  | learning_rate: 0.00036\n",
      "OA: 0.8992  | AA:  0.8439  | Kappa:  0.8853  | Time: 54.0\n",
      "[2000,  4001] loss: 0.0266264  | loss_wrt: 0.00192  | loss_unl: 0.00370  | learning_rate: 0.00036\n",
      "OA: 0.8972  | AA:  0.8478  | Kappa:  0.8831  | Time: 54.1\n",
      "Finished Training\n",
      "model saved\n",
      "[0.94871795 0.79571664 0.95460993 0.88059701 0.91240876 0.95483871\n",
      " 0.         0.99261084 0.47058824 0.84261501 0.86344034 0.93650794\n",
      " 1.         0.96837209 0.99695122 0.96202532]\n",
      "0.8977037887485648 0.8424999997539402 0.8836342398828037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.711\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -4.48 | loss:0.699 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.27 | loss:0.719 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.03 | loss:0.705 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -3.92 | loss:0.724 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -3.84 | loss:0.719 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.93 | loss:0.704 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.03 | loss:0.725 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.98 | loss:0.701 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.77 | loss:0.711 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -3.62 | loss:0.695 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.68 | loss:0.702 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -3.59 | loss:0.690 | 100 bands | 4.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -3.39 | loss:0.707 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -3.59 | loss:0.696 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -3.85 | loss:0.686 | 100 bands | 4.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -3.71 | loss:0.685 | 100 bands | 4.6s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -3.42 | loss:0.696 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.33 | loss:0.696 | 100 bands | 4.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.23 | loss:0.690 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.09 | loss:0.684 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.06 | loss:0.675 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -2.98 | loss:0.679 | 100 bands | 4.6s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -2.88 | loss:0.689 | 100 bands | 4.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -2.65 | loss:0.677 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -2.63 | loss:0.690 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -2.76 | loss:0.667 | 100 bands | 4.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -2.97 | loss:0.673 | 100 bands | 4.8s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.02 | loss:0.664 | 100 bands | 4.8s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -3.28 | loss:0.657 | 100 bands | 4.9s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -3.40 | loss:0.668 | 100 bands | 4.9s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -3.34 | loss:0.669 | 100 bands | 4.8s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -3.24 | loss:0.687 | 100 bands | 4.8s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.40 | loss:0.658 | 100 bands | 4.8s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.81 | loss:0.683 | 100 bands | 5.1s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.60 | loss:0.689 | 100 bands | 4.8s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.43 | loss:0.663 | 100 bands | 4.8s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.20 | loss:0.661 | 100 bands | 4.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.23 | loss:0.681 | 100 bands | 4.9s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.07 | loss:0.653 | 100 bands | 4.9s\n",
      "r_max, 0.6637532938384538\n",
      "Done\n",
      "time :189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 14:18:44.231458: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 14:18:44.234296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 14:18:44.234454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 14:18:44.672370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 14:18:44.672466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 14:18:44.672515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 14:18:44.672711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2570320  | loss_wrt: 0.14039  | loss_unl: 0.15717  | learning_rate: 0.00100\n",
      "OA: 0.9040  | AA:  0.7305  | Kappa:  0.8906  | Time: 16.3\n",
      "[50,   201] loss: 0.1375447  | loss_wrt: 0.05600  | loss_unl: 0.06935  | learning_rate: 0.00090\n",
      "OA: 0.9631  | AA:  0.8849  | Kappa:  0.9580  | Time: 16.2\n",
      "[75,   301] loss: 0.0547207  | loss_wrt: 0.03409  | loss_unl: 0.03624  | learning_rate: 0.00081\n",
      "OA: 0.9662  | AA:  0.8893  | Kappa:  0.9615  | Time: 16.3\n",
      "[100,   401] loss: 0.0771940  | loss_wrt: 0.05165  | loss_unl: 0.05420  | learning_rate: 0.00073\n",
      "OA: 0.9661  | AA:  0.9044  | Kappa:  0.9614  | Time: 16.3\n",
      "[125,   501] loss: 0.0400935  | loss_wrt: 0.02162  | loss_unl: 0.02838  | learning_rate: 0.00066\n",
      "OA: 0.9724  | AA:  0.8963  | Kappa:  0.9686  | Time: 16.3\n",
      "[150,   601] loss: 0.0233543  | loss_wrt: 0.01432  | loss_unl: 0.02061  | learning_rate: 0.00059\n",
      "OA: 0.9739  | AA:  0.9047  | Kappa:  0.9703  | Time: 16.3\n",
      "[175,   701] loss: 0.0161623  | loss_wrt: 0.01105  | loss_unl: 0.01664  | learning_rate: 0.00053\n",
      "OA: 0.9743  | AA:  0.8928  | Kappa:  0.9707  | Time: 16.3\n",
      "[200,   801] loss: 0.0118360  | loss_wrt: 0.00725  | loss_unl: 0.01149  | learning_rate: 0.00048\n",
      "OA: 0.9763  | AA:  0.8975  | Kappa:  0.9730  | Time: 16.3\n",
      "[225,   901] loss: 0.0091929  | loss_wrt: 0.00593  | loss_unl: 0.00891  | learning_rate: 0.00043\n",
      "OA: 0.9765  | AA:  0.8997  | Kappa:  0.9732  | Time: 16.3\n",
      "[250,  1001] loss: 0.0071733  | loss_wrt: 0.00481  | loss_unl: 0.00781  | learning_rate: 0.00039\n",
      "OA: 0.9769  | AA:  0.9037  | Kappa:  0.9737  | Time: 16.3\n",
      "[275,  1101] loss: 0.0059067  | loss_wrt: 0.00338  | loss_unl: 0.00771  | learning_rate: 0.00035\n",
      "OA: 0.9770  | AA:  0.9047  | Kappa:  0.9738  | Time: 16.3\n",
      "[300,  1201] loss: 0.0047454  | loss_wrt: 0.00331  | loss_unl: 0.00453  | learning_rate: 0.00031\n",
      "OA: 0.9765  | AA:  0.8960  | Kappa:  0.9732  | Time: 16.3\n",
      "[325,  1301] loss: 0.0039062  | loss_wrt: 0.00237  | loss_unl: 0.00406  | learning_rate: 0.00028\n",
      "OA: 0.9759  | AA:  0.8942  | Kappa:  0.9725  | Time: 16.2\n",
      "[350,  1401] loss: 0.0032286  | loss_wrt: 0.00199  | loss_unl: 0.00326  | learning_rate: 0.00025\n",
      "OA: 0.9765  | AA:  0.9026  | Kappa:  0.9732  | Time: 16.3\n",
      "[375,  1501] loss: 0.0027513  | loss_wrt: 0.00174  | loss_unl: 0.00251  | learning_rate: 0.00023\n",
      "OA: 0.9762  | AA:  0.8995  | Kappa:  0.9729  | Time: 16.2\n",
      "[400,  1601] loss: 0.0022661  | loss_wrt: 0.00159  | loss_unl: 0.00222  | learning_rate: 0.00021\n",
      "OA: 0.9760  | AA:  0.8994  | Kappa:  0.9726  | Time: 16.2\n",
      "[425,  1701] loss: 0.0020024  | loss_wrt: 0.00129  | loss_unl: 0.00179  | learning_rate: 0.00019\n",
      "OA: 0.9770  | AA:  0.8999  | Kappa:  0.9738  | Time: 16.2\n",
      "[450,  1801] loss: 0.0017639  | loss_wrt: 0.00129  | loss_unl: 0.00147  | learning_rate: 0.00017\n",
      "OA: 0.9761  | AA:  0.8993  | Kappa:  0.9728  | Time: 16.3\n",
      "[475,  1901] loss: 0.0015855  | loss_wrt: 0.00112  | loss_unl: 0.00149  | learning_rate: 0.00015\n",
      "OA: 0.9749  | AA:  0.9001  | Kappa:  0.9713  | Time: 16.4\n",
      "[500,  2001] loss: 0.0013712  | loss_wrt: 0.00103  | loss_unl: 0.00141  | learning_rate: 0.00014\n",
      "OA: 0.9757  | AA:  0.9037  | Kappa:  0.9722  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.8974359  0.94481054 0.99432624 1.         0.97323601 0.95967742\n",
      " 0.5        0.99753695 0.47058824 0.97820823 0.99233349 0.98611111\n",
      " 1.         0.98046512 1.         0.78481013]\n",
      "0.9756601607347876 0.9037212107432695 0.9722463098964063\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1917631  | loss_wrt: 0.13544  | loss_unl: 0.16870  | learning_rate: 0.00050\n",
      "OA: 0.7759  | AA:  0.5840  | Kappa:  0.7411  | Time: 55.2\n",
      "[100,   201] loss: 0.2675004  | loss_wrt: 0.09431  | loss_unl: 0.12784  | learning_rate: 0.00050\n",
      "OA: 0.8509  | AA:  0.7198  | Kappa:  0.8293  | Time: 53.4\n",
      "[150,   301] loss: 0.1532357  | loss_wrt: 0.05926  | loss_unl: 0.09010  | learning_rate: 0.00050\n",
      "OA: 0.8499  | AA:  0.7153  | Kappa:  0.8279  | Time: 53.4\n",
      "[200,   401] loss: 0.0865923  | loss_wrt: 0.05065  | loss_unl: 0.07600  | learning_rate: 0.00050\n",
      "OA: 0.8746  | AA:  0.7514  | Kappa:  0.8566  | Time: 53.5\n",
      "[250,   501] loss: 0.0705192  | loss_wrt: 0.03910  | loss_unl: 0.06109  | learning_rate: 0.00050\n",
      "OA: 0.8543  | AA:  0.7277  | Kappa:  0.8334  | Time: 53.4\n",
      "[300,   601] loss: 0.1651233  | loss_wrt: 0.04276  | loss_unl: 0.05967  | learning_rate: 0.00050\n",
      "OA: 0.8575  | AA:  0.7180  | Kappa:  0.8369  | Time: 53.4\n",
      "[350,   701] loss: 0.0985570  | loss_wrt: 0.03900  | loss_unl: 0.05820  | learning_rate: 0.00050\n",
      "OA: 0.8423  | AA:  0.7162  | Kappa:  0.8184  | Time: 53.5\n",
      "[400,   801] loss: 0.0604669  | loss_wrt: 0.02049  | loss_unl: 0.03325  | learning_rate: 0.00050\n",
      "OA: 0.8899  | AA:  0.7664  | Kappa:  0.8741  | Time: 53.4\n",
      "[450,   901] loss: 0.1309372  | loss_wrt: 0.04749  | loss_unl: 0.05293  | learning_rate: 0.00050\n",
      "OA: 0.8652  | AA:  0.7510  | Kappa:  0.8458  | Time: 53.4\n",
      "[500,  1001] loss: 0.0409238  | loss_wrt: 0.01617  | loss_unl: 0.02909  | learning_rate: 0.00050\n",
      "OA: 0.8881  | AA:  0.7640  | Kappa:  0.8719  | Time: 53.5\n",
      "[550,  1101] loss: 0.0819421  | loss_wrt: 0.02689  | loss_unl: 0.03642  | learning_rate: 0.00045\n",
      "OA: 0.8860  | AA:  0.7646  | Kappa:  0.8696  | Time: 53.3\n",
      "[600,  1201] loss: 0.0557498  | loss_wrt: 0.01652  | loss_unl: 0.03059  | learning_rate: 0.00045\n",
      "OA: 0.8960  | AA:  0.7732  | Kappa:  0.8812  | Time: 53.4\n",
      "[650,  1301] loss: 0.0523556  | loss_wrt: 0.01566  | loss_unl: 0.04217  | learning_rate: 0.00045\n",
      "OA: 0.8792  | AA:  0.7628  | Kappa:  0.8616  | Time: 53.5\n",
      "[700,  1401] loss: 0.0537604  | loss_wrt: 0.01231  | loss_unl: 0.02710  | learning_rate: 0.00045\n",
      "OA: 0.8939  | AA:  0.7801  | Kappa:  0.8789  | Time: 53.4\n",
      "[750,  1501] loss: 0.0281897  | loss_wrt: 0.01219  | loss_unl: 0.02116  | learning_rate: 0.00045\n",
      "OA: 0.8955  | AA:  0.7787  | Kappa:  0.8804  | Time: 53.4\n",
      "[800,  1601] loss: 0.1205199  | loss_wrt: 0.01815  | loss_unl: 0.02638  | learning_rate: 0.00045\n",
      "OA: 0.8887  | AA:  0.7785  | Kappa:  0.8729  | Time: 53.5\n",
      "[850,  1701] loss: 0.0489413  | loss_wrt: 0.01902  | loss_unl: 0.03014  | learning_rate: 0.00045\n",
      "OA: 0.8755  | AA:  0.7330  | Kappa:  0.8573  | Time: 53.4\n",
      "[900,  1801] loss: 0.0581075  | loss_wrt: 0.01354  | loss_unl: 0.02165  | learning_rate: 0.00045\n",
      "OA: 0.8944  | AA:  0.7677  | Kappa:  0.8792  | Time: 53.4\n",
      "[950,  1901] loss: 0.0213738  | loss_wrt: 0.00810  | loss_unl: 0.01757  | learning_rate: 0.00045\n",
      "OA: 0.9020  | AA:  0.7793  | Kappa:  0.8880  | Time: 53.5\n",
      "[1000,  2001] loss: 0.0166995  | loss_wrt: 0.00618  | loss_unl: 0.01653  | learning_rate: 0.00045\n",
      "OA: 0.8899  | AA:  0.7659  | Kappa:  0.8739  | Time: 53.4\n",
      "[1050,  2101] loss: 0.0134342  | loss_wrt: 0.00626  | loss_unl: 0.01504  | learning_rate: 0.00041\n",
      "OA: 0.8962  | AA:  0.7711  | Kappa:  0.8816  | Time: 53.4\n",
      "[1100,  2201] loss: 0.0298021  | loss_wrt: 0.00715  | loss_unl: 0.01734  | learning_rate: 0.00041\n",
      "OA: 0.8956  | AA:  0.7792  | Kappa:  0.8807  | Time: 53.5\n",
      "[1150,  2301] loss: 0.0644177  | loss_wrt: 0.00830  | loss_unl: 0.01474  | learning_rate: 0.00041\n",
      "OA: 0.9022  | AA:  0.7791  | Kappa:  0.8883  | Time: 53.4\n",
      "[1200,  2401] loss: 0.0281272  | loss_wrt: 0.00824  | loss_unl: 0.01357  | learning_rate: 0.00041\n",
      "OA: 0.9003  | AA:  0.7729  | Kappa:  0.8862  | Time: 53.4\n",
      "[1250,  2501] loss: 0.0191347  | loss_wrt: 0.00885  | loss_unl: 0.01449  | learning_rate: 0.00041\n",
      "OA: 0.9026  | AA:  0.7733  | Kappa:  0.8888  | Time: 53.5\n",
      "[1300,  2601] loss: 0.0096649  | loss_wrt: 0.00380  | loss_unl: 0.01060  | learning_rate: 0.00041\n",
      "OA: 0.8918  | AA:  0.7617  | Kappa:  0.8766  | Time: 53.4\n",
      "[1350,  2701] loss: 0.0424510  | loss_wrt: 0.00924  | loss_unl: 0.01602  | learning_rate: 0.00041\n",
      "OA: 0.8917  | AA:  0.7765  | Kappa:  0.8766  | Time: 53.4\n",
      "[1400,  2801] loss: 0.0454252  | loss_wrt: 0.00633  | loss_unl: 0.01157  | learning_rate: 0.00041\n",
      "OA: 0.8947  | AA:  0.7738  | Kappa:  0.8798  | Time: 53.5\n",
      "[1450,  2901] loss: 0.0090286  | loss_wrt: 0.00306  | loss_unl: 0.00996  | learning_rate: 0.00041\n",
      "OA: 0.9052  | AA:  0.7875  | Kappa:  0.8918  | Time: 53.4\n",
      "[1500,  3001] loss: 0.0093380  | loss_wrt: 0.00465  | loss_unl: 0.00906  | learning_rate: 0.00041\n",
      "OA: 0.9061  | AA:  0.7842  | Kappa:  0.8928  | Time: 53.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0244335  | loss_wrt: 0.00559  | loss_unl: 0.01220  | learning_rate: 0.00036\n",
      "OA: 0.8992  | AA:  0.7829  | Kappa:  0.8851  | Time: 53.5\n",
      "[1600,  3201] loss: 0.0078135  | loss_wrt: 0.00252  | loss_unl: 0.00709  | learning_rate: 0.00036\n",
      "OA: 0.9093  | AA:  0.7893  | Kappa:  0.8965  | Time: 53.4\n",
      "[1650,  3301] loss: 0.0096059  | loss_wrt: 0.00342  | loss_unl: 0.00829  | learning_rate: 0.00036\n",
      "OA: 0.9048  | AA:  0.7853  | Kappa:  0.8915  | Time: 53.4\n",
      "[1700,  3401] loss: 0.0089981  | loss_wrt: 0.00253  | loss_unl: 0.00606  | learning_rate: 0.00036\n",
      "OA: 0.9021  | AA:  0.7763  | Kappa:  0.8882  | Time: 53.5\n",
      "[1750,  3501] loss: 0.0054325  | loss_wrt: 0.00246  | loss_unl: 0.00753  | learning_rate: 0.00036\n",
      "OA: 0.9060  | AA:  0.7788  | Kappa:  0.8927  | Time: 53.4\n",
      "[1800,  3601] loss: 0.0083193  | loss_wrt: 0.00293  | loss_unl: 0.00622  | learning_rate: 0.00036\n",
      "OA: 0.9062  | AA:  0.7863  | Kappa:  0.8929  | Time: 53.4\n",
      "[1850,  3701] loss: 0.0042216  | loss_wrt: 0.00157  | loss_unl: 0.00489  | learning_rate: 0.00036\n",
      "OA: 0.9106  | AA:  0.7888  | Kappa:  0.8980  | Time: 53.5\n",
      "[1900,  3801] loss: 0.0033470  | loss_wrt: 0.00130  | loss_unl: 0.00488  | learning_rate: 0.00036\n",
      "OA: 0.9101  | AA:  0.7887  | Kappa:  0.8975  | Time: 53.4\n",
      "[1950,  3901] loss: 0.0028451  | loss_wrt: 0.00156  | loss_unl: 0.00329  | learning_rate: 0.00036\n",
      "OA: 0.9093  | AA:  0.7823  | Kappa:  0.8965  | Time: 53.4\n",
      "[2000,  4001] loss: 0.0071991  | loss_wrt: 0.00284  | loss_unl: 0.00412  | learning_rate: 0.00036\n",
      "OA: 0.9092  | AA:  0.7907  | Kappa:  0.8964  | Time: 53.5\n",
      "Finished Training\n",
      "model saved\n",
      "[0.82051282 0.95963756 0.89219858 0.94527363 0.79318735 0.73225806\n",
      " 0.         1.         0.         0.82687651 0.98418783 0.8531746\n",
      " 0.99425287 0.92093023 0.91768293 0.98734177]\n",
      "0.9082663605051665 0.7892196724472302 0.8953164919594939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.460\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -4.70 | loss:0.463 | 100 bands | 7.7s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.45 | loss:0.463 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.35 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.24 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.24 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -4.13 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.19 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -4.22 | loss:0.462 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -4.45 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.53 | loss:0.459 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -4.73 | loss:0.456 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -4.88 | loss:0.458 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -4.81 | loss:0.457 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -4.55 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -4.28 | loss:0.460 | 100 bands | 4.4s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -4.20 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -4.16 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -4.21 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -4.09 | loss:0.458 | 100 bands | 4.5s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -4.30 | loss:0.450 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -4.71 | loss:0.454 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -4.56 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -4.46 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -4.44 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -4.52 | loss:0.459 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -4.28 | loss:0.451 | 100 bands | 4.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -4.16 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -4.22 | loss:0.458 | 100 bands | 4.5s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -4.24 | loss:0.451 | 100 bands | 4.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -4.14 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -4.10 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -4.06 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.98 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.96 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.98 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.95 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.90 | loss:0.457 | 100 bands | 4.5s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.93 | loss:0.448 | 100 bands | 4.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.99 | loss:0.451 | 100 bands | 4.5s\n",
      "r_max, 0.45428441115655005\n",
      "Done\n",
      "time :183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 15:03:17.387670: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 15:03:17.390544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 15:03:17.390703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 15:03:17.828616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 15:03:17.828717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 15:03:17.828766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 15:03:17.828967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.4864410  | loss_wrt: 0.15359  | loss_unl: 0.16904  | learning_rate: 0.00100\n",
      "OA: 0.8374  | AA:  0.6505  | Kappa:  0.8142  | Time: 16.3\n",
      "[50,   201] loss: 0.1760864  | loss_wrt: 0.06211  | loss_unl: 0.09196  | learning_rate: 0.00090\n",
      "OA: 0.9416  | AA:  0.9177  | Kappa:  0.9333  | Time: 16.2\n",
      "[75,   301] loss: 0.0759699  | loss_wrt: 0.03715  | loss_unl: 0.04585  | learning_rate: 0.00081\n",
      "OA: 0.9491  | AA:  0.9240  | Kappa:  0.9419  | Time: 16.3\n",
      "[100,   401] loss: 0.0375249  | loss_wrt: 0.02066  | loss_unl: 0.03030  | learning_rate: 0.00073\n",
      "OA: 0.9548  | AA:  0.9224  | Kappa:  0.9484  | Time: 16.3\n",
      "[125,   501] loss: 0.0235572  | loss_wrt: 0.01350  | loss_unl: 0.02100  | learning_rate: 0.00066\n",
      "OA: 0.9569  | AA:  0.9120  | Kappa:  0.9508  | Time: 16.3\n",
      "[150,   601] loss: 0.0166968  | loss_wrt: 0.00955  | loss_unl: 0.01676  | learning_rate: 0.00059\n",
      "OA: 0.9574  | AA:  0.9102  | Kappa:  0.9514  | Time: 16.3\n",
      "[175,   701] loss: 0.0122977  | loss_wrt: 0.00825  | loss_unl: 0.01323  | learning_rate: 0.00053\n",
      "OA: 0.9569  | AA:  0.9123  | Kappa:  0.9508  | Time: 16.3\n",
      "[200,   801] loss: 0.0095392  | loss_wrt: 0.00688  | loss_unl: 0.01053  | learning_rate: 0.00048\n",
      "OA: 0.9544  | AA:  0.9170  | Kappa:  0.9480  | Time: 16.3\n",
      "[225,   901] loss: 0.0072909  | loss_wrt: 0.00570  | loss_unl: 0.00762  | learning_rate: 0.00043\n",
      "OA: 0.9541  | AA:  0.9100  | Kappa:  0.9475  | Time: 16.3\n",
      "[250,  1001] loss: 0.0058843  | loss_wrt: 0.00380  | loss_unl: 0.00656  | learning_rate: 0.00039\n",
      "OA: 0.9541  | AA:  0.9075  | Kappa:  0.9476  | Time: 16.3\n",
      "[275,  1101] loss: 0.0050476  | loss_wrt: 0.00335  | loss_unl: 0.00447  | learning_rate: 0.00035\n",
      "OA: 0.9543  | AA:  0.9079  | Kappa:  0.9478  | Time: 16.2\n",
      "[300,  1201] loss: 0.0039040  | loss_wrt: 0.00355  | loss_unl: 0.00432  | learning_rate: 0.00031\n",
      "OA: 0.9546  | AA:  0.9190  | Kappa:  0.9482  | Time: 16.3\n",
      "[325,  1301] loss: 0.0033180  | loss_wrt: 0.00226  | loss_unl: 0.00284  | learning_rate: 0.00028\n",
      "OA: 0.9543  | AA:  0.9112  | Kappa:  0.9478  | Time: 16.3\n",
      "[350,  1401] loss: 0.0027722  | loss_wrt: 0.00205  | loss_unl: 0.00306  | learning_rate: 0.00025\n",
      "OA: 0.9526  | AA:  0.9090  | Kappa:  0.9459  | Time: 16.3\n",
      "[375,  1501] loss: 0.0023601  | loss_wrt: 0.00200  | loss_unl: 0.00220  | learning_rate: 0.00023\n",
      "OA: 0.9540  | AA:  0.9125  | Kappa:  0.9474  | Time: 16.3\n",
      "[400,  1601] loss: 0.0020622  | loss_wrt: 0.00135  | loss_unl: 0.00179  | learning_rate: 0.00021\n",
      "OA: 0.9529  | AA:  0.9119  | Kappa:  0.9463  | Time: 16.2\n",
      "[425,  1701] loss: 0.0018265  | loss_wrt: 0.00136  | loss_unl: 0.00144  | learning_rate: 0.00019\n",
      "OA: 0.9528  | AA:  0.9114  | Kappa:  0.9461  | Time: 16.2\n",
      "[450,  1801] loss: 0.0015914  | loss_wrt: 0.00123  | loss_unl: 0.00146  | learning_rate: 0.00017\n",
      "OA: 0.9528  | AA:  0.9105  | Kappa:  0.9461  | Time: 16.3\n",
      "[475,  1901] loss: 0.0014172  | loss_wrt: 0.00101  | loss_unl: 0.00168  | learning_rate: 0.00015\n",
      "OA: 0.9526  | AA:  0.9016  | Kappa:  0.9459  | Time: 16.2\n",
      "[500,  2001] loss: 0.0012295  | loss_wrt: 0.00097  | loss_unl: 0.00162  | learning_rate: 0.00014\n",
      "OA: 0.9533  | AA:  0.9113  | Kappa:  0.9466  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.74358974 0.94069193 0.96170213 0.88557214 0.88077859 0.99032258\n",
      " 1.         1.         0.58823529 0.83656174 0.98466699 0.95039683\n",
      " 0.99425287 1.         0.97560976 0.84810127]\n",
      "0.9532721010332951 0.9112801157476251 0.9466490504203097\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2853792  | loss_wrt: 0.17193  | loss_unl: 0.20553  | learning_rate: 0.00050\n",
      "OA: 0.7904  | AA:  0.6486  | Kappa:  0.7599  | Time: 55.4\n",
      "[100,   201] loss: 0.1924490  | loss_wrt: 0.07347  | loss_unl: 0.10895  | learning_rate: 0.00050\n",
      "OA: 0.8390  | AA:  0.7291  | Kappa:  0.8158  | Time: 53.7\n",
      "[150,   301] loss: 0.1456209  | loss_wrt: 0.06913  | loss_unl: 0.09194  | learning_rate: 0.00050\n",
      "OA: 0.8455  | AA:  0.7368  | Kappa:  0.8235  | Time: 53.6\n",
      "[200,   401] loss: 0.1377339  | loss_wrt: 0.06725  | loss_unl: 0.08704  | learning_rate: 0.00050\n",
      "OA: 0.8276  | AA:  0.7673  | Kappa:  0.8037  | Time: 53.7\n",
      "[250,   501] loss: 0.1164521  | loss_wrt: 0.03445  | loss_unl: 0.06862  | learning_rate: 0.00050\n",
      "OA: 0.8680  | AA:  0.7732  | Kappa:  0.8492  | Time: 53.6\n",
      "[300,   601] loss: 0.0619776  | loss_wrt: 0.03452  | loss_unl: 0.05868  | learning_rate: 0.00050\n",
      "OA: 0.8520  | AA:  0.7682  | Kappa:  0.8310  | Time: 53.6\n",
      "[350,   701] loss: 0.0681299  | loss_wrt: 0.02624  | loss_unl: 0.05499  | learning_rate: 0.00050\n",
      "OA: 0.8753  | AA:  0.7940  | Kappa:  0.8574  | Time: 53.7\n",
      "[400,   801] loss: 0.0458639  | loss_wrt: 0.03072  | loss_unl: 0.04785  | learning_rate: 0.00050\n",
      "OA: 0.8496  | AA:  0.8031  | Kappa:  0.8288  | Time: 53.6\n",
      "[450,   901] loss: 0.0681555  | loss_wrt: 0.02108  | loss_unl: 0.03377  | learning_rate: 0.00050\n",
      "OA: 0.8534  | AA:  0.7597  | Kappa:  0.8325  | Time: 53.6\n",
      "[500,  1001] loss: 0.1575837  | loss_wrt: 0.02625  | loss_unl: 0.03832  | learning_rate: 0.00050\n",
      "OA: 0.8629  | AA:  0.7689  | Kappa:  0.8429  | Time: 53.7\n",
      "[550,  1101] loss: 0.1068339  | loss_wrt: 0.02526  | loss_unl: 0.03511  | learning_rate: 0.00045\n",
      "OA: 0.8592  | AA:  0.7852  | Kappa:  0.8388  | Time: 53.6\n",
      "[600,  1201] loss: 0.0293533  | loss_wrt: 0.01325  | loss_unl: 0.02747  | learning_rate: 0.00045\n",
      "OA: 0.8759  | AA:  0.8006  | Kappa:  0.8583  | Time: 53.7\n",
      "[650,  1301] loss: 0.0480678  | loss_wrt: 0.01645  | loss_unl: 0.03161  | learning_rate: 0.00045\n",
      "OA: 0.8834  | AA:  0.7939  | Kappa:  0.8668  | Time: 53.8\n",
      "[700,  1401] loss: 0.0650332  | loss_wrt: 0.02458  | loss_unl: 0.02846  | learning_rate: 0.00045\n",
      "OA: 0.8848  | AA:  0.8174  | Kappa:  0.8682  | Time: 53.7\n",
      "[750,  1501] loss: 0.0184030  | loss_wrt: 0.00943  | loss_unl: 0.02032  | learning_rate: 0.00045\n",
      "OA: 0.8607  | AA:  0.7871  | Kappa:  0.8410  | Time: 53.6\n",
      "[800,  1601] loss: 0.0517670  | loss_wrt: 0.01462  | loss_unl: 0.02474  | learning_rate: 0.00045\n",
      "OA: 0.8754  | AA:  0.8101  | Kappa:  0.8578  | Time: 53.7\n",
      "[850,  1701] loss: 0.0381887  | loss_wrt: 0.01327  | loss_unl: 0.02399  | learning_rate: 0.00045\n",
      "OA: 0.8620  | AA:  0.8133  | Kappa:  0.8426  | Time: 53.6\n",
      "[900,  1801] loss: 0.0347055  | loss_wrt: 0.00697  | loss_unl: 0.01624  | learning_rate: 0.00045\n",
      "OA: 0.8869  | AA:  0.8095  | Kappa:  0.8706  | Time: 53.6\n",
      "[950,  1901] loss: 0.0342197  | loss_wrt: 0.00991  | loss_unl: 0.01757  | learning_rate: 0.00045\n",
      "OA: 0.8610  | AA:  0.7698  | Kappa:  0.8406  | Time: 53.8\n",
      "[1000,  2001] loss: 0.0209305  | loss_wrt: 0.00800  | loss_unl: 0.01700  | learning_rate: 0.00045\n",
      "OA: 0.8875  | AA:  0.7991  | Kappa:  0.8714  | Time: 53.6\n",
      "[1050,  2101] loss: 0.0377537  | loss_wrt: 0.00847  | loss_unl: 0.01569  | learning_rate: 0.00041\n",
      "OA: 0.8615  | AA:  0.8025  | Kappa:  0.8416  | Time: 53.6\n",
      "[1100,  2201] loss: 0.0256303  | loss_wrt: 0.00533  | loss_unl: 0.01364  | learning_rate: 0.00041\n",
      "OA: 0.8828  | AA:  0.8091  | Kappa:  0.8659  | Time: 53.8\n",
      "[1150,  2301] loss: 0.0269203  | loss_wrt: 0.00942  | loss_unl: 0.01543  | learning_rate: 0.00041\n",
      "OA: 0.8693  | AA:  0.8069  | Kappa:  0.8507  | Time: 53.6\n",
      "[1200,  2401] loss: 0.0175685  | loss_wrt: 0.00453  | loss_unl: 0.01188  | learning_rate: 0.00041\n",
      "OA: 0.8890  | AA:  0.8137  | Kappa:  0.8730  | Time: 53.6\n",
      "[1250,  2501] loss: 0.0527843  | loss_wrt: 0.00712  | loss_unl: 0.01196  | learning_rate: 0.00041\n",
      "OA: 0.8808  | AA:  0.8125  | Kappa:  0.8637  | Time: 53.7\n",
      "[1300,  2601] loss: 0.0266448  | loss_wrt: 0.00569  | loss_unl: 0.01077  | learning_rate: 0.00041\n",
      "OA: 0.8797  | AA:  0.7962  | Kappa:  0.8623  | Time: 53.6\n",
      "[1350,  2701] loss: 0.0086234  | loss_wrt: 0.00514  | loss_unl: 0.01021  | learning_rate: 0.00041\n",
      "OA: 0.8923  | AA:  0.8187  | Kappa:  0.8769  | Time: 53.6\n",
      "[1400,  2801] loss: 0.0060626  | loss_wrt: 0.00216  | loss_unl: 0.00704  | learning_rate: 0.00041\n",
      "OA: 0.8906  | AA:  0.8142  | Kappa:  0.8749  | Time: 53.7\n",
      "[1450,  2901] loss: 0.0069281  | loss_wrt: 0.00508  | loss_unl: 0.00847  | learning_rate: 0.00041\n",
      "OA: 0.8916  | AA:  0.8159  | Kappa:  0.8761  | Time: 53.6\n",
      "[1500,  3001] loss: 0.0094257  | loss_wrt: 0.00488  | loss_unl: 0.00739  | learning_rate: 0.00041\n",
      "OA: 0.8945  | AA:  0.8215  | Kappa:  0.8793  | Time: 53.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0085190  | loss_wrt: 0.00568  | loss_unl: 0.01088  | learning_rate: 0.00036\n",
      "OA: 0.8939  | AA:  0.8374  | Kappa:  0.8787  | Time: 53.7\n",
      "[1600,  3201] loss: 0.0048606  | loss_wrt: 0.00157  | loss_unl: 0.00507  | learning_rate: 0.00036\n",
      "OA: 0.8990  | AA:  0.8318  | Kappa:  0.8845  | Time: 53.6\n",
      "[1650,  3301] loss: 0.0163893  | loss_wrt: 0.00522  | loss_unl: 0.01076  | learning_rate: 0.00036\n",
      "OA: 0.8886  | AA:  0.8139  | Kappa:  0.8727  | Time: 53.6\n",
      "[1700,  3401] loss: 0.0213414  | loss_wrt: 0.00456  | loss_unl: 0.01972  | learning_rate: 0.00036\n",
      "OA: 0.8861  | AA:  0.8162  | Kappa:  0.8697  | Time: 53.7\n",
      "[1750,  3501] loss: 0.0053960  | loss_wrt: 0.00174  | loss_unl: 0.00567  | learning_rate: 0.00036\n",
      "OA: 0.8976  | AA:  0.8377  | Kappa:  0.8829  | Time: 53.6\n",
      "[1800,  3601] loss: 0.0149034  | loss_wrt: 0.00469  | loss_unl: 0.00742  | learning_rate: 0.00036\n",
      "OA: 0.8842  | AA:  0.8246  | Kappa:  0.8674  | Time: 53.6\n",
      "[1850,  3701] loss: 0.0056343  | loss_wrt: 0.00206  | loss_unl: 0.00525  | learning_rate: 0.00036\n",
      "OA: 0.8980  | AA:  0.8261  | Kappa:  0.8834  | Time: 53.7\n",
      "[1900,  3801] loss: 0.0139945  | loss_wrt: 0.00258  | loss_unl: 0.00525  | learning_rate: 0.00036\n",
      "OA: 0.8904  | AA:  0.8027  | Kappa:  0.8746  | Time: 53.7\n",
      "[1950,  3901] loss: 0.0063273  | loss_wrt: 0.00377  | loss_unl: 0.00676  | learning_rate: 0.00036\n",
      "OA: 0.8875  | AA:  0.8171  | Kappa:  0.8714  | Time: 53.6\n",
      "[2000,  4001] loss: 0.0133240  | loss_wrt: 0.00305  | loss_unl: 0.00643  | learning_rate: 0.00036\n",
      "OA: 0.8853  | AA:  0.8221  | Kappa:  0.8690  | Time: 53.8\n",
      "Finished Training\n",
      "model saved\n",
      "[0.8974359  0.86985173 0.87375887 0.8358209  0.85158151 0.89032258\n",
      " 0.625      1.         0.41176471 0.81355932 0.97077144 0.88888889\n",
      " 0.99425287 0.88930233 0.82012195 0.72151899]\n",
      "0.896211251435132 0.8346219983724329 0.8813913603373869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.504\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -5.43 | loss:0.499 | 100 bands | 7.7s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.77 | loss:0.494 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.47 | loss:0.503 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.43 | loss:0.507 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.21 | loss:0.500 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -4.20 | loss:0.505 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.41 | loss:0.483 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -4.32 | loss:0.497 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -4.27 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.15 | loss:0.498 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -4.14 | loss:0.483 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -4.19 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -4.18 | loss:0.475 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -4.28 | loss:0.491 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -4.91 | loss:0.481 | 100 bands | 4.9s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -4.78 | loss:0.486 | 100 bands | 4.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -4.28 | loss:0.487 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.91 | loss:0.500 | 100 bands | 4.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.85 | loss:0.479 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.77 | loss:0.493 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.96 | loss:0.486 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -3.86 | loss:0.485 | 100 bands | 4.6s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -3.88 | loss:0.494 | 100 bands | 4.6s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -3.71 | loss:0.486 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -3.50 | loss:0.488 | 100 bands | 4.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -3.46 | loss:0.489 | 100 bands | 4.6s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -3.74 | loss:0.480 | 100 bands | 4.7s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.68 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -3.57 | loss:0.477 | 100 bands | 4.6s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -3.53 | loss:0.482 | 100 bands | 4.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -3.38 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -3.45 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.34 | loss:0.488 | 100 bands | 4.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.31 | loss:0.480 | 100 bands | 4.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.35 | loss:0.493 | 100 bands | 4.6s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.39 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.18 | loss:0.487 | 100 bands | 4.5s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.15 | loss:0.484 | 100 bands | 4.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.12 | loss:0.489 | 100 bands | 4.6s\n",
      "r_max, 0.478000927138055\n",
      "Done\n",
      "time :186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 15:47:53.718484: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 15:47:53.721242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 15:47:53.721411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 15:47:54.157680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 15:47:54.157782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 15:47:54.157830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 15:47:54.158025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2776748  | loss_wrt: 0.12684  | loss_unl: 0.13855  | learning_rate: 0.00100\n",
      "OA: 0.8901  | AA:  0.6997  | Kappa:  0.8748  | Time: 16.3\n",
      "[50,   201] loss: 0.1355112  | loss_wrt: 0.05757  | loss_unl: 0.06442  | learning_rate: 0.00090\n",
      "OA: 0.9336  | AA:  0.8445  | Kappa:  0.9243  | Time: 16.2\n",
      "[75,   301] loss: 0.0564804  | loss_wrt: 0.02897  | loss_unl: 0.04288  | learning_rate: 0.00081\n",
      "OA: 0.9433  | AA:  0.8905  | Kappa:  0.9354  | Time: 16.2\n",
      "[100,   401] loss: 0.0366606  | loss_wrt: 0.02531  | loss_unl: 0.02809  | learning_rate: 0.00073\n",
      "OA: 0.9524  | AA:  0.8708  | Kappa:  0.9457  | Time: 16.2\n",
      "[125,   501] loss: 0.0226583  | loss_wrt: 0.01355  | loss_unl: 0.01875  | learning_rate: 0.00066\n",
      "OA: 0.9538  | AA:  0.8749  | Kappa:  0.9473  | Time: 16.2\n",
      "[150,   601] loss: 0.0208054  | loss_wrt: 0.03490  | loss_unl: 0.03567  | learning_rate: 0.00059\n",
      "OA: 0.8503  | AA:  0.7759  | Kappa:  0.8299  | Time: 16.2\n",
      "[175,   701] loss: 0.0810117  | loss_wrt: 0.02780  | loss_unl: 0.02724  | learning_rate: 0.00053\n",
      "OA: 0.9561  | AA:  0.8710  | Kappa:  0.9500  | Time: 16.3\n",
      "[200,   801] loss: 0.0243573  | loss_wrt: 0.01369  | loss_unl: 0.02174  | learning_rate: 0.00048\n",
      "OA: 0.9588  | AA:  0.8815  | Kappa:  0.9530  | Time: 16.3\n",
      "[225,   901] loss: 0.0163429  | loss_wrt: 0.00988  | loss_unl: 0.01602  | learning_rate: 0.00043\n",
      "OA: 0.9598  | AA:  0.8903  | Kappa:  0.9542  | Time: 16.2\n",
      "[250,  1001] loss: 0.0121407  | loss_wrt: 0.00768  | loss_unl: 0.01261  | learning_rate: 0.00039\n",
      "OA: 0.9608  | AA:  0.8837  | Kappa:  0.9553  | Time: 16.2\n",
      "[275,  1101] loss: 0.0097751  | loss_wrt: 0.00600  | loss_unl: 0.00932  | learning_rate: 0.00035\n",
      "OA: 0.9615  | AA:  0.8864  | Kappa:  0.9561  | Time: 16.2\n",
      "[300,  1201] loss: 0.0077660  | loss_wrt: 0.00486  | loss_unl: 0.00655  | learning_rate: 0.00031\n",
      "OA: 0.9583  | AA:  0.8814  | Kappa:  0.9524  | Time: 16.3\n",
      "[325,  1301] loss: 0.0064340  | loss_wrt: 0.00454  | loss_unl: 0.00698  | learning_rate: 0.00028\n",
      "OA: 0.9621  | AA:  0.8938  | Kappa:  0.9568  | Time: 16.2\n",
      "[350,  1401] loss: 0.0054213  | loss_wrt: 0.00394  | loss_unl: 0.00538  | learning_rate: 0.00025\n",
      "OA: 0.9606  | AA:  0.8877  | Kappa:  0.9551  | Time: 16.3\n",
      "[375,  1501] loss: 0.0046990  | loss_wrt: 0.00340  | loss_unl: 0.00514  | learning_rate: 0.00023\n",
      "OA: 0.9606  | AA:  0.8917  | Kappa:  0.9551  | Time: 16.3\n",
      "[400,  1601] loss: 0.0038520  | loss_wrt: 0.00291  | loss_unl: 0.00406  | learning_rate: 0.00021\n",
      "OA: 0.9603  | AA:  0.8815  | Kappa:  0.9547  | Time: 16.2\n",
      "[425,  1701] loss: 0.0032216  | loss_wrt: 0.00243  | loss_unl: 0.00362  | learning_rate: 0.00019\n",
      "OA: 0.9597  | AA:  0.8863  | Kappa:  0.9540  | Time: 16.3\n",
      "[450,  1801] loss: 0.0028760  | loss_wrt: 0.00223  | loss_unl: 0.00232  | learning_rate: 0.00017\n",
      "OA: 0.9596  | AA:  0.8864  | Kappa:  0.9539  | Time: 16.2\n",
      "[475,  1901] loss: 0.0025496  | loss_wrt: 0.00164  | loss_unl: 0.00195  | learning_rate: 0.00015\n",
      "OA: 0.9592  | AA:  0.8852  | Kappa:  0.9535  | Time: 16.3\n",
      "[500,  2001] loss: 0.0023067  | loss_wrt: 0.00227  | loss_unl: 0.00234  | learning_rate: 0.00014\n",
      "OA: 0.9594  | AA:  0.8856  | Kappa:  0.9536  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.94871795 0.98682043 0.97021277 0.94527363 0.84671533 0.96612903\n",
      " 0.41666667 1.         0.47058824 0.92009685 0.98370867 0.87103175\n",
      " 0.98850575 0.98139535 1.         0.87341772]\n",
      "0.9593570608495982 0.8855800078805549 0.9536150620002557\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.3541974  | loss_wrt: 0.17189  | loss_unl: 0.20531  | learning_rate: 0.00050\n",
      "OA: 0.7945  | AA:  0.6775  | Kappa:  0.7634  | Time: 55.4\n",
      "[100,   201] loss: 0.3659129  | loss_wrt: 0.10558  | loss_unl: 0.13984  | learning_rate: 0.00050\n",
      "OA: 0.8662  | AA:  0.7962  | Kappa:  0.8469  | Time: 53.5\n",
      "[150,   301] loss: 0.1500101  | loss_wrt: 0.07727  | loss_unl: 0.08742  | learning_rate: 0.00050\n",
      "OA: 0.8832  | AA:  0.8533  | Kappa:  0.8667  | Time: 53.5\n",
      "[200,   401] loss: 0.1017924  | loss_wrt: 0.06175  | loss_unl: 0.08416  | learning_rate: 0.00050\n",
      "OA: 0.8883  | AA:  0.8649  | Kappa:  0.8726  | Time: 53.7\n",
      "[250,   501] loss: 0.0960220  | loss_wrt: 0.03547  | loss_unl: 0.05832  | learning_rate: 0.00050\n",
      "OA: 0.9003  | AA:  0.8854  | Kappa:  0.8863  | Time: 53.5\n",
      "[300,   601] loss: 0.0781412  | loss_wrt: 0.04012  | loss_unl: 0.05607  | learning_rate: 0.00050\n",
      "OA: 0.9160  | AA:  0.8960  | Kappa:  0.9042  | Time: 53.5\n",
      "[350,   701] loss: 0.0527326  | loss_wrt: 0.03670  | loss_unl: 0.05039  | learning_rate: 0.00050\n",
      "OA: 0.8815  | AA:  0.8715  | Kappa:  0.8647  | Time: 53.7\n",
      "[400,   801] loss: 0.0373839  | loss_wrt: 0.01217  | loss_unl: 0.02763  | learning_rate: 0.00050\n",
      "OA: 0.9055  | AA:  0.8951  | Kappa:  0.8924  | Time: 53.5\n",
      "[450,   901] loss: 0.0194215  | loss_wrt: 0.00741  | loss_unl: 0.02271  | learning_rate: 0.00050\n",
      "OA: 0.9204  | AA:  0.9029  | Kappa:  0.9094  | Time: 53.5\n",
      "[500,  1001] loss: 0.0902882  | loss_wrt: 0.02216  | loss_unl: 0.03610  | learning_rate: 0.00050\n",
      "OA: 0.9086  | AA:  0.8883  | Kappa:  0.8957  | Time: 53.7\n",
      "[550,  1101] loss: 0.0315833  | loss_wrt: 0.01293  | loss_unl: 0.02789  | learning_rate: 0.00045\n",
      "OA: 0.9162  | AA:  0.9045  | Kappa:  0.9045  | Time: 53.6\n",
      "[600,  1201] loss: 0.0377559  | loss_wrt: 0.01227  | loss_unl: 0.02044  | learning_rate: 0.00045\n",
      "OA: 0.9209  | AA:  0.9115  | Kappa:  0.9099  | Time: 53.6\n",
      "[650,  1301] loss: 0.0576896  | loss_wrt: 0.01624  | loss_unl: 0.02894  | learning_rate: 0.00045\n",
      "OA: 0.9085  | AA:  0.8925  | Kappa:  0.8958  | Time: 53.7\n",
      "[700,  1401] loss: 0.0628503  | loss_wrt: 0.01385  | loss_unl: 0.02246  | learning_rate: 0.00045\n",
      "OA: 0.9153  | AA:  0.8909  | Kappa:  0.9033  | Time: 53.6\n",
      "[750,  1501] loss: 0.0240247  | loss_wrt: 0.03402  | loss_unl: 0.02033  | learning_rate: 0.00045\n",
      "OA: 0.9224  | AA:  0.9115  | Kappa:  0.9117  | Time: 53.5\n",
      "[800,  1601] loss: 0.0599994  | loss_wrt: 0.01439  | loss_unl: 0.02202  | learning_rate: 0.00045\n",
      "OA: 0.9127  | AA:  0.9052  | Kappa:  0.9007  | Time: 53.7\n",
      "[850,  1701] loss: 0.0767349  | loss_wrt: 0.01242  | loss_unl: 0.01927  | learning_rate: 0.00045\n",
      "OA: 0.9165  | AA:  0.9045  | Kappa:  0.9049  | Time: 53.5\n",
      "[900,  1801] loss: 0.0442299  | loss_wrt: 0.00901  | loss_unl: 0.01631  | learning_rate: 0.00045\n",
      "OA: 0.9186  | AA:  0.9152  | Kappa:  0.9074  | Time: 53.6\n",
      "[950,  1901] loss: 0.0828713  | loss_wrt: 0.01512  | loss_unl: 0.02504  | learning_rate: 0.00045\n",
      "OA: 0.9080  | AA:  0.8907  | Kappa:  0.8952  | Time: 53.7\n",
      "[1000,  2001] loss: 0.0166090  | loss_wrt: 0.00804  | loss_unl: 0.01552  | learning_rate: 0.00045\n",
      "OA: 0.9263  | AA:  0.9205  | Kappa:  0.9162  | Time: 53.6\n",
      "[1050,  2101] loss: 0.0258019  | loss_wrt: 0.01403  | loss_unl: 0.01831  | learning_rate: 0.00041\n",
      "OA: 0.9219  | AA:  0.9184  | Kappa:  0.9110  | Time: 53.5\n",
      "[1100,  2201] loss: 0.0199626  | loss_wrt: 0.00981  | loss_unl: 0.01841  | learning_rate: 0.00041\n",
      "OA: 0.9064  | AA:  0.8924  | Kappa:  0.8932  | Time: 53.7\n",
      "[1150,  2301] loss: 0.0532269  | loss_wrt: 0.00892  | loss_unl: 0.01287  | learning_rate: 0.00041\n",
      "OA: 0.9264  | AA:  0.9157  | Kappa:  0.9162  | Time: 53.6\n",
      "[1200,  2401] loss: 0.0102552  | loss_wrt: 0.00363  | loss_unl: 0.01283  | learning_rate: 0.00041\n",
      "OA: 0.9278  | AA:  0.9221  | Kappa:  0.9179  | Time: 53.6\n",
      "[1250,  2501] loss: 0.0101146  | loss_wrt: 0.00359  | loss_unl: 0.00843  | learning_rate: 0.00041\n",
      "OA: 0.9272  | AA:  0.9201  | Kappa:  0.9172  | Time: 53.7\n",
      "[1300,  2601] loss: 0.0114859  | loss_wrt: 0.00735  | loss_unl: 0.01370  | learning_rate: 0.00041\n",
      "OA: 0.9216  | AA:  0.9186  | Kappa:  0.9108  | Time: 53.6\n",
      "[1350,  2701] loss: 0.0273970  | loss_wrt: 0.00991  | loss_unl: 0.01457  | learning_rate: 0.00041\n",
      "OA: 0.9175  | AA:  0.9098  | Kappa:  0.9061  | Time: 53.6\n",
      "[1400,  2801] loss: 0.0331125  | loss_wrt: 0.01018  | loss_unl: 0.01791  | learning_rate: 0.00041\n",
      "OA: 0.9157  | AA:  0.9009  | Kappa:  0.9042  | Time: 53.6\n",
      "[1450,  2901] loss: 0.0111460  | loss_wrt: 0.00538  | loss_unl: 0.00982  | learning_rate: 0.00041\n",
      "OA: 0.9247  | AA:  0.9177  | Kappa:  0.9143  | Time: 53.5\n",
      "[1500,  3001] loss: 0.0148780  | loss_wrt: 0.00580  | loss_unl: 0.01092  | learning_rate: 0.00041\n",
      "OA: 0.9268  | AA:  0.9106  | Kappa:  0.9166  | Time: 53.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0107689  | loss_wrt: 0.00313  | loss_unl: 0.00687  | learning_rate: 0.00036\n",
      "OA: 0.9258  | AA:  0.9126  | Kappa:  0.9156  | Time: 53.5\n",
      "[1600,  3201] loss: 0.0073513  | loss_wrt: 0.00360  | loss_unl: 0.00748  | learning_rate: 0.00036\n",
      "OA: 0.9256  | AA:  0.9214  | Kappa:  0.9153  | Time: 53.4\n",
      "[1650,  3301] loss: 0.0394516  | loss_wrt: 0.00484  | loss_unl: 0.00953  | learning_rate: 0.00036\n",
      "OA: 0.9094  | AA:  0.9071  | Kappa:  0.8969  | Time: 53.4\n",
      "[1700,  3401] loss: 0.0112667  | loss_wrt: 0.00419  | loss_unl: 0.00680  | learning_rate: 0.00036\n",
      "OA: 0.9247  | AA:  0.9163  | Kappa:  0.9144  | Time: 53.6\n",
      "[1750,  3501] loss: 0.0069565  | loss_wrt: 0.00258  | loss_unl: 0.00802  | learning_rate: 0.00036\n",
      "OA: 0.9256  | AA:  0.9176  | Kappa:  0.9154  | Time: 53.4\n",
      "[1800,  3601] loss: 0.0074929  | loss_wrt: 0.00522  | loss_unl: 0.01046  | learning_rate: 0.00036\n",
      "OA: 0.9286  | AA:  0.9255  | Kappa:  0.9186  | Time: 53.4\n",
      "[1850,  3701] loss: 0.0560631  | loss_wrt: 0.00492  | loss_unl: 0.00985  | learning_rate: 0.00036\n",
      "OA: 0.9212  | AA:  0.9072  | Kappa:  0.9104  | Time: 53.6\n",
      "[1900,  3801] loss: 0.0163607  | loss_wrt: 0.00433  | loss_unl: 0.00974  | learning_rate: 0.00036\n",
      "OA: 0.9269  | AA:  0.9217  | Kappa:  0.9169  | Time: 53.4\n",
      "[1950,  3901] loss: 0.0189617  | loss_wrt: 0.00559  | loss_unl: 0.00807  | learning_rate: 0.00036\n",
      "OA: 0.9092  | AA:  0.8973  | Kappa:  0.8964  | Time: 54.2\n",
      "[2000,  4001] loss: 0.0059086  | loss_wrt: 0.00203  | loss_unl: 0.00622  | learning_rate: 0.00036\n",
      "OA: 0.9249  | AA:  0.9239  | Kappa:  0.9146  | Time: 53.7\n",
      "Finished Training\n",
      "model saved\n",
      "[0.92307692 0.95963756 0.85531915 0.89054726 0.8540146  0.97419355\n",
      " 1.         0.99507389 1.         0.92251816 0.9281265  0.93650794\n",
      " 0.99425287 0.9172093  0.91768293 0.62025316]\n",
      "0.9257175660160735 0.9180258623112929 0.9155041592014832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.405\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -5.43 | loss:0.405 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.93 | loss:0.414 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.44 | loss:0.394 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.24 | loss:0.402 | 100 bands | 4.4s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.03 | loss:0.402 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.74 | loss:0.384 | 100 bands | 4.4s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -3.44 | loss:0.384 | 100 bands | 4.4s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.31 | loss:0.375 | 100 bands | 4.4s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.09 | loss:0.372 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -3.03 | loss:0.377 | 100 bands | 4.6s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.10 | loss:0.392 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -2.97 | loss:0.376 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -2.83 | loss:0.388 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -2.99 | loss:0.349 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -2.94 | loss:0.366 | 100 bands | 4.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -2.96 | loss:0.355 | 100 bands | 4.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -2.96 | loss:0.360 | 100 bands | 4.8s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -2.92 | loss:0.380 | 100 bands | 4.7s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -2.61 | loss:0.365 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -2.45 | loss:0.368 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -2.45 | loss:0.350 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -2.50 | loss:0.358 | 100 bands | 4.7s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -2.27 | loss:0.353 | 100 bands | 4.7s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -2.31 | loss:0.347 | 100 bands | 4.8s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -2.29 | loss:0.366 | 100 bands | 4.8s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -1.99 | loss:0.358 | 100 bands | 4.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -1.76 | loss:0.344 | 100 bands | 4.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -1.61 | loss:0.360 | 100 bands | 4.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -1.69 | loss:0.340 | 100 bands | 4.8s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -1.56 | loss:0.340 | 100 bands | 4.7s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -1.85 | loss:0.357 | 100 bands | 4.9s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -1.68 | loss:0.351 | 100 bands | 4.8s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -1.87 | loss:0.326 | 100 bands | 4.9s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -2.03 | loss:0.337 | 100 bands | 4.9s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -2.19 | loss:0.352 | 100 bands | 5.0s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -1.99 | loss:0.363 | 100 bands | 4.9s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -1.81 | loss:0.354 | 100 bands | 4.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -1.64 | loss:0.363 | 100 bands | 4.8s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -1.22 | loss:0.346 | 100 bands | 4.7s\n",
      "r_max, 0.33915774204797344\n",
      "Done\n",
      "time :189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 16:32:29.329708: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 16:32:29.332579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 16:32:29.332740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 16:32:29.768135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 16:32:29.768236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 16:32:29.768284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 16:32:29.768484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2855594  | loss_wrt: 0.12753  | loss_unl: 0.14679  | learning_rate: 0.00100\n",
      "OA: 0.8936  | AA:  0.7352  | Kappa:  0.8789  | Time: 16.5\n",
      "[50,   201] loss: 0.1455527  | loss_wrt: 0.06401  | loss_unl: 0.07100  | learning_rate: 0.00090\n",
      "OA: 0.9490  | AA:  0.9047  | Kappa:  0.9420  | Time: 16.3\n",
      "[75,   301] loss: 0.0584793  | loss_wrt: 0.02752  | loss_unl: 0.03716  | learning_rate: 0.00081\n",
      "OA: 0.9620  | AA:  0.9236  | Kappa:  0.9567  | Time: 16.3\n",
      "[100,   401] loss: 0.0316908  | loss_wrt: 0.01855  | loss_unl: 0.02689  | learning_rate: 0.00073\n",
      "OA: 0.9641  | AA:  0.9179  | Kappa:  0.9591  | Time: 16.3\n",
      "[125,   501] loss: 0.0389101  | loss_wrt: 0.04151  | loss_unl: 0.05079  | learning_rate: 0.00066\n",
      "OA: 0.9549  | AA:  0.9088  | Kappa:  0.9486  | Time: 16.3\n",
      "[150,   601] loss: 0.0325327  | loss_wrt: 0.01353  | loss_unl: 0.01986  | learning_rate: 0.00059\n",
      "OA: 0.9680  | AA:  0.9267  | Kappa:  0.9635  | Time: 16.3\n",
      "[175,   701] loss: 0.0152836  | loss_wrt: 0.00821  | loss_unl: 0.01484  | learning_rate: 0.00053\n",
      "OA: 0.9692  | AA:  0.9292  | Kappa:  0.9649  | Time: 16.3\n",
      "[200,   801] loss: 0.0110958  | loss_wrt: 0.00718  | loss_unl: 0.01159  | learning_rate: 0.00048\n",
      "OA: 0.9696  | AA:  0.9210  | Kappa:  0.9653  | Time: 16.3\n",
      "[225,   901] loss: 0.0088529  | loss_wrt: 0.00724  | loss_unl: 0.00900  | learning_rate: 0.00043\n",
      "OA: 0.9680  | AA:  0.9256  | Kappa:  0.9635  | Time: 16.3\n",
      "[250,  1001] loss: 0.0199029  | loss_wrt: 0.03669  | loss_unl: 0.03991  | learning_rate: 0.00039\n",
      "OA: 0.9386  | AA:  0.8267  | Kappa:  0.9300  | Time: 16.3\n",
      "[275,  1101] loss: 0.0209499  | loss_wrt: 0.00940  | loss_unl: 0.01181  | learning_rate: 0.00035\n",
      "OA: 0.9692  | AA:  0.9246  | Kappa:  0.9650  | Time: 16.3\n",
      "[300,  1201] loss: 0.0089704  | loss_wrt: 0.00535  | loss_unl: 0.00858  | learning_rate: 0.00031\n",
      "OA: 0.9701  | AA:  0.9264  | Kappa:  0.9660  | Time: 16.3\n",
      "[325,  1301] loss: 0.0065131  | loss_wrt: 0.00402  | loss_unl: 0.00688  | learning_rate: 0.00028\n",
      "OA: 0.9710  | AA:  0.9279  | Kappa:  0.9669  | Time: 16.3\n",
      "[350,  1401] loss: 0.0054270  | loss_wrt: 0.00314  | loss_unl: 0.00547  | learning_rate: 0.00025\n",
      "OA: 0.9713  | AA:  0.9277  | Kappa:  0.9673  | Time: 16.3\n",
      "[375,  1501] loss: 0.0045749  | loss_wrt: 0.00281  | loss_unl: 0.00471  | learning_rate: 0.00023\n",
      "OA: 0.9707  | AA:  0.9278  | Kappa:  0.9667  | Time: 16.3\n",
      "[400,  1601] loss: 0.0040305  | loss_wrt: 0.00248  | loss_unl: 0.00453  | learning_rate: 0.00021\n",
      "OA: 0.9708  | AA:  0.9206  | Kappa:  0.9668  | Time: 16.5\n",
      "[425,  1701] loss: 0.0034006  | loss_wrt: 0.00254  | loss_unl: 0.00371  | learning_rate: 0.00019\n",
      "OA: 0.9710  | AA:  0.9271  | Kappa:  0.9669  | Time: 16.6\n",
      "[450,  1801] loss: 0.0030532  | loss_wrt: 0.00207  | loss_unl: 0.00239  | learning_rate: 0.00017\n",
      "OA: 0.9712  | AA:  0.9238  | Kappa:  0.9672  | Time: 16.4\n",
      "[475,  1901] loss: 0.0027185  | loss_wrt: 0.00197  | loss_unl: 0.00309  | learning_rate: 0.00015\n",
      "OA: 0.9715  | AA:  0.9214  | Kappa:  0.9676  | Time: 16.3\n",
      "[500,  2001] loss: 0.0024456  | loss_wrt: 0.00157  | loss_unl: 0.00238  | learning_rate: 0.00014\n",
      "OA: 0.9715  | AA:  0.9237  | Kappa:  0.9676  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.94871795 0.99588138 0.95602837 0.93034826 0.87347932 0.97741935\n",
      " 1.         0.97783251 0.64705882 0.97941889 0.97700048 1.\n",
      " 0.98850575 0.99162791 0.99085366 0.5443038 ]\n",
      "0.9715269804822043 0.9236547778097066 0.9675632522437665\n",
      "(21025, 2)\n"
     ]
    }
   ],
   "source": [
    "#count results\n",
    "data_name = \"Indian_pines\"\n",
    "###################################\n",
    "from evaluate_ss import RET\n",
    "results =[]\n",
    "for i in range(5):\n",
    "    !python get_prefile_ss.py --data_name \"Indian_pines\" --pt 0.05 --pv 0.10\n",
    "    !python train_evalnet_ss_v2.py --data_name \"Indian_pines\" \n",
    "    !python A3C_main.py --data_name \"Indian_pines\" --num_band_selection 100 --eval_net_path \"./checkpoint/Indian_pines.t7\" -- out_put_path \"./output/Indian_pines\"\n",
    "    model = RET(data_name)\n",
    "    results.append(model.results)\n",
    "import numpy as np\n",
    "results = np.array(results)\n",
    "avarage = results.mean(axis=0)*100\n",
    "std = results.std(axis=0)*100\n",
    "avg = [\"%.1f±%.1f\"%(avarage[i],std[i])for i in range(avarage.shape[0])]\n",
    "import xlwt\n",
    "import time\n",
    "#创建一个Workbook对象，相当于创建了一个Excel文件\n",
    "book=xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "sheet = book.add_sheet(data_name, cell_overwrite_ok=True)\n",
    "clo_0 = [\"OA\",\"AA\",\"Kappa\"]+list(range(16))\n",
    "row_o = [data_name]+list(range(5))+[\"avg\"]\n",
    "for i in range(len(row_o)):\n",
    "    sheet.write(0, i,row_o[i])\n",
    "for j in range(len(clo_0)):\n",
    "    sheet.write(j+1, 0,clo_0[j])\n",
    "for i in range(len(results)):\n",
    "    for j in range(len(results[0])):\n",
    "        sheet.write(j+1, i+1,results[i][j])\n",
    "for j in range(len(results[0])):\n",
    "    sheet.write(j+1,6,avg[j])\n",
    "book.save(data_name+\"_BSRL_\"+avg[0]+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164624\n",
      "1646\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################################\n",
    "from evaluate_ss import RET\n",
    "results =[]\n",
    "for i in range(5):\n",
    "    !python get_prefile_ss.py --data_name \"PaviaU\" --pt 0.03 --pv 0.06\n",
    "    !python train_evalnet_ss_v2.py --data_name \"PaviaU\" \n",
    "    !python A3C_main.py --data_name \"PaviaU\" --num_band_selection 60 --eval_net_path \"./checkpoint/PaviaU.t7\" -- out_put_path \"./output/PaviaU\"\n",
    "    model = RET(data_name)\n",
    "    results.append(model.results)\n",
    "import numpy as np\n",
    "results = np.array(results)\n",
    "avarage = results.mean(axis=0)*100\n",
    "std = results.std(axis=0)*100\n",
    "avg = [\"%.1f±%.1f\"%(avarage[i],std[i])for i in range(avarage.shape[0])]\n",
    "import xlwt\n",
    "import time\n",
    "#创建一个Workbook对象，相当于创建了一个Excel文件\n",
    "book=xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "sheet = book.add_sheet(data_name, cell_overwrite_ok=True)\n",
    "clo_0 = [\"OA\",\"AA\",\"Kappa\"]+list(range(16))\n",
    "row_o = [data_name]+list(range(5))+[\"avg\"]\n",
    "for i in range(len(row_o)):\n",
    "    sheet.write(0, i,row_o[i])\n",
    "for j in range(len(clo_0)):\n",
    "    sheet.write(j+1, 0,clo_0[j])\n",
    "for i in range(len(results)):\n",
    "    for j in range(len(results[0])):\n",
    "        sheet.write(j+1, i+1,results[i][j])\n",
    "for j in range(len(results[0])):\n",
    "    sheet.write(j+1,6,avg[j])\n",
    "book.save(data_name+\"_BSRL_\"+avg[0]+'.xls')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649816\n",
      "6498\n",
      "Finished!\n",
      "751\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1032195  | loss_wrt: 0.14021  | loss_unl: 0.17470  | learning_rate: 0.00050\n",
      "OA: 0.7632  | AA:  0.7607  | Kappa:  0.7437  | Time: 18.4\n",
      "[100,   201] loss: 0.4032870  | loss_wrt: 0.12155  | loss_unl: 0.13892  | learning_rate: 0.00050\n",
      "OA: 0.8561  | AA:  0.8577  | Kappa:  0.8444  | Time: 16.6\n",
      "[150,   301] loss: 0.3059242  | loss_wrt: 0.12404  | loss_unl: 0.11742  | learning_rate: 0.00050\n",
      "OA: 0.8872  | AA:  0.8925  | Kappa:  0.8780  | Time: 16.5\n",
      "[200,   401] loss: 0.1735783  | loss_wrt: 0.05804  | loss_unl: 0.08327  | learning_rate: 0.00050\n",
      "OA: 0.8951  | AA:  0.8979  | Kappa:  0.8866  | Time: 16.5\n",
      "[250,   501] loss: 0.1265102  | loss_wrt: 0.04675  | loss_unl: 0.07297  | learning_rate: 0.00050\n",
      "OA: 0.9151  | AA:  0.9181  | Kappa:  0.9082  | Time: 16.5\n",
      "[300,   601] loss: 0.0977050  | loss_wrt: 0.04736  | loss_unl: 0.07072  | learning_rate: 0.00050\n",
      "OA: 0.8960  | AA:  0.9009  | Kappa:  0.8875  | Time: 16.5\n",
      "[350,   701] loss: 0.1315399  | loss_wrt: 0.04509  | loss_unl: 0.06660  | learning_rate: 0.00050\n",
      "OA: 0.8786  | AA:  0.8819  | Kappa:  0.8687  | Time: 16.5\n",
      "[400,   801] loss: 0.0763724  | loss_wrt: 0.02798  | loss_unl: 0.05039  | learning_rate: 0.00050\n",
      "OA: 0.9054  | AA:  0.9118  | Kappa:  0.8977  | Time: 16.5\n",
      "[450,   901] loss: 0.0919127  | loss_wrt: 0.02938  | loss_unl: 0.04101  | learning_rate: 0.00050\n",
      "OA: 0.8997  | AA:  0.9055  | Kappa:  0.8916  | Time: 16.6\n",
      "[500,  1001] loss: 0.0664182  | loss_wrt: 0.02237  | loss_unl: 0.03757  | learning_rate: 0.00050\n",
      "OA: 0.8983  | AA:  0.9054  | Kappa:  0.8901  | Time: 16.6\n",
      "[550,  1101] loss: 0.0872739  | loss_wrt: 0.01998  | loss_unl: 0.04531  | learning_rate: 0.00045\n",
      "OA: 0.9072  | AA:  0.9099  | Kappa:  0.8996  | Time: 16.5\n",
      "[600,  1201] loss: 0.0605245  | loss_wrt: 0.02475  | loss_unl: 0.03422  | learning_rate: 0.00045\n",
      "OA: 0.8988  | AA:  0.9007  | Kappa:  0.8905  | Time: 16.5\n",
      "[650,  1301] loss: 0.0786853  | loss_wrt: 0.01570  | loss_unl: 0.02703  | learning_rate: 0.00045\n",
      "OA: 0.9114  | AA:  0.9154  | Kappa:  0.9042  | Time: 16.5\n",
      "[700,  1401] loss: 0.0373201  | loss_wrt: 0.01283  | loss_unl: 0.02668  | learning_rate: 0.00045\n",
      "OA: 0.9119  | AA:  0.9152  | Kappa:  0.9047  | Time: 16.5\n",
      "[750,  1501] loss: 0.0745814  | loss_wrt: 0.02382  | loss_unl: 0.02997  | learning_rate: 0.00045\n",
      "OA: 0.8918  | AA:  0.8946  | Kappa:  0.8830  | Time: 16.6\n",
      "[800,  1601] loss: 0.0512106  | loss_wrt: 0.01387  | loss_unl: 0.02885  | learning_rate: 0.00045\n",
      "OA: 0.9125  | AA:  0.9141  | Kappa:  0.9054  | Time: 16.5\n",
      "[850,  1701] loss: 0.0203484  | loss_wrt: 0.00948  | loss_unl: 0.01846  | learning_rate: 0.00045\n",
      "OA: 0.9153  | AA:  0.9184  | Kappa:  0.9084  | Time: 16.6\n",
      "[900,  1801] loss: 0.0382857  | loss_wrt: 0.01626  | loss_unl: 0.02603  | learning_rate: 0.00045\n",
      "OA: 0.8976  | AA:  0.9054  | Kappa:  0.8893  | Time: 16.7\n",
      "[950,  1901] loss: 0.0360533  | loss_wrt: 0.00910  | loss_unl: 0.02099  | learning_rate: 0.00045\n",
      "OA: 0.9104  | AA:  0.9137  | Kappa:  0.9031  | Time: 16.7\n",
      "[1000,  2001] loss: 0.0498009  | loss_wrt: 0.01311  | loss_unl: 0.01825  | learning_rate: 0.00045\n",
      "OA: 0.9019  | AA:  0.9073  | Kappa:  0.8939  | Time: 17.2\n",
      "[1050,  2101] loss: 0.0547770  | loss_wrt: 0.01236  | loss_unl: 0.01981  | learning_rate: 0.00041\n",
      "OA: 0.9010  | AA:  0.9039  | Kappa:  0.8930  | Time: 16.7\n",
      "[1100,  2201] loss: 0.0257973  | loss_wrt: 0.01102  | loss_unl: 0.01903  | learning_rate: 0.00041\n",
      "OA: 0.8946  | AA:  0.9012  | Kappa:  0.8861  | Time: 16.7\n",
      "[1150,  2301] loss: 0.0220803  | loss_wrt: 0.01010  | loss_unl: 0.01625  | learning_rate: 0.00041\n",
      "OA: 0.9112  | AA:  0.9158  | Kappa:  0.9040  | Time: 16.8\n",
      "[1200,  2401] loss: 0.0353391  | loss_wrt: 0.01087  | loss_unl: 0.01386  | learning_rate: 0.00041\n",
      "OA: 0.8985  | AA:  0.9019  | Kappa:  0.8903  | Time: 16.9\n",
      "[1250,  2501] loss: 0.0124135  | loss_wrt: 0.00643  | loss_unl: 0.01146  | learning_rate: 0.00041\n",
      "OA: 0.9227  | AA:  0.9262  | Kappa:  0.9164  | Time: 17.1\n",
      "[1300,  2601] loss: 0.0176136  | loss_wrt: 0.00716  | loss_unl: 0.01205  | learning_rate: 0.00041\n",
      "OA: 0.9130  | AA:  0.9145  | Kappa:  0.9059  | Time: 17.0\n",
      "[1350,  2701] loss: 0.0338957  | loss_wrt: 0.00808  | loss_unl: 0.01376  | learning_rate: 0.00041\n",
      "OA: 0.9080  | AA:  0.9125  | Kappa:  0.9005  | Time: 17.0\n",
      "[1400,  2801] loss: 0.0415991  | loss_wrt: 0.01092  | loss_unl: 0.01448  | learning_rate: 0.00041\n",
      "OA: 0.9001  | AA:  0.9042  | Kappa:  0.8920  | Time: 16.9\n",
      "[1450,  2901] loss: 0.0142488  | loss_wrt: 0.00498  | loss_unl: 0.01081  | learning_rate: 0.00041\n",
      "OA: 0.9189  | AA:  0.9208  | Kappa:  0.9123  | Time: 16.8\n",
      "[1500,  3001] loss: 0.0178502  | loss_wrt: 0.01022  | loss_unl: 0.01549  | learning_rate: 0.00041\n",
      "OA: 0.9032  | AA:  0.9028  | Kappa:  0.8953  | Time: 17.0\n",
      "[1550,  3101] loss: 0.0347634  | loss_wrt: 0.00584  | loss_unl: 0.01127  | learning_rate: 0.00036\n",
      "OA: 0.9101  | AA:  0.9109  | Kappa:  0.9027  | Time: 17.0\n",
      "[1600,  3201] loss: 0.0285265  | loss_wrt: 0.00850  | loss_unl: 0.01559  | learning_rate: 0.00036\n",
      "OA: 0.8921  | AA:  0.9008  | Kappa:  0.8834  | Time: 17.0\n",
      "[1650,  3301] loss: 0.0100223  | loss_wrt: 0.00359  | loss_unl: 0.00883  | learning_rate: 0.00036\n",
      "OA: 0.9202  | AA:  0.9221  | Kappa:  0.9137  | Time: 17.0\n",
      "[1700,  3401] loss: 0.0231061  | loss_wrt: 0.00772  | loss_unl: 0.01459  | learning_rate: 0.00036\n",
      "OA: 0.9045  | AA:  0.9077  | Kappa:  0.8967  | Time: 17.0\n",
      "[1750,  3501] loss: 0.0179201  | loss_wrt: 0.00479  | loss_unl: 0.00991  | learning_rate: 0.00036\n",
      "OA: 0.9220  | AA:  0.9224  | Kappa:  0.9157  | Time: 17.0\n",
      "[1800,  3601] loss: 0.0314317  | loss_wrt: 0.00435  | loss_unl: 0.00910  | learning_rate: 0.00036\n",
      "OA: 0.9180  | AA:  0.9210  | Kappa:  0.9114  | Time: 16.9\n",
      "[1850,  3701] loss: 0.0242164  | loss_wrt: 0.00534  | loss_unl: 0.01108  | learning_rate: 0.00036\n",
      "OA: 0.9115  | AA:  0.9106  | Kappa:  0.9042  | Time: 17.0\n",
      "[1900,  3801] loss: 0.0120976  | loss_wrt: 0.00628  | loss_unl: 0.00992  | learning_rate: 0.00036\n",
      "OA: 0.9083  | AA:  0.9100  | Kappa:  0.9008  | Time: 16.7\n",
      "[1950,  3901] loss: 0.0070889  | loss_wrt: 0.00289  | loss_unl: 0.01071  | learning_rate: 0.00036\n",
      "OA: 0.9179  | AA:  0.9202  | Kappa:  0.9112  | Time: 16.5\n",
      "[2000,  4001] loss: 0.0206621  | loss_wrt: 0.00507  | loss_unl: 0.01651  | learning_rate: 0.00036\n",
      "OA: 0.9155  | AA:  0.9191  | Kappa:  0.9086  | Time: 16.5\n",
      "Finished Training\n",
      "model saved\n",
      "[0.77610536 0.93245779 0.9847973  0.8987701  0.98200758 0.92753623\n",
      " 0.95083488 0.82970672 0.95112782 0.99712368 0.91047619 0.83492366\n",
      " 0.79699248 0.99725275 1.        ]\n",
      "0.913731016126507 0.9180075025417674 0.906714362750317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([376, 144, 31, 31]) torch.Size([376, 144, 31, 31])\n",
      "=> all bands acc: 0.588\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -7.65 | loss:0.589 | 100 bands | 8.9s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -7.53 | loss:0.587 | 100 bands | 5.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -7.44 | loss:0.589 | 100 bands | 5.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -7.50 | loss:0.596 | 100 bands | 5.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -7.62 | loss:0.587 | 100 bands | 5.5s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -7.97 | loss:0.591 | 100 bands | 5.6s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -8.24 | loss:0.591 | 100 bands | 5.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -8.27 | loss:0.586 | 100 bands | 5.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -8.27 | loss:0.590 | 100 bands | 5.6s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -8.09 | loss:0.587 | 100 bands | 5.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -8.12 | loss:0.585 | 100 bands | 5.5s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -8.28 | loss:0.582 | 100 bands | 5.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -8.05 | loss:0.590 | 100 bands | 5.5s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -7.81 | loss:0.581 | 100 bands | 5.4s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -7.85 | loss:0.594 | 100 bands | 5.5s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -7.75 | loss:0.586 | 100 bands | 5.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -7.75 | loss:0.584 | 100 bands | 5.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -7.61 | loss:0.584 | 100 bands | 5.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -7.54 | loss:0.586 | 100 bands | 5.5s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -7.53 | loss:0.582 | 100 bands | 5.5s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -7.61 | loss:0.582 | 100 bands | 5.5s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -7.35 | loss:0.584 | 100 bands | 5.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -7.28 | loss:0.580 | 100 bands | 5.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -7.14 | loss:0.583 | 100 bands | 5.4s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -7.18 | loss:0.587 | 100 bands | 5.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -7.19 | loss:0.582 | 100 bands | 5.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -7.30 | loss:0.581 | 100 bands | 5.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -7.06 | loss:0.582 | 100 bands | 5.4s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -6.92 | loss:0.584 | 100 bands | 5.4s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -6.99 | loss:0.587 | 100 bands | 5.5s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -6.91 | loss:0.583 | 100 bands | 5.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -6.90 | loss:0.578 | 100 bands | 5.5s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -7.34 | loss:0.581 | 100 bands | 5.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -7.49 | loss:0.581 | 100 bands | 5.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -7.30 | loss:0.581 | 100 bands | 5.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -7.29 | loss:0.586 | 100 bands | 5.5s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -7.19 | loss:0.571 | 100 bands | 5.4s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -7.19 | loss:0.581 | 100 bands | 5.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -7.23 | loss:0.587 | 100 bands | 5.6s\n",
      "r_max, 0.5879493575193919\n",
      "Done\n",
      "time :224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 17:20:09.764391: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 17:20:09.767176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 17:20:09.767346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 17:20:10.204312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 17:20:10.204420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 17:20:10.204469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 17:20:10.204670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[20,   101] loss: 1.1907192  | loss_wrt: 0.12038  | loss_unl: 0.13362  | learning_rate: 0.00100\n",
      "OA: 0.8647  | AA:  0.8645  | Kappa:  0.8537  | Time: 18.1\n",
      "[40,   201] loss: 0.2303664  | loss_wrt: 0.08303  | loss_unl: 0.09398  | learning_rate: 0.00090\n",
      "OA: 0.9326  | AA:  0.9319  | Kappa:  0.9271  | Time: 16.2\n",
      "[60,   301] loss: 0.0985167  | loss_wrt: 0.05217  | loss_unl: 0.06118  | learning_rate: 0.00081\n",
      "OA: 0.9495  | AA:  0.9470  | Kappa:  0.9454  | Time: 16.3\n",
      "[80,   401] loss: 0.0769052  | loss_wrt: 0.03999  | loss_unl: 0.04802  | learning_rate: 0.00073\n",
      "OA: 0.9550  | AA:  0.9542  | Kappa:  0.9513  | Time: 16.6\n",
      "[100,   501] loss: 0.0515306  | loss_wrt: 0.02758  | loss_unl: 0.03623  | learning_rate: 0.00066\n",
      "OA: 0.9612  | AA:  0.9610  | Kappa:  0.9580  | Time: 16.5\n",
      "[120,   601] loss: 0.0300782  | loss_wrt: 0.01686  | loss_unl: 0.02726  | learning_rate: 0.00059\n",
      "OA: 0.9637  | AA:  0.9629  | Kappa:  0.9607  | Time: 16.5\n",
      "[140,   701] loss: 0.0302821  | loss_wrt: 0.01507  | loss_unl: 0.02006  | learning_rate: 0.00053\n",
      "OA: 0.9613  | AA:  0.9609  | Kappa:  0.9582  | Time: 16.5\n",
      "[160,   801] loss: 0.0180211  | loss_wrt: 0.01216  | loss_unl: 0.01830  | learning_rate: 0.00048\n",
      "OA: 0.9651  | AA:  0.9644  | Kappa:  0.9623  | Time: 16.8\n",
      "[180,   901] loss: 0.0142793  | loss_wrt: 0.01035  | loss_unl: 0.01370  | learning_rate: 0.00043\n",
      "OA: 0.9662  | AA:  0.9649  | Kappa:  0.9634  | Time: 16.6\n",
      "[200,  1001] loss: 0.0223724  | loss_wrt: 0.01364  | loss_unl: 0.01578  | learning_rate: 0.00039\n",
      "OA: 0.9654  | AA:  0.9651  | Kappa:  0.9626  | Time: 16.4\n",
      "[220,  1101] loss: 0.0124303  | loss_wrt: 0.00911  | loss_unl: 0.01066  | learning_rate: 0.00035\n",
      "OA: 0.9647  | AA:  0.9634  | Kappa:  0.9618  | Time: 16.4\n",
      "[240,  1201] loss: 0.0168530  | loss_wrt: 0.01355  | loss_unl: 0.01417  | learning_rate: 0.00031\n",
      "OA: 0.9563  | AA:  0.9563  | Kappa:  0.9528  | Time: 16.4\n",
      "[260,  1301] loss: 0.0126456  | loss_wrt: 0.00720  | loss_unl: 0.00930  | learning_rate: 0.00028\n",
      "OA: 0.9641  | AA:  0.9629  | Kappa:  0.9612  | Time: 16.4\n",
      "[280,  1401] loss: 0.0081395  | loss_wrt: 0.00549  | loss_unl: 0.00876  | learning_rate: 0.00025\n",
      "OA: 0.9645  | AA:  0.9638  | Kappa:  0.9617  | Time: 16.4\n",
      "[300,  1501] loss: 0.0081092  | loss_wrt: 0.00539  | loss_unl: 0.00684  | learning_rate: 0.00023\n",
      "OA: 0.9662  | AA:  0.9651  | Kappa:  0.9634  | Time: 16.4\n",
      "[320,  1601] loss: 0.0061805  | loss_wrt: 0.00587  | loss_unl: 0.00719  | learning_rate: 0.00021\n",
      "OA: 0.9656  | AA:  0.9640  | Kappa:  0.9628  | Time: 16.4\n",
      "[340,  1701] loss: 0.0054086  | loss_wrt: 0.00344  | loss_unl: 0.00516  | learning_rate: 0.00019\n",
      "OA: 0.9658  | AA:  0.9640  | Kappa:  0.9630  | Time: 16.4\n",
      "[360,  1801] loss: 0.0049709  | loss_wrt: 0.00494  | loss_unl: 0.00790  | learning_rate: 0.00017\n",
      "OA: 0.9619  | AA:  0.9606  | Kappa:  0.9588  | Time: 16.4\n",
      "[380,  1901] loss: 0.0047968  | loss_wrt: 0.00339  | loss_unl: 0.00487  | learning_rate: 0.00015\n",
      "OA: 0.9654  | AA:  0.9634  | Kappa:  0.9626  | Time: 16.4\n",
      "[400,  2001] loss: 0.0041668  | loss_wrt: 0.00373  | loss_unl: 0.00404  | learning_rate: 0.00014\n",
      "OA: 0.9650  | AA:  0.9627  | Kappa:  0.9622  | Time: 16.4\n",
      "[420,  2101] loss: 0.0037321  | loss_wrt: 0.00276  | loss_unl: 0.00427  | learning_rate: 0.00012\n",
      "OA: 0.9655  | AA:  0.9631  | Kappa:  0.9627  | Time: 16.4\n",
      "[440,  2201] loss: 0.0033622  | loss_wrt: 0.00197  | loss_unl: 0.00300  | learning_rate: 0.00011\n",
      "OA: 0.9656  | AA:  0.9635  | Kappa:  0.9628  | Time: 16.4\n",
      "[460,  2301] loss: 0.0030511  | loss_wrt: 0.00236  | loss_unl: 0.00306  | learning_rate: 0.00010\n",
      "OA: 0.9655  | AA:  0.9631  | Kappa:  0.9627  | Time: 16.4\n",
      "[480,  2401] loss: 0.0028059  | loss_wrt: 0.00273  | loss_unl: 0.00235  | learning_rate: 0.00009\n",
      "OA: 0.9656  | AA:  0.9635  | Kappa:  0.9628  | Time: 16.4\n",
      "[500,  2501] loss: 0.0027260  | loss_wrt: 0.00176  | loss_unl: 0.00293  | learning_rate: 0.00008\n",
      "OA: 0.9654  | AA:  0.9631  | Kappa:  0.9626  | Time: 16.4\n",
      "Finished Training\n",
      "(12774, 2)\n",
      "[0.97836312 0.98311445 1.         0.95458846 1.         0.87318841\n",
      " 0.95825603 0.90350047 0.94924812 0.95397891 0.99619048 0.96374046\n",
      " 0.93483709 1.         0.99821747]\n",
      "0.9653984656333177 0.963148230615106 0.9625884459706688\n",
      "(664845, 2)\n",
      "649816\n",
      "6498\n",
      "Finished!\n",
      "751\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1764948  | loss_wrt: 0.16102  | loss_unl: 0.19965  | learning_rate: 0.00050\n",
      "OA: 0.7707  | AA:  0.7813  | Kappa:  0.7521  | Time: 18.4\n",
      "[100,   201] loss: 0.3708320  | loss_wrt: 0.11237  | loss_unl: 0.14326  | learning_rate: 0.00050\n",
      "OA: 0.8160  | AA:  0.8246  | Kappa:  0.8011  | Time: 17.0\n",
      "[150,   301] loss: 0.2901063  | loss_wrt: 0.08419  | loss_unl: 0.10603  | learning_rate: 0.00050\n",
      "OA: 0.8469  | AA:  0.8516  | Kappa:  0.8344  | Time: 17.0\n",
      "[200,   401] loss: 0.1700154  | loss_wrt: 0.05864  | loss_unl: 0.07982  | learning_rate: 0.00050\n",
      "OA: 0.8435  | AA:  0.8531  | Kappa:  0.8308  | Time: 16.9\n",
      "[250,   501] loss: 0.1476034  | loss_wrt: 0.05588  | loss_unl: 0.08899  | learning_rate: 0.00050\n",
      "OA: 0.8669  | AA:  0.8746  | Kappa:  0.8561  | Time: 16.9\n",
      "[300,   601] loss: 0.0903521  | loss_wrt: 0.04045  | loss_unl: 0.05767  | learning_rate: 0.00050\n",
      "OA: 0.8656  | AA:  0.8651  | Kappa:  0.8546  | Time: 17.0\n",
      "[350,   701] loss: 0.0780531  | loss_wrt: 0.02788  | loss_unl: 0.04754  | learning_rate: 0.00050\n",
      "OA: 0.8708  | AA:  0.8744  | Kappa:  0.8602  | Time: 16.9\n",
      "[400,   801] loss: 0.1103382  | loss_wrt: 0.05133  | loss_unl: 0.06870  | learning_rate: 0.00050\n",
      "OA: 0.8476  | AA:  0.8497  | Kappa:  0.8352  | Time: 16.8\n",
      "[450,   901] loss: 0.0592275  | loss_wrt: 0.02695  | loss_unl: 0.04653  | learning_rate: 0.00050\n",
      "OA: 0.8722  | AA:  0.8762  | Kappa:  0.8617  | Time: 16.9\n",
      "[500,  1001] loss: 0.0687493  | loss_wrt: 0.01878  | loss_unl: 0.03242  | learning_rate: 0.00050\n",
      "OA: 0.8645  | AA:  0.8666  | Kappa:  0.8534  | Time: 16.8\n",
      "[550,  1101] loss: 0.0569730  | loss_wrt: 0.02419  | loss_unl: 0.03893  | learning_rate: 0.00045\n",
      "OA: 0.8552  | AA:  0.8448  | Kappa:  0.8432  | Time: 16.9\n",
      "[600,  1201] loss: 0.0521550  | loss_wrt: 0.01775  | loss_unl: 0.03093  | learning_rate: 0.00045\n",
      "OA: 0.8650  | AA:  0.8649  | Kappa:  0.8540  | Time: 16.9\n",
      "[650,  1301] loss: 0.0512730  | loss_wrt: 0.01426  | loss_unl: 0.02757  | learning_rate: 0.00045\n",
      "OA: 0.8520  | AA:  0.8564  | Kappa:  0.8400  | Time: 16.8\n",
      "[700,  1401] loss: 0.0223240  | loss_wrt: 0.00952  | loss_unl: 0.01963  | learning_rate: 0.00045\n",
      "OA: 0.8768  | AA:  0.8791  | Kappa:  0.8668  | Time: 16.8\n",
      "[750,  1501] loss: 0.0292605  | loss_wrt: 0.00852  | loss_unl: 0.01628  | learning_rate: 0.00045\n",
      "OA: 0.8794  | AA:  0.8840  | Kappa:  0.8696  | Time: 16.8\n",
      "[800,  1601] loss: 0.0609387  | loss_wrt: 0.01067  | loss_unl: 0.01805  | learning_rate: 0.00045\n",
      "OA: 0.8657  | AA:  0.8668  | Kappa:  0.8548  | Time: 16.9\n",
      "[850,  1701] loss: 0.0530270  | loss_wrt: 0.01744  | loss_unl: 0.02447  | learning_rate: 0.00045\n",
      "OA: 0.8620  | AA:  0.8675  | Kappa:  0.8508  | Time: 16.9\n",
      "[900,  1801] loss: 0.0351871  | loss_wrt: 0.01225  | loss_unl: 0.01793  | learning_rate: 0.00045\n",
      "OA: 0.8527  | AA:  0.8571  | Kappa:  0.8407  | Time: 16.8\n",
      "[950,  1901] loss: 0.0338607  | loss_wrt: 0.01127  | loss_unl: 0.02030  | learning_rate: 0.00045\n",
      "OA: 0.8624  | AA:  0.8687  | Kappa:  0.8512  | Time: 16.9\n",
      "[1000,  2001] loss: 0.0309270  | loss_wrt: 0.01423  | loss_unl: 0.02117  | learning_rate: 0.00045\n",
      "OA: 0.8398  | AA:  0.8403  | Kappa:  0.8268  | Time: 16.9\n",
      "[1050,  2101] loss: 0.0156799  | loss_wrt: 0.00733  | loss_unl: 0.01550  | learning_rate: 0.00041\n",
      "OA: 0.8668  | AA:  0.8719  | Kappa:  0.8560  | Time: 16.8\n",
      "[1100,  2201] loss: 0.0275684  | loss_wrt: 0.00688  | loss_unl: 0.01470  | learning_rate: 0.00041\n",
      "OA: 0.8708  | AA:  0.8736  | Kappa:  0.8602  | Time: 16.6\n",
      "[1150,  2301] loss: 0.0273654  | loss_wrt: 0.00582  | loss_unl: 0.01460  | learning_rate: 0.00041\n",
      "OA: 0.8665  | AA:  0.8699  | Kappa:  0.8557  | Time: 16.6\n",
      "[1200,  2401] loss: 0.0401581  | loss_wrt: 0.00865  | loss_unl: 0.01461  | learning_rate: 0.00041\n",
      "OA: 0.8636  | AA:  0.8668  | Kappa:  0.8525  | Time: 16.6\n",
      "[1250,  2501] loss: 0.0183913  | loss_wrt: 0.01079  | loss_unl: 0.01480  | learning_rate: 0.00041\n",
      "OA: 0.8540  | AA:  0.8602  | Kappa:  0.8422  | Time: 16.6\n",
      "[1300,  2601] loss: 0.0136718  | loss_wrt: 0.00539  | loss_unl: 0.01027  | learning_rate: 0.00041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA: 0.8625  | AA:  0.8677  | Kappa:  0.8512  | Time: 16.6\n",
      "[1350,  2701] loss: 0.0542801  | loss_wrt: 0.01259  | loss_unl: 0.01860  | learning_rate: 0.00041\n",
      "OA: 0.8344  | AA:  0.8316  | Kappa:  0.8209  | Time: 16.9\n",
      "[1400,  2801] loss: 0.0581846  | loss_wrt: 0.01109  | loss_unl: 0.01532  | learning_rate: 0.00041\n",
      "OA: 0.8521  | AA:  0.8559  | Kappa:  0.8400  | Time: 16.9\n",
      "[1450,  2901] loss: 0.0327674  | loss_wrt: 0.00800  | loss_unl: 0.01241  | learning_rate: 0.00041\n",
      "OA: 0.8549  | AA:  0.8615  | Kappa:  0.8431  | Time: 17.1\n",
      "[1500,  3001] loss: 0.0255204  | loss_wrt: 0.00580  | loss_unl: 0.01266  | learning_rate: 0.00041\n",
      "OA: 0.8733  | AA:  0.8776  | Kappa:  0.8629  | Time: 17.0\n",
      "[1550,  3101] loss: 0.0227075  | loss_wrt: 0.00706  | loss_unl: 0.01314  | learning_rate: 0.00036\n",
      "OA: 0.8646  | AA:  0.8708  | Kappa:  0.8536  | Time: 17.0\n",
      "[1600,  3201] loss: 0.0341595  | loss_wrt: 0.00947  | loss_unl: 0.01349  | learning_rate: 0.00036\n",
      "OA: 0.8574  | AA:  0.8656  | Kappa:  0.8459  | Time: 16.9\n",
      "[1650,  3301] loss: 0.0271307  | loss_wrt: 0.00714  | loss_unl: 0.01094  | learning_rate: 0.00036\n",
      "OA: 0.8683  | AA:  0.8734  | Kappa:  0.8576  | Time: 16.5\n",
      "[1700,  3401] loss: 0.0108265  | loss_wrt: 0.00420  | loss_unl: 0.00955  | learning_rate: 0.00036\n",
      "OA: 0.8698  | AA:  0.8750  | Kappa:  0.8592  | Time: 16.5\n",
      "[1750,  3501] loss: 0.0150545  | loss_wrt: 0.00493  | loss_unl: 0.01124  | learning_rate: 0.00036\n",
      "OA: 0.8626  | AA:  0.8684  | Kappa:  0.8514  | Time: 16.6\n",
      "[1800,  3601] loss: 0.0074125  | loss_wrt: 0.00383  | loss_unl: 0.00772  | learning_rate: 0.00036\n",
      "OA: 0.8637  | AA:  0.8674  | Kappa:  0.8526  | Time: 16.8\n",
      "[1850,  3701] loss: 0.0175336  | loss_wrt: 0.00734  | loss_unl: 0.01153  | learning_rate: 0.00036\n",
      "OA: 0.8538  | AA:  0.8624  | Kappa:  0.8420  | Time: 17.0\n",
      "[1900,  3801] loss: 0.0173859  | loss_wrt: 0.00748  | loss_unl: 0.01320  | learning_rate: 0.00036\n",
      "OA: 0.8591  | AA:  0.8640  | Kappa:  0.8476  | Time: 17.0\n",
      "[1950,  3901] loss: 0.0138337  | loss_wrt: 0.00351  | loss_unl: 0.00818  | learning_rate: 0.00036\n",
      "OA: 0.8730  | AA:  0.8781  | Kappa:  0.8627  | Time: 16.5\n",
      "[2000,  4001] loss: 0.0194029  | loss_wrt: 0.00508  | loss_unl: 0.00906  | learning_rate: 0.00036\n",
      "OA: 0.8575  | AA:  0.8656  | Kappa:  0.8459  | Time: 16.6\n",
      "Finished Training\n",
      "model saved\n",
      "[0.91063029 0.69136961 1.         0.85808893 0.99810606 0.81521739\n",
      " 0.86827458 0.5269631  0.92951128 0.92329818 0.94952381 0.81965649\n",
      " 0.79699248 0.99175824 0.98039216]\n",
      "0.8621418506341005 0.8706521733723487 0.8509301930285472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([376, 144, 31, 31]) torch.Size([376, 144, 31, 31])\n",
      "=> all bands acc: 0.663\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -6.01 | loss:0.658 | 100 bands | 9.0s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -6.62 | loss:0.666 | 100 bands | 5.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -7.28 | loss:0.663 | 100 bands | 5.5s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -7.56 | loss:0.666 | 100 bands | 5.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -7.97 | loss:0.663 | 100 bands | 5.7s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -7.90 | loss:0.664 | 100 bands | 5.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -8.04 | loss:0.662 | 100 bands | 5.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -7.92 | loss:0.667 | 100 bands | 5.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -7.74 | loss:0.660 | 100 bands | 5.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -8.03 | loss:0.669 | 100 bands | 5.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -8.18 | loss:0.660 | 100 bands | 5.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -7.90 | loss:0.660 | 100 bands | 5.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -7.90 | loss:0.661 | 100 bands | 5.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -8.43 | loss:0.661 | 100 bands | 5.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -8.62 | loss:0.662 | 100 bands | 5.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -8.53 | loss:0.671 | 100 bands | 5.6s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -8.45 | loss:0.659 | 100 bands | 5.6s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -8.25 | loss:0.657 | 100 bands | 5.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -8.34 | loss:0.661 | 100 bands | 5.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -8.28 | loss:0.664 | 100 bands | 5.5s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -7.98 | loss:0.662 | 100 bands | 5.5s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -7.74 | loss:0.656 | 100 bands | 5.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -7.95 | loss:0.663 | 100 bands | 5.6s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -7.99 | loss:0.654 | 100 bands | 5.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -8.13 | loss:0.658 | 100 bands | 5.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -8.24 | loss:0.664 | 100 bands | 5.6s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -8.13 | loss:0.662 | 100 bands | 5.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -8.12 | loss:0.655 | 100 bands | 5.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -8.04 | loss:0.656 | 100 bands | 5.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -7.98 | loss:0.659 | 100 bands | 5.5s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -7.86 | loss:0.655 | 100 bands | 5.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -7.62 | loss:0.653 | 100 bands | 5.4s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -7.60 | loss:0.664 | 100 bands | 5.5s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -7.72 | loss:0.663 | 100 bands | 5.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -8.17 | loss:0.657 | 100 bands | 5.8s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -8.30 | loss:0.657 | 100 bands | 5.7s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -8.10 | loss:0.652 | 100 bands | 5.6s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -7.64 | loss:0.658 | 100 bands | 5.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -7.42 | loss:0.651 | 100 bands | 5.6s\n",
      "r_max, 0.6571583016630029\n",
      "Done\n",
      "time :227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 17:43:57.885143: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 17:43:57.887931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 17:43:57.888096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 17:43:58.335256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 17:43:58.335359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 17:43:58.335407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 17:43:58.335603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[20,   101] loss: 1.2565072  | loss_wrt: 0.12827  | loss_unl: 0.15105  | learning_rate: 0.00100\n",
      "OA: 0.8722  | AA:  0.8778  | Kappa:  0.8618  | Time: 16.5\n",
      "[40,   201] loss: 0.2401783  | loss_wrt: 0.08437  | loss_unl: 0.09839  | learning_rate: 0.00090\n",
      "OA: 0.9348  | AA:  0.9365  | Kappa:  0.9295  | Time: 16.5\n",
      "[60,   301] loss: 0.1045414  | loss_wrt: 0.05274  | loss_unl: 0.06661  | learning_rate: 0.00081\n",
      "OA: 0.9426  | AA:  0.9439  | Kappa:  0.9380  | Time: 16.6\n",
      "[80,   401] loss: 0.0584698  | loss_wrt: 0.03436  | loss_unl: 0.04095  | learning_rate: 0.00073\n",
      "OA: 0.9430  | AA:  0.9470  | Kappa:  0.9384  | Time: 16.4\n",
      "[100,   501] loss: 0.0386425  | loss_wrt: 0.02377  | loss_unl: 0.03131  | learning_rate: 0.00066\n",
      "OA: 0.9473  | AA:  0.9507  | Kappa:  0.9430  | Time: 16.3\n",
      "[120,   601] loss: 0.0614025  | loss_wrt: 0.05223  | loss_unl: 0.05713  | learning_rate: 0.00059\n",
      "OA: 0.9367  | AA:  0.9328  | Kappa:  0.9315  | Time: 16.3\n",
      "[140,   701] loss: 0.0363664  | loss_wrt: 0.01977  | loss_unl: 0.02777  | learning_rate: 0.00053\n",
      "OA: 0.9486  | AA:  0.9516  | Kappa:  0.9445  | Time: 16.2\n",
      "[160,   801] loss: 0.0217227  | loss_wrt: 0.01280  | loss_unl: 0.01930  | learning_rate: 0.00048\n",
      "OA: 0.9510  | AA:  0.9531  | Kappa:  0.9470  | Time: 16.2\n",
      "[180,   901] loss: 0.0169833  | loss_wrt: 0.01253  | loss_unl: 0.01788  | learning_rate: 0.00043\n",
      "OA: 0.9533  | AA:  0.9548  | Kappa:  0.9495  | Time: 16.2\n",
      "[200,  1001] loss: 0.0135732  | loss_wrt: 0.00813  | loss_unl: 0.01224  | learning_rate: 0.00039\n",
      "OA: 0.9540  | AA:  0.9558  | Kappa:  0.9503  | Time: 16.2\n",
      "[220,  1101] loss: 0.0107464  | loss_wrt: 0.00754  | loss_unl: 0.01037  | learning_rate: 0.00035\n",
      "OA: 0.9552  | AA:  0.9572  | Kappa:  0.9516  | Time: 16.2\n",
      "[240,  1201] loss: 0.0242892  | loss_wrt: 0.01029  | loss_unl: 0.01522  | learning_rate: 0.00031\n",
      "OA: 0.9524  | AA:  0.9545  | Kappa:  0.9485  | Time: 16.3\n",
      "[260,  1301] loss: 0.0102843  | loss_wrt: 0.00595  | loss_unl: 0.00966  | learning_rate: 0.00028\n",
      "OA: 0.9539  | AA:  0.9556  | Kappa:  0.9502  | Time: 16.3\n",
      "[280,  1401] loss: 0.0079788  | loss_wrt: 0.00529  | loss_unl: 0.00898  | learning_rate: 0.00025\n",
      "OA: 0.9549  | AA:  0.9566  | Kappa:  0.9513  | Time: 16.3\n",
      "[300,  1501] loss: 0.0067170  | loss_wrt: 0.00414  | loss_unl: 0.00796  | learning_rate: 0.00023\n",
      "OA: 0.9552  | AA:  0.9571  | Kappa:  0.9516  | Time: 16.3\n",
      "[320,  1601] loss: 0.0060570  | loss_wrt: 0.00389  | loss_unl: 0.00597  | learning_rate: 0.00021\n",
      "OA: 0.9566  | AA:  0.9581  | Kappa:  0.9531  | Time: 16.3\n",
      "[340,  1701] loss: 0.0052596  | loss_wrt: 0.00340  | loss_unl: 0.00562  | learning_rate: 0.00019\n",
      "OA: 0.9556  | AA:  0.9573  | Kappa:  0.9520  | Time: 16.3\n",
      "[360,  1801] loss: 0.0045194  | loss_wrt: 0.00356  | loss_unl: 0.00435  | learning_rate: 0.00017\n",
      "OA: 0.9565  | AA:  0.9582  | Kappa:  0.9529  | Time: 16.3\n",
      "[380,  1901] loss: 0.0039412  | loss_wrt: 0.00277  | loss_unl: 0.00372  | learning_rate: 0.00015\n",
      "OA: 0.9570  | AA:  0.9586  | Kappa:  0.9535  | Time: 16.3\n",
      "[400,  2001] loss: 0.0034131  | loss_wrt: 0.00283  | loss_unl: 0.00267  | learning_rate: 0.00014\n",
      "OA: 0.9572  | AA:  0.9586  | Kappa:  0.9537  | Time: 16.3\n",
      "[420,  2101] loss: 0.0031134  | loss_wrt: 0.00220  | loss_unl: 0.00310  | learning_rate: 0.00012\n",
      "OA: 0.9571  | AA:  0.9587  | Kappa:  0.9536  | Time: 16.3\n",
      "[440,  2201] loss: 0.0028293  | loss_wrt: 0.00205  | loss_unl: 0.00237  | learning_rate: 0.00011\n",
      "OA: 0.9566  | AA:  0.9581  | Kappa:  0.9531  | Time: 16.3\n",
      "[460,  2301] loss: 0.0025884  | loss_wrt: 0.00162  | loss_unl: 0.00283  | learning_rate: 0.00010\n",
      "OA: 0.9569  | AA:  0.9584  | Kappa:  0.9535  | Time: 16.3\n",
      "[480,  2401] loss: 0.0023303  | loss_wrt: 0.00195  | loss_unl: 0.00228  | learning_rate: 0.00009\n",
      "OA: 0.9569  | AA:  0.9585  | Kappa:  0.9534  | Time: 16.3\n",
      "[500,  2501] loss: 0.0022504  | loss_wrt: 0.00115  | loss_unl: 0.00195  | learning_rate: 0.00008\n",
      "OA: 0.9563  | AA:  0.9578  | Kappa:  0.9528  | Time: 16.3\n",
      "Finished Training\n",
      "(12774, 2)\n",
      "[0.9943556  0.94559099 0.99831081 0.95364238 1.         0.92753623\n",
      " 0.92022263 0.80794702 0.9906015  0.99904123 0.98190476 0.93129771\n",
      " 0.94736842 0.97252747 0.99643494]\n",
      "0.9563175199624236 0.9577854471281759 0.9527797945230118\n",
      "(664845, 2)\n",
      "649816\n",
      "6498\n",
      "Finished!\n",
      "751\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2729720  | loss_wrt: 0.18068  | loss_unl: 0.20624  | learning_rate: 0.00050\n",
      "OA: 0.7323  | AA:  0.7376  | Kappa:  0.7104  | Time: 18.0\n",
      "[100,   201] loss: 0.4977851  | loss_wrt: 0.12425  | loss_unl: 0.15684  | learning_rate: 0.00050\n",
      "OA: 0.7615  | AA:  0.7628  | Kappa:  0.7418  | Time: 16.4\n",
      "[150,   301] loss: 0.2043890  | loss_wrt: 0.08336  | loss_unl: 0.13152  | learning_rate: 0.00050\n",
      "OA: 0.8477  | AA:  0.8474  | Kappa:  0.8354  | Time: 16.6\n",
      "[200,   401] loss: 0.1377786  | loss_wrt: 0.06851  | loss_unl: 0.09150  | learning_rate: 0.00050\n",
      "OA: 0.8565  | AA:  0.8517  | Kappa:  0.8448  | Time: 16.5\n",
      "[250,   501] loss: 0.1130721  | loss_wrt: 0.04073  | loss_unl: 0.06656  | learning_rate: 0.00050\n",
      "OA: 0.8372  | AA:  0.8356  | Kappa:  0.8239  | Time: 16.5\n",
      "[300,   601] loss: 0.0653868  | loss_wrt: 0.03677  | loss_unl: 0.06052  | learning_rate: 0.00050\n",
      "OA: 0.8562  | AA:  0.8510  | Kappa:  0.8444  | Time: 16.5\n",
      "[350,   701] loss: 0.1196082  | loss_wrt: 0.04127  | loss_unl: 0.05873  | learning_rate: 0.00050\n",
      "OA: 0.8225  | AA:  0.8178  | Kappa:  0.8079  | Time: 16.5\n",
      "[400,   801] loss: 0.0724824  | loss_wrt: 0.04305  | loss_unl: 0.04831  | learning_rate: 0.00050\n",
      "OA: 0.8581  | AA:  0.8530  | Kappa:  0.8465  | Time: 16.5\n",
      "[450,   901] loss: 0.0894407  | loss_wrt: 0.03937  | loss_unl: 0.06357  | learning_rate: 0.00050\n",
      "OA: 0.8156  | AA:  0.8237  | Kappa:  0.8007  | Time: 16.5\n",
      "[500,  1001] loss: 0.0909849  | loss_wrt: 0.02641  | loss_unl: 0.04465  | learning_rate: 0.00050\n",
      "OA: 0.8586  | AA:  0.8552  | Kappa:  0.8471  | Time: 16.8\n",
      "[550,  1101] loss: 0.0618963  | loss_wrt: 0.01712  | loss_unl: 0.02915  | learning_rate: 0.00045\n",
      "OA: 0.8695  | AA:  0.8638  | Kappa:  0.8588  | Time: 16.9\n",
      "[600,  1201] loss: 0.0555147  | loss_wrt: 0.01672  | loss_unl: 0.03091  | learning_rate: 0.00045\n",
      "OA: 0.8571  | AA:  0.8511  | Kappa:  0.8454  | Time: 16.8\n",
      "[650,  1301] loss: 0.0557834  | loss_wrt: 0.01888  | loss_unl: 0.03310  | learning_rate: 0.00045\n",
      "OA: 0.8352  | AA:  0.8283  | Kappa:  0.8216  | Time: 16.6\n",
      "[700,  1401] loss: 0.0501935  | loss_wrt: 0.02413  | loss_unl: 0.03350  | learning_rate: 0.00045\n",
      "OA: 0.8561  | AA:  0.8526  | Kappa:  0.8443  | Time: 16.5\n",
      "[750,  1501] loss: 0.0575122  | loss_wrt: 0.02025  | loss_unl: 0.03101  | learning_rate: 0.00045\n",
      "OA: 0.8561  | AA:  0.8509  | Kappa:  0.8443  | Time: 16.6\n",
      "[800,  1601] loss: 0.0317914  | loss_wrt: 0.01393  | loss_unl: 0.02545  | learning_rate: 0.00045\n",
      "OA: 0.8730  | AA:  0.8670  | Kappa:  0.8626  | Time: 16.5\n",
      "[850,  1701] loss: 0.0443833  | loss_wrt: 0.01201  | loss_unl: 0.02270  | learning_rate: 0.00045\n",
      "OA: 0.8652  | AA:  0.8605  | Kappa:  0.8541  | Time: 16.5\n",
      "[900,  1801] loss: 0.0231217  | loss_wrt: 0.00832  | loss_unl: 0.01850  | learning_rate: 0.00045\n",
      "OA: 0.8532  | AA:  0.8470  | Kappa:  0.8412  | Time: 16.6\n",
      "[950,  1901] loss: 0.0318779  | loss_wrt: 0.01742  | loss_unl: 0.02490  | learning_rate: 0.00045\n",
      "OA: 0.8651  | AA:  0.8597  | Kappa:  0.8541  | Time: 16.6\n",
      "[1000,  2001] loss: 0.0839076  | loss_wrt: 0.02093  | loss_unl: 0.02659  | learning_rate: 0.00045\n",
      "OA: 0.8529  | AA:  0.8465  | Kappa:  0.8408  | Time: 16.6\n",
      "[1050,  2101] loss: 0.0440071  | loss_wrt: 0.01154  | loss_unl: 0.01999  | learning_rate: 0.00041\n",
      "OA: 0.8622  | AA:  0.8555  | Kappa:  0.8509  | Time: 16.5\n",
      "[1100,  2201] loss: 0.0443185  | loss_wrt: 0.01054  | loss_unl: 0.01749  | learning_rate: 0.00041\n",
      "OA: 0.8544  | AA:  0.8463  | Kappa:  0.8424  | Time: 16.5\n",
      "[1150,  2301] loss: 0.0172210  | loss_wrt: 0.00628  | loss_unl: 0.01599  | learning_rate: 0.00041\n",
      "OA: 0.8708  | AA:  0.8634  | Kappa:  0.8601  | Time: 16.5\n",
      "[1200,  2401] loss: 0.0218570  | loss_wrt: 0.00823  | loss_unl: 0.01238  | learning_rate: 0.00041\n",
      "OA: 0.8714  | AA:  0.8657  | Kappa:  0.8608  | Time: 16.6\n",
      "[1250,  2501] loss: 0.0134221  | loss_wrt: 0.00453  | loss_unl: 0.01236  | learning_rate: 0.00041\n",
      "OA: 0.8692  | AA:  0.8617  | Kappa:  0.8585  | Time: 16.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300,  2601] loss: 0.0412115  | loss_wrt: 0.01424  | loss_unl: 0.02128  | learning_rate: 0.00041\n",
      "OA: 0.8696  | AA:  0.8630  | Kappa:  0.8589  | Time: 16.5\n",
      "[1350,  2701] loss: 0.0530059  | loss_wrt: 0.00964  | loss_unl: 0.01358  | learning_rate: 0.00041\n",
      "OA: 0.8639  | AA:  0.8570  | Kappa:  0.8528  | Time: 16.7\n",
      "[1400,  2801] loss: 0.0171056  | loss_wrt: 0.00836  | loss_unl: 0.01641  | learning_rate: 0.00041\n",
      "OA: 0.8626  | AA:  0.8575  | Kappa:  0.8514  | Time: 17.0\n",
      "[1450,  2901] loss: 0.0227284  | loss_wrt: 0.00737  | loss_unl: 0.01532  | learning_rate: 0.00041\n",
      "OA: 0.8446  | AA:  0.8435  | Kappa:  0.8319  | Time: 16.7\n",
      "[1500,  3001] loss: 0.0109225  | loss_wrt: 0.00419  | loss_unl: 0.00911  | learning_rate: 0.00041\n",
      "OA: 0.8687  | AA:  0.8634  | Kappa:  0.8579  | Time: 17.0\n",
      "[1550,  3101] loss: 0.0279203  | loss_wrt: 0.00605  | loss_unl: 0.01305  | learning_rate: 0.00036\n",
      "OA: 0.8648  | AA:  0.8599  | Kappa:  0.8537  | Time: 16.8\n",
      "[1600,  3201] loss: 0.0220289  | loss_wrt: 0.00834  | loss_unl: 0.01360  | learning_rate: 0.00036\n",
      "OA: 0.8446  | AA:  0.8395  | Kappa:  0.8318  | Time: 17.2\n",
      "[1650,  3301] loss: 0.0094361  | loss_wrt: 0.00413  | loss_unl: 0.00989  | learning_rate: 0.00036\n",
      "OA: 0.8728  | AA:  0.8662  | Kappa:  0.8624  | Time: 16.9\n",
      "[1700,  3401] loss: 0.0154575  | loss_wrt: 0.00626  | loss_unl: 0.01160  | learning_rate: 0.00036\n",
      "OA: 0.8682  | AA:  0.8606  | Kappa:  0.8574  | Time: 16.8\n",
      "[1750,  3501] loss: 0.0098574  | loss_wrt: 0.00487  | loss_unl: 0.00847  | learning_rate: 0.00036\n",
      "OA: 0.8571  | AA:  0.8532  | Kappa:  0.8453  | Time: 16.8\n",
      "[1800,  3601] loss: 0.0162405  | loss_wrt: 0.00426  | loss_unl: 0.00771  | learning_rate: 0.00036\n",
      "OA: 0.8661  | AA:  0.8611  | Kappa:  0.8551  | Time: 17.0\n",
      "[1850,  3701] loss: 0.0260170  | loss_wrt: 0.00630  | loss_unl: 0.01248  | learning_rate: 0.00036\n",
      "OA: 0.8620  | AA:  0.8566  | Kappa:  0.8507  | Time: 16.8\n",
      "[1900,  3801] loss: 0.0340467  | loss_wrt: 0.00739  | loss_unl: 0.01234  | learning_rate: 0.00036\n",
      "OA: 0.8732  | AA:  0.8674  | Kappa:  0.8628  | Time: 17.1\n",
      "[1950,  3901] loss: 0.0220294  | loss_wrt: 0.00552  | loss_unl: 0.00950  | learning_rate: 0.00036\n",
      "OA: 0.8735  | AA:  0.8670  | Kappa:  0.8631  | Time: 16.9\n",
      "[2000,  4001] loss: 0.0327785  | loss_wrt: 0.00572  | loss_unl: 0.00925  | learning_rate: 0.00036\n",
      "OA: 0.8693  | AA:  0.8637  | Kappa:  0.8585  | Time: 16.9\n",
      "Finished Training\n",
      "model saved\n",
      "[0.87676388 0.85928705 0.99662162 0.88741722 0.90246212 0.76449275\n",
      " 0.9257885  0.76726585 0.7462406  0.90316395 0.82857143 0.89408397\n",
      " 0.54636591 0.98901099 0.9714795 ]\n",
      "0.862298418662909 0.8572676895706076 0.8510035507420461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([376, 144, 31, 31]) torch.Size([376, 144, 31, 31])\n",
      "=> all bands acc: 0.531\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -7.49 | loss:0.530 | 100 bands | 9.2s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -7.82 | loss:0.524 | 100 bands | 5.7s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -8.76 | loss:0.531 | 100 bands | 6.3s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -8.91 | loss:0.528 | 100 bands | 6.3s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -9.08 | loss:0.528 | 100 bands | 6.2s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -8.73 | loss:0.528 | 100 bands | 6.0s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -8.61 | loss:0.528 | 100 bands | 5.8s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -8.42 | loss:0.527 | 100 bands | 5.8s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -8.16 | loss:0.533 | 100 bands | 5.9s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -7.88 | loss:0.530 | 100 bands | 6.0s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -7.92 | loss:0.529 | 100 bands | 6.0s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -7.84 | loss:0.528 | 100 bands | 6.0s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -7.89 | loss:0.531 | 100 bands | 5.9s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -7.77 | loss:0.523 | 100 bands | 5.8s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -7.55 | loss:0.528 | 100 bands | 5.8s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -7.36 | loss:0.531 | 100 bands | 5.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -7.43 | loss:0.528 | 100 bands | 5.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -7.56 | loss:0.528 | 100 bands | 5.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -7.72 | loss:0.525 | 100 bands | 5.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -7.79 | loss:0.528 | 100 bands | 5.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -7.72 | loss:0.529 | 100 bands | 5.5s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -7.55 | loss:0.528 | 100 bands | 5.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -7.38 | loss:0.535 | 100 bands | 5.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -7.18 | loss:0.525 | 100 bands | 5.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -7.17 | loss:0.525 | 100 bands | 5.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -7.00 | loss:0.527 | 100 bands | 5.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -7.20 | loss:0.526 | 100 bands | 5.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -7.34 | loss:0.521 | 100 bands | 5.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -7.21 | loss:0.535 | 100 bands | 5.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -7.32 | loss:0.525 | 100 bands | 5.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -7.27 | loss:0.524 | 100 bands | 5.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -7.16 | loss:0.531 | 100 bands | 5.5s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -7.18 | loss:0.526 | 100 bands | 5.5s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -7.44 | loss:0.524 | 100 bands | 5.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -7.26 | loss:0.529 | 100 bands | 5.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -7.25 | loss:0.522 | 100 bands | 5.5s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -7.09 | loss:0.527 | 100 bands | 5.7s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -7.13 | loss:0.526 | 100 bands | 5.7s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -7.12 | loss:0.531 | 100 bands | 5.6s\n",
      "r_max, 0.524904625461204\n",
      "Done\n",
      "time :232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 18:07:36.771021: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 18:07:36.773870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 18:07:36.774025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 18:07:37.222589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 18:07:37.222689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 18:07:37.222738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 18:07:37.222937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[20,   101] loss: 1.3979248  | loss_wrt: 0.14012  | loss_unl: 0.15973  | learning_rate: 0.00100\n",
      "OA: 0.7967  | AA:  0.8059  | Kappa:  0.7800  | Time: 17.2\n",
      "[40,   201] loss: 0.2586856  | loss_wrt: 0.08593  | loss_unl: 0.09883  | learning_rate: 0.00090\n",
      "OA: 0.9152  | AA:  0.9150  | Kappa:  0.9083  | Time: 16.7\n",
      "[60,   301] loss: 0.1197035  | loss_wrt: 0.05776  | loss_unl: 0.06873  | learning_rate: 0.00081\n",
      "OA: 0.9295  | AA:  0.9283  | Kappa:  0.9237  | Time: 16.9\n",
      "[80,   401] loss: 0.0786582  | loss_wrt: 0.04407  | loss_unl: 0.04943  | learning_rate: 0.00073\n",
      "OA: 0.9333  | AA:  0.9315  | Kappa:  0.9279  | Time: 16.6\n",
      "[100,   501] loss: 0.0494154  | loss_wrt: 0.02648  | loss_unl: 0.03572  | learning_rate: 0.00066\n",
      "OA: 0.9408  | AA:  0.9380  | Kappa:  0.9360  | Time: 16.4\n",
      "[120,   601] loss: 0.0376800  | loss_wrt: 0.01992  | loss_unl: 0.02585  | learning_rate: 0.00059\n",
      "OA: 0.9442  | AA:  0.9422  | Kappa:  0.9397  | Time: 16.7\n",
      "[140,   701] loss: 0.0480704  | loss_wrt: 0.03761  | loss_unl: 0.04400  | learning_rate: 0.00053\n",
      "OA: 0.9299  | AA:  0.9284  | Kappa:  0.9242  | Time: 16.8\n",
      "[160,   801] loss: 0.0300193  | loss_wrt: 0.01354  | loss_unl: 0.02223  | learning_rate: 0.00048\n",
      "OA: 0.9429  | AA:  0.9383  | Kappa:  0.9382  | Time: 16.5\n",
      "[180,   901] loss: 0.0221029  | loss_wrt: 0.01282  | loss_unl: 0.01806  | learning_rate: 0.00043\n",
      "OA: 0.9439  | AA:  0.9401  | Kappa:  0.9393  | Time: 16.9\n",
      "[200,  1001] loss: 0.0151285  | loss_wrt: 0.00881  | loss_unl: 0.01315  | learning_rate: 0.00039\n",
      "OA: 0.9472  | AA:  0.9421  | Kappa:  0.9429  | Time: 16.8\n",
      "[220,  1101] loss: 0.0145333  | loss_wrt: 0.01215  | loss_unl: 0.01612  | learning_rate: 0.00035\n",
      "OA: 0.9491  | AA:  0.9444  | Kappa:  0.9450  | Time: 16.7\n",
      "[240,  1201] loss: 0.0111473  | loss_wrt: 0.00621  | loss_unl: 0.00938  | learning_rate: 0.00031\n",
      "OA: 0.9504  | AA:  0.9452  | Kappa:  0.9464  | Time: 16.7\n",
      "[260,  1301] loss: 0.0082580  | loss_wrt: 0.00527  | loss_unl: 0.00834  | learning_rate: 0.00028\n",
      "OA: 0.9501  | AA:  0.9450  | Kappa:  0.9461  | Time: 16.4\n",
      "[280,  1401] loss: 0.0067208  | loss_wrt: 0.00402  | loss_unl: 0.00719  | learning_rate: 0.00025\n",
      "OA: 0.9512  | AA:  0.9456  | Kappa:  0.9472  | Time: 16.4\n",
      "[300,  1501] loss: 0.0060203  | loss_wrt: 0.00578  | loss_unl: 0.00661  | learning_rate: 0.00023\n",
      "OA: 0.9505  | AA:  0.9457  | Kappa:  0.9465  | Time: 16.4\n",
      "[320,  1601] loss: 0.0089812  | loss_wrt: 0.00353  | loss_unl: 0.00593  | learning_rate: 0.00021\n",
      "OA: 0.9522  | AA:  0.9470  | Kappa:  0.9483  | Time: 16.4\n",
      "[340,  1701] loss: 0.0048301  | loss_wrt: 0.00331  | loss_unl: 0.00551  | learning_rate: 0.00019\n",
      "OA: 0.9525  | AA:  0.9468  | Kappa:  0.9486  | Time: 16.4\n",
      "[360,  1801] loss: 0.0038962  | loss_wrt: 0.00293  | loss_unl: 0.00466  | learning_rate: 0.00017\n",
      "OA: 0.9522  | AA:  0.9464  | Kappa:  0.9484  | Time: 16.4\n",
      "[380,  1901] loss: 0.0034331  | loss_wrt: 0.00212  | loss_unl: 0.00365  | learning_rate: 0.00015\n",
      "OA: 0.9522  | AA:  0.9468  | Kappa:  0.9484  | Time: 16.4\n",
      "[400,  2001] loss: 0.0032744  | loss_wrt: 0.00283  | loss_unl: 0.00374  | learning_rate: 0.00014\n",
      "OA: 0.9522  | AA:  0.9469  | Kappa:  0.9483  | Time: 16.4\n",
      "[420,  2101] loss: 0.0028957  | loss_wrt: 0.00157  | loss_unl: 0.00260  | learning_rate: 0.00012\n",
      "OA: 0.9525  | AA:  0.9472  | Kappa:  0.9486  | Time: 16.4\n",
      "[440,  2201] loss: 0.0025191  | loss_wrt: 0.00146  | loss_unl: 0.00253  | learning_rate: 0.00011\n",
      "OA: 0.9532  | AA:  0.9479  | Kappa:  0.9494  | Time: 16.4\n",
      "[460,  2301] loss: 0.0023159  | loss_wrt: 0.00158  | loss_unl: 0.00219  | learning_rate: 0.00010\n",
      "OA: 0.9531  | AA:  0.9475  | Kappa:  0.9493  | Time: 16.4\n",
      "[480,  2401] loss: 0.0021252  | loss_wrt: 0.00139  | loss_unl: 0.00205  | learning_rate: 0.00009\n",
      "OA: 0.9530  | AA:  0.9476  | Kappa:  0.9491  | Time: 16.4\n",
      "[500,  2501] loss: 0.0019925  | loss_wrt: 0.00165  | loss_unl: 0.00173  | learning_rate: 0.00008\n",
      "OA: 0.9536  | AA:  0.9479  | Kappa:  0.9498  | Time: 16.4\n",
      "Finished Training\n",
      "(12774, 2)\n",
      "[0.95296331 0.99061914 0.98986486 0.95175024 1.         0.79347826\n",
      " 0.99165121 0.81267739 0.97838346 0.98082454 0.96571429 0.92366412\n",
      " 0.93483709 1.         0.95187166]\n",
      "0.9535775794582746 0.9478866377957792 0.9498066045534457\n",
      "(664845, 2)\n",
      "649816\n",
      "6498\n",
      "Finished!\n",
      "751\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2177006  | loss_wrt: 0.15135  | loss_unl: 0.17975  | learning_rate: 0.00050\n",
      "OA: 0.7831  | AA:  0.7928  | Kappa:  0.7654  | Time: 18.3\n",
      "[100,   201] loss: 0.3686577  | loss_wrt: 0.11794  | loss_unl: 0.13355  | learning_rate: 0.00050\n",
      "OA: 0.8149  | AA:  0.8252  | Kappa:  0.7999  | Time: 16.7\n",
      "[150,   301] loss: 0.2910273  | loss_wrt: 0.08508  | loss_unl: 0.11437  | learning_rate: 0.00050\n",
      "OA: 0.8688  | AA:  0.8814  | Kappa:  0.8582  | Time: 16.7\n",
      "[200,   401] loss: 0.2134359  | loss_wrt: 0.07459  | loss_unl: 0.09883  | learning_rate: 0.00050\n",
      "OA: 0.8774  | AA:  0.8847  | Kappa:  0.8675  | Time: 16.7\n",
      "[250,   501] loss: 0.1362973  | loss_wrt: 0.05398  | loss_unl: 0.06767  | learning_rate: 0.00050\n",
      "OA: 0.8748  | AA:  0.8849  | Kappa:  0.8647  | Time: 16.7\n",
      "[300,   601] loss: 0.0935753  | loss_wrt: 0.06106  | loss_unl: 0.08014  | learning_rate: 0.00050\n",
      "OA: 0.8584  | AA:  0.8716  | Kappa:  0.8469  | Time: 16.7\n",
      "[350,   701] loss: 0.1106382  | loss_wrt: 0.03982  | loss_unl: 0.05318  | learning_rate: 0.00050\n",
      "OA: 0.8729  | AA:  0.8823  | Kappa:  0.8626  | Time: 16.7\n",
      "[400,   801] loss: 0.0856749  | loss_wrt: 0.02402  | loss_unl: 0.03966  | learning_rate: 0.00050\n",
      "OA: 0.8787  | AA:  0.8887  | Kappa:  0.8690  | Time: 16.7\n",
      "[450,   901] loss: 0.0588984  | loss_wrt: 0.01941  | loss_unl: 0.03607  | learning_rate: 0.00050\n",
      "OA: 0.8805  | AA:  0.8884  | Kappa:  0.8709  | Time: 16.7\n",
      "[500,  1001] loss: 0.0608593  | loss_wrt: 0.04133  | loss_unl: 0.05667  | learning_rate: 0.00050\n",
      "OA: 0.8516  | AA:  0.8639  | Kappa:  0.8396  | Time: 16.7\n",
      "[550,  1101] loss: 0.0482411  | loss_wrt: 0.01761  | loss_unl: 0.02819  | learning_rate: 0.00045\n",
      "OA: 0.8719  | AA:  0.8832  | Kappa:  0.8617  | Time: 16.7\n",
      "[600,  1201] loss: 0.0530555  | loss_wrt: 0.01720  | loss_unl: 0.03126  | learning_rate: 0.00045\n",
      "OA: 0.8690  | AA:  0.8781  | Kappa:  0.8583  | Time: 16.7\n",
      "[650,  1301] loss: 0.1004362  | loss_wrt: 0.02015  | loss_unl: 0.03005  | learning_rate: 0.00045\n",
      "OA: 0.8782  | AA:  0.8900  | Kappa:  0.8684  | Time: 16.7\n",
      "[700,  1401] loss: 0.0741254  | loss_wrt: 0.02475  | loss_unl: 0.03349  | learning_rate: 0.00045\n",
      "OA: 0.8813  | AA:  0.8863  | Kappa:  0.8717  | Time: 16.7\n",
      "[750,  1501] loss: 0.0280062  | loss_wrt: 0.01348  | loss_unl: 0.02541  | learning_rate: 0.00045\n",
      "OA: 0.8889  | AA:  0.9012  | Kappa:  0.8800  | Time: 16.7\n",
      "[800,  1601] loss: 0.0372923  | loss_wrt: 0.01565  | loss_unl: 0.02600  | learning_rate: 0.00045\n",
      "OA: 0.8781  | AA:  0.8863  | Kappa:  0.8683  | Time: 16.7\n",
      "[850,  1701] loss: 0.0603223  | loss_wrt: 0.01858  | loss_unl: 0.03030  | learning_rate: 0.00045\n",
      "OA: 0.8674  | AA:  0.8799  | Kappa:  0.8567  | Time: 16.7\n",
      "[900,  1801] loss: 0.0178026  | loss_wrt: 0.00937  | loss_unl: 0.01911  | learning_rate: 0.00045\n",
      "OA: 0.8974  | AA:  0.9079  | Kappa:  0.8891  | Time: 17.2\n",
      "[950,  1901] loss: 0.0338850  | loss_wrt: 0.01114  | loss_unl: 0.01992  | learning_rate: 0.00045\n",
      "OA: 0.8812  | AA:  0.8934  | Kappa:  0.8716  | Time: 17.2\n",
      "[1000,  2001] loss: 0.0378788  | loss_wrt: 0.01762  | loss_unl: 0.02714  | learning_rate: 0.00045\n",
      "OA: 0.8467  | AA:  0.8396  | Kappa:  0.8341  | Time: 17.3\n",
      "[1050,  2101] loss: 0.0659642  | loss_wrt: 0.01202  | loss_unl: 0.02315  | learning_rate: 0.00041\n",
      "OA: 0.8814  | AA:  0.8965  | Kappa:  0.8719  | Time: 17.1\n",
      "[1100,  2201] loss: 0.0455760  | loss_wrt: 0.01227  | loss_unl: 0.02732  | learning_rate: 0.00041\n",
      "OA: 0.8722  | AA:  0.8806  | Kappa:  0.8618  | Time: 17.1\n",
      "[1150,  2301] loss: 0.0194691  | loss_wrt: 0.00758  | loss_unl: 0.01608  | learning_rate: 0.00041\n",
      "OA: 0.8885  | AA:  0.8998  | Kappa:  0.8795  | Time: 17.2\n",
      "[1200,  2401] loss: 0.0527610  | loss_wrt: 0.00993  | loss_unl: 0.01949  | learning_rate: 0.00041\n",
      "OA: 0.8859  | AA:  0.8937  | Kappa:  0.8766  | Time: 17.4\n",
      "[1250,  2501] loss: 0.0321725  | loss_wrt: 0.01034  | loss_unl: 0.01696  | learning_rate: 0.00041\n",
      "OA: 0.8955  | AA:  0.9024  | Kappa:  0.8870  | Time: 17.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300,  2601] loss: 0.0205702  | loss_wrt: 0.00804  | loss_unl: 0.01397  | learning_rate: 0.00041\n",
      "OA: 0.8928  | AA:  0.9037  | Kappa:  0.8842  | Time: 16.9\n",
      "[1350,  2701] loss: 0.0188041  | loss_wrt: 0.00672  | loss_unl: 0.01399  | learning_rate: 0.00041\n",
      "OA: 0.8989  | AA:  0.9085  | Kappa:  0.8907  | Time: 16.9\n",
      "[1400,  2801] loss: 0.0095571  | loss_wrt: 0.00362  | loss_unl: 0.00985  | learning_rate: 0.00041\n",
      "OA: 0.8947  | AA:  0.9052  | Kappa:  0.8862  | Time: 17.0\n",
      "[1450,  2901] loss: 0.0480756  | loss_wrt: 0.00934  | loss_unl: 0.01443  | learning_rate: 0.00041\n",
      "OA: 0.8788  | AA:  0.8859  | Kappa:  0.8690  | Time: 17.1\n",
      "[1500,  3001] loss: 0.0546918  | loss_wrt: 0.00746  | loss_unl: 0.01857  | learning_rate: 0.00041\n",
      "OA: 0.8914  | AA:  0.9041  | Kappa:  0.8826  | Time: 17.0\n",
      "[1550,  3101] loss: 0.0432419  | loss_wrt: 0.00693  | loss_unl: 0.01175  | learning_rate: 0.00036\n",
      "OA: 0.8945  | AA:  0.9045  | Kappa:  0.8859  | Time: 16.9\n",
      "[1600,  3201] loss: 0.0163934  | loss_wrt: 0.00495  | loss_unl: 0.01227  | learning_rate: 0.00036\n",
      "OA: 0.8949  | AA:  0.9075  | Kappa:  0.8865  | Time: 17.0\n",
      "[1650,  3301] loss: 0.0256148  | loss_wrt: 0.00621  | loss_unl: 0.01463  | learning_rate: 0.00036\n",
      "OA: 0.8921  | AA:  0.9021  | Kappa:  0.8834  | Time: 17.0\n",
      "[1700,  3401] loss: 0.0101709  | loss_wrt: 0.00396  | loss_unl: 0.01034  | learning_rate: 0.00036\n",
      "OA: 0.8950  | AA:  0.9059  | Kappa:  0.8865  | Time: 16.8\n",
      "[1750,  3501] loss: 0.0192915  | loss_wrt: 0.00509  | loss_unl: 0.01131  | learning_rate: 0.00036\n",
      "OA: 0.9061  | AA:  0.9178  | Kappa:  0.8985  | Time: 16.8\n",
      "[1800,  3601] loss: 0.0148686  | loss_wrt: 0.00489  | loss_unl: 0.01202  | learning_rate: 0.00036\n",
      "OA: 0.8928  | AA:  0.9059  | Kappa:  0.8841  | Time: 16.8\n",
      "[1850,  3701] loss: 0.0126735  | loss_wrt: 0.00822  | loss_unl: 0.00958  | learning_rate: 0.00036\n",
      "OA: 0.8829  | AA:  0.8924  | Kappa:  0.8734  | Time: 16.9\n",
      "[1900,  3801] loss: 0.0433444  | loss_wrt: 0.00400  | loss_unl: 0.00983  | learning_rate: 0.00036\n",
      "OA: 0.8931  | AA:  0.9040  | Kappa:  0.8844  | Time: 17.1\n",
      "[1950,  3901] loss: 0.0360836  | loss_wrt: 0.00759  | loss_unl: 0.01699  | learning_rate: 0.00036\n",
      "OA: 0.8691  | AA:  0.8860  | Kappa:  0.8585  | Time: 17.1\n",
      "[2000,  4001] loss: 0.0169649  | loss_wrt: 0.00558  | loss_unl: 0.01053  | learning_rate: 0.00036\n",
      "OA: 0.8917  | AA:  0.9057  | Kappa:  0.8830  | Time: 17.1\n",
      "Finished Training\n",
      "model saved\n",
      "[0.96613358 0.815197   0.99324324 0.80605487 0.99242424 0.9384058\n",
      " 0.90538033 0.79091769 0.90601504 0.85330777 0.86       0.88072519\n",
      " 0.9197995  1.         0.9714795 ]\n",
      "0.8932988883669954 0.9066055838020955 0.8846839025277945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([376, 144, 31, 31]) torch.Size([376, 144, 31, 31])\n",
      "=> all bands acc: 0.445\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -8.39 | loss:0.446 | 100 bands | 9.2s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -8.08 | loss:0.445 | 100 bands | 5.6s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -7.74 | loss:0.444 | 100 bands | 5.6s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -7.63 | loss:0.444 | 100 bands | 5.6s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -7.59 | loss:0.447 | 100 bands | 5.7s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -7.50 | loss:0.444 | 100 bands | 5.6s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -7.76 | loss:0.441 | 100 bands | 5.7s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -7.71 | loss:0.438 | 100 bands | 5.7s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -7.61 | loss:0.442 | 100 bands | 5.6s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -7.55 | loss:0.444 | 100 bands | 5.7s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -7.50 | loss:0.441 | 100 bands | 5.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -7.49 | loss:0.446 | 100 bands | 5.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -7.51 | loss:0.433 | 100 bands | 5.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -7.73 | loss:0.436 | 100 bands | 5.6s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -7.65 | loss:0.439 | 100 bands | 5.6s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -7.53 | loss:0.443 | 100 bands | 5.6s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -7.50 | loss:0.448 | 100 bands | 5.8s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -7.51 | loss:0.442 | 100 bands | 5.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -7.46 | loss:0.439 | 100 bands | 5.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -7.72 | loss:0.442 | 100 bands | 5.7s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -7.71 | loss:0.442 | 100 bands | 5.6s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -7.50 | loss:0.443 | 100 bands | 5.6s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -7.47 | loss:0.441 | 100 bands | 5.7s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -7.40 | loss:0.435 | 100 bands | 5.8s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -7.38 | loss:0.438 | 100 bands | 5.8s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -7.51 | loss:0.437 | 100 bands | 5.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -7.42 | loss:0.435 | 100 bands | 5.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -7.43 | loss:0.434 | 100 bands | 5.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -7.55 | loss:0.437 | 100 bands | 5.7s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -7.53 | loss:0.444 | 100 bands | 5.7s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -7.42 | loss:0.440 | 100 bands | 5.7s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -7.55 | loss:0.441 | 100 bands | 5.8s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -7.43 | loss:0.437 | 100 bands | 5.8s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -7.41 | loss:0.438 | 100 bands | 6.0s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -7.26 | loss:0.438 | 100 bands | 5.9s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -7.28 | loss:0.437 | 100 bands | 5.9s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -7.12 | loss:0.436 | 100 bands | 5.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -7.15 | loss:0.441 | 100 bands | 5.8s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -7.00 | loss:0.435 | 100 bands | 5.7s\n",
      "r_max, 0.4319838325973251\n",
      "Done\n",
      "time :231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 18:31:36.997531: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 18:31:37.000799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 18:31:37.000980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 18:31:37.446494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 18:31:37.446594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 18:31:37.446641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 18:31:37.446842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[20,   101] loss: 1.2448322  | loss_wrt: 0.14938  | loss_unl: 0.15078  | learning_rate: 0.00100\n",
      "OA: 0.8709  | AA:  0.8847  | Kappa:  0.8604  | Time: 16.6\n",
      "[40,   201] loss: 0.2372917  | loss_wrt: 0.09112  | loss_unl: 0.09779  | learning_rate: 0.00090\n",
      "OA: 0.9467  | AA:  0.9503  | Kappa:  0.9424  | Time: 16.5\n",
      "[60,   301] loss: 0.1166685  | loss_wrt: 0.06610  | loss_unl: 0.07658  | learning_rate: 0.00081\n",
      "OA: 0.9578  | AA:  0.9601  | Kappa:  0.9544  | Time: 16.4\n",
      "[80,   401] loss: 0.0750658  | loss_wrt: 0.04896  | loss_unl: 0.05428  | learning_rate: 0.00073\n",
      "OA: 0.9479  | AA:  0.9470  | Kappa:  0.9436  | Time: 16.4\n",
      "[100,   501] loss: 0.0563063  | loss_wrt: 0.03200  | loss_unl: 0.04157  | learning_rate: 0.00066\n",
      "OA: 0.9642  | AA:  0.9669  | Kappa:  0.9613  | Time: 16.4\n",
      "[120,   601] loss: 0.0315193  | loss_wrt: 0.01856  | loss_unl: 0.02626  | learning_rate: 0.00059\n",
      "OA: 0.9657  | AA:  0.9682  | Kappa:  0.9629  | Time: 16.5\n",
      "[140,   701] loss: 0.0528639  | loss_wrt: 0.05803  | loss_unl: 0.06777  | learning_rate: 0.00053\n",
      "OA: 0.9170  | AA:  0.9162  | Kappa:  0.9103  | Time: 16.4\n",
      "[160,   801] loss: 0.0508193  | loss_wrt: 0.02067  | loss_unl: 0.02769  | learning_rate: 0.00048\n",
      "OA: 0.9664  | AA:  0.9678  | Kappa:  0.9637  | Time: 16.4\n",
      "[180,   901] loss: 0.0229421  | loss_wrt: 0.01543  | loss_unl: 0.02309  | learning_rate: 0.00043\n",
      "OA: 0.9673  | AA:  0.9688  | Kappa:  0.9646  | Time: 16.4\n",
      "[200,  1001] loss: 0.0173956  | loss_wrt: 0.01059  | loss_unl: 0.01631  | learning_rate: 0.00039\n",
      "OA: 0.9680  | AA:  0.9697  | Kappa:  0.9654  | Time: 16.4\n",
      "[220,  1101] loss: 0.0221614  | loss_wrt: 0.02024  | loss_unl: 0.02131  | learning_rate: 0.00035\n",
      "OA: 0.9663  | AA:  0.9686  | Kappa:  0.9635  | Time: 16.4\n",
      "[240,  1201] loss: 0.0152932  | loss_wrt: 0.00820  | loss_unl: 0.01652  | learning_rate: 0.00031\n",
      "OA: 0.9692  | AA:  0.9712  | Kappa:  0.9667  | Time: 16.4\n",
      "[260,  1301] loss: 0.0111318  | loss_wrt: 0.00647  | loss_unl: 0.01136  | learning_rate: 0.00028\n",
      "OA: 0.9685  | AA:  0.9704  | Kappa:  0.9660  | Time: 16.4\n",
      "[280,  1401] loss: 0.0094270  | loss_wrt: 0.00616  | loss_unl: 0.00870  | learning_rate: 0.00025\n",
      "OA: 0.9690  | AA:  0.9711  | Kappa:  0.9665  | Time: 16.4\n",
      "[300,  1501] loss: 0.0079246  | loss_wrt: 0.00499  | loss_unl: 0.00891  | learning_rate: 0.00023\n",
      "OA: 0.9688  | AA:  0.9711  | Kappa:  0.9663  | Time: 16.4\n",
      "[320,  1601] loss: 0.0070467  | loss_wrt: 0.00524  | loss_unl: 0.00557  | learning_rate: 0.00021\n",
      "OA: 0.9685  | AA:  0.9706  | Kappa:  0.9659  | Time: 16.4\n",
      "[340,  1701] loss: 0.0058689  | loss_wrt: 0.00334  | loss_unl: 0.00630  | learning_rate: 0.00019\n",
      "OA: 0.9692  | AA:  0.9713  | Kappa:  0.9667  | Time: 16.4\n",
      "[360,  1801] loss: 0.0051740  | loss_wrt: 0.00349  | loss_unl: 0.00572  | learning_rate: 0.00017\n",
      "OA: 0.9681  | AA:  0.9696  | Kappa:  0.9656  | Time: 16.4\n",
      "[380,  1901] loss: 0.0043253  | loss_wrt: 0.00254  | loss_unl: 0.00467  | learning_rate: 0.00015\n",
      "OA: 0.9684  | AA:  0.9701  | Kappa:  0.9658  | Time: 16.4\n",
      "[400,  2001] loss: 0.0041652  | loss_wrt: 0.00366  | loss_unl: 0.00378  | learning_rate: 0.00014\n",
      "OA: 0.9688  | AA:  0.9707  | Kappa:  0.9663  | Time: 16.4\n",
      "[420,  2101] loss: 0.0033708  | loss_wrt: 0.00265  | loss_unl: 0.00305  | learning_rate: 0.00012\n",
      "OA: 0.9703  | AA:  0.9715  | Kappa:  0.9679  | Time: 16.4\n",
      "[440,  2201] loss: 0.0030481  | loss_wrt: 0.00166  | loss_unl: 0.00298  | learning_rate: 0.00011\n",
      "OA: 0.9699  | AA:  0.9708  | Kappa:  0.9675  | Time: 16.4\n",
      "[460,  2301] loss: 0.0027735  | loss_wrt: 0.00160  | loss_unl: 0.00285  | learning_rate: 0.00010\n",
      "OA: 0.9701  | AA:  0.9716  | Kappa:  0.9677  | Time: 16.4\n",
      "[480,  2401] loss: 0.0025424  | loss_wrt: 0.00205  | loss_unl: 0.00267  | learning_rate: 0.00009\n",
      "OA: 0.9708  | AA:  0.9721  | Kappa:  0.9684  | Time: 16.4\n",
      "[500,  2501] loss: 0.0023051  | loss_wrt: 0.00146  | loss_unl: 0.00227  | learning_rate: 0.00008\n",
      "OA: 0.9697  | AA:  0.9702  | Kappa:  0.9672  | Time: 16.4\n",
      "Finished Training\n",
      "(12774, 2)\n",
      "[0.9943556  0.98217636 0.99324324 0.92904447 0.99905303 0.94565217\n",
      " 0.9703154  0.88836329 0.99342105 0.97027804 0.99333333 0.96087786\n",
      " 0.95739348 1.         0.97504456]\n",
      "0.969704086425552 0.9701701267596899 0.967247278588452\n",
      "(664845, 2)\n",
      "649816\n",
      "6498\n",
      "Finished!\n",
      "751\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2819104  | loss_wrt: 0.14799  | loss_unl: 0.19624  | learning_rate: 0.00050\n",
      "OA: 0.7698  | AA:  0.7684  | Kappa:  0.7511  | Time: 18.2\n",
      "[100,   201] loss: 0.4192396  | loss_wrt: 0.11244  | loss_unl: 0.13755  | learning_rate: 0.00050\n",
      "OA: 0.8365  | AA:  0.8397  | Kappa:  0.8233  | Time: 16.7\n",
      "[150,   301] loss: 0.2267115  | loss_wrt: 0.08707  | loss_unl: 0.11711  | learning_rate: 0.00050\n",
      "OA: 0.8299  | AA:  0.8208  | Kappa:  0.8159  | Time: 16.7\n",
      "[200,   401] loss: 0.2410787  | loss_wrt: 0.06692  | loss_unl: 0.09454  | learning_rate: 0.00050\n",
      "OA: 0.8708  | AA:  0.8713  | Kappa:  0.8603  | Time: 16.7\n",
      "[250,   501] loss: 0.1544959  | loss_wrt: 0.06039  | loss_unl: 0.08309  | learning_rate: 0.00050\n",
      "OA: 0.8578  | AA:  0.8577  | Kappa:  0.8461  | Time: 16.7\n",
      "[300,   601] loss: 0.1033941  | loss_wrt: 0.05684  | loss_unl: 0.06788  | learning_rate: 0.00050\n",
      "OA: 0.8654  | AA:  0.8552  | Kappa:  0.8543  | Time: 16.7\n",
      "[350,   701] loss: 0.1919070  | loss_wrt: 0.06144  | loss_unl: 0.07054  | learning_rate: 0.00050\n",
      "OA: 0.8778  | AA:  0.8765  | Kappa:  0.8678  | Time: 16.7\n",
      "[400,   801] loss: 0.0919433  | loss_wrt: 0.03613  | loss_unl: 0.04483  | learning_rate: 0.00050\n",
      "OA: 0.8913  | AA:  0.8854  | Kappa:  0.8824  | Time: 16.8\n",
      "[450,   901] loss: 0.0767561  | loss_wrt: 0.02734  | loss_unl: 0.04424  | learning_rate: 0.00050\n",
      "OA: 0.8859  | AA:  0.8784  | Kappa:  0.8765  | Time: 16.7\n",
      "[500,  1001] loss: 0.0904064  | loss_wrt: 0.03882  | loss_unl: 0.04837  | learning_rate: 0.00050\n",
      "OA: 0.8690  | AA:  0.8574  | Kappa:  0.8583  | Time: 16.7\n",
      "[550,  1101] loss: 0.0625760  | loss_wrt: 0.01995  | loss_unl: 0.02998  | learning_rate: 0.00045\n",
      "OA: 0.8953  | AA:  0.8913  | Kappa:  0.8867  | Time: 16.7\n",
      "[600,  1201] loss: 0.0829726  | loss_wrt: 0.03414  | loss_unl: 0.04380  | learning_rate: 0.00045\n",
      "OA: 0.8634  | AA:  0.8629  | Kappa:  0.8523  | Time: 16.7\n",
      "[650,  1301] loss: 0.0500851  | loss_wrt: 0.02249  | loss_unl: 0.05047  | learning_rate: 0.00045\n",
      "OA: 0.8758  | AA:  0.8724  | Kappa:  0.8656  | Time: 16.7\n",
      "[700,  1401] loss: 0.0267030  | loss_wrt: 0.01512  | loss_unl: 0.02115  | learning_rate: 0.00045\n",
      "OA: 0.8924  | AA:  0.8894  | Kappa:  0.8837  | Time: 16.8\n",
      "[750,  1501] loss: 0.0509336  | loss_wrt: 0.01985  | loss_unl: 0.03088  | learning_rate: 0.00045\n",
      "OA: 0.8603  | AA:  0.8623  | Kappa:  0.8490  | Time: 16.7\n",
      "[800,  1601] loss: 0.0500831  | loss_wrt: 0.01841  | loss_unl: 0.02874  | learning_rate: 0.00045\n",
      "OA: 0.8793  | AA:  0.8769  | Kappa:  0.8694  | Time: 16.7\n",
      "[850,  1701] loss: 0.0460104  | loss_wrt: 0.02224  | loss_unl: 0.02939  | learning_rate: 0.00045\n",
      "OA: 0.8807  | AA:  0.8749  | Kappa:  0.8709  | Time: 16.7\n",
      "[900,  1801] loss: 0.0515089  | loss_wrt: 0.02681  | loss_unl: 0.03636  | learning_rate: 0.00045\n",
      "OA: 0.8690  | AA:  0.8720  | Kappa:  0.8583  | Time: 16.8\n",
      "[950,  1901] loss: 0.0350886  | loss_wrt: 0.01232  | loss_unl: 0.01992  | learning_rate: 0.00045\n",
      "OA: 0.8875  | AA:  0.8845  | Kappa:  0.8783  | Time: 16.8\n",
      "[1000,  2001] loss: 0.0266888  | loss_wrt: 0.01480  | loss_unl: 0.02110  | learning_rate: 0.00045\n",
      "OA: 0.8929  | AA:  0.8857  | Kappa:  0.8842  | Time: 16.7\n",
      "[1050,  2101] loss: 0.0240603  | loss_wrt: 0.01440  | loss_unl: 0.02353  | learning_rate: 0.00041\n",
      "OA: 0.8805  | AA:  0.8783  | Kappa:  0.8708  | Time: 16.8\n",
      "[1100,  2201] loss: 0.0268908  | loss_wrt: 0.00804  | loss_unl: 0.01496  | learning_rate: 0.00041\n",
      "OA: 0.8989  | AA:  0.8921  | Kappa:  0.8906  | Time: 16.7\n",
      "[1150,  2301] loss: 0.0329795  | loss_wrt: 0.00812  | loss_unl: 0.01342  | learning_rate: 0.00041\n",
      "OA: 0.8940  | AA:  0.8899  | Kappa:  0.8854  | Time: 16.8\n",
      "[1200,  2401] loss: 0.0759848  | loss_wrt: 0.01077  | loss_unl: 0.01719  | learning_rate: 0.00041\n",
      "OA: 0.8708  | AA:  0.8741  | Kappa:  0.8602  | Time: 16.7\n",
      "[1250,  2501] loss: 0.0337763  | loss_wrt: 0.00936  | loss_unl: 0.01335  | learning_rate: 0.00041\n",
      "OA: 0.8957  | AA:  0.8932  | Kappa:  0.8872  | Time: 16.8\n",
      "[1300,  2601] loss: 0.0720408  | loss_wrt: 0.01081  | loss_unl: 0.01639  | learning_rate: 0.00041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OA: 0.8827  | AA:  0.8829  | Kappa:  0.8731  | Time: 16.8\n",
      "[1350,  2701] loss: 0.0304894  | loss_wrt: 0.00808  | loss_unl: 0.01481  | learning_rate: 0.00041\n",
      "OA: 0.8743  | AA:  0.8704  | Kappa:  0.8640  | Time: 16.8\n",
      "[1400,  2801] loss: 0.0347614  | loss_wrt: 0.00780  | loss_unl: 0.01795  | learning_rate: 0.00041\n",
      "OA: 0.8861  | AA:  0.8797  | Kappa:  0.8768  | Time: 16.7\n",
      "[1450,  2901] loss: 0.0250747  | loss_wrt: 0.00790  | loss_unl: 0.01396  | learning_rate: 0.00041\n",
      "OA: 0.8906  | AA:  0.8855  | Kappa:  0.8816  | Time: 16.8\n",
      "[1500,  3001] loss: 0.0449480  | loss_wrt: 0.01283  | loss_unl: 0.01813  | learning_rate: 0.00041\n",
      "OA: 0.8605  | AA:  0.8622  | Kappa:  0.8491  | Time: 16.7\n",
      "[1550,  3101] loss: 0.0286695  | loss_wrt: 0.00763  | loss_unl: 0.01047  | learning_rate: 0.00036\n",
      "OA: 0.8926  | AA:  0.8870  | Kappa:  0.8838  | Time: 16.7\n",
      "[1600,  3201] loss: 0.0483757  | loss_wrt: 0.01271  | loss_unl: 0.01990  | learning_rate: 0.00036\n",
      "OA: 0.8714  | AA:  0.8730  | Kappa:  0.8609  | Time: 16.7\n",
      "[1650,  3301] loss: 0.0140178  | loss_wrt: 0.00567  | loss_unl: 0.01085  | learning_rate: 0.00036\n",
      "OA: 0.8875  | AA:  0.8856  | Kappa:  0.8783  | Time: 16.7\n",
      "[1700,  3401] loss: 0.0178460  | loss_wrt: 0.00766  | loss_unl: 0.01330  | learning_rate: 0.00036\n",
      "OA: 0.8902  | AA:  0.8894  | Kappa:  0.8812  | Time: 16.7\n",
      "[1750,  3501] loss: 0.0215338  | loss_wrt: 0.00872  | loss_unl: 0.01401  | learning_rate: 0.00036\n",
      "OA: 0.8894  | AA:  0.8907  | Kappa:  0.8804  | Time: 16.7\n",
      "[1800,  3601] loss: 0.0402270  | loss_wrt: 0.00838  | loss_unl: 0.01012  | learning_rate: 0.00036\n",
      "OA: 0.8898  | AA:  0.8872  | Kappa:  0.8808  | Time: 16.6\n",
      "[1850,  3701] loss: 0.0226070  | loss_wrt: 0.00505  | loss_unl: 0.02183  | learning_rate: 0.00036\n",
      "OA: 0.8917  | AA:  0.8900  | Kappa:  0.8829  | Time: 16.6\n",
      "[1900,  3801] loss: 0.0298702  | loss_wrt: 0.00799  | loss_unl: 0.01402  | learning_rate: 0.00036\n",
      "OA: 0.8843  | AA:  0.8814  | Kappa:  0.8748  | Time: 16.6\n",
      "[1950,  3901] loss: 0.0138039  | loss_wrt: 0.00466  | loss_unl: 0.00877  | learning_rate: 0.00036\n",
      "OA: 0.8976  | AA:  0.8947  | Kappa:  0.8892  | Time: 16.7\n",
      "[2000,  4001] loss: 0.0156470  | loss_wrt: 0.01000  | loss_unl: 0.00879  | learning_rate: 0.00036\n",
      "OA: 0.8883  | AA:  0.8860  | Kappa:  0.8792  | Time: 16.6\n",
      "Finished Training\n",
      "model saved\n",
      "[0.93414864 0.78705441 0.98310811 0.94134342 0.94128788 0.65942029\n",
      " 0.91558442 0.80227058 0.83834586 0.88302972 0.90857143 0.92557252\n",
      " 0.87218045 0.98901099 0.98217469]\n",
      "0.8936903084390168 0.8908735601092055 0.8850130143670794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([376, 144, 31, 31]) torch.Size([376, 144, 31, 31])\n",
      "=> all bands acc: 0.427\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -7.79 | loss:0.426 | 100 bands | 9.0s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -7.67 | loss:0.425 | 100 bands | 5.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -7.63 | loss:0.426 | 100 bands | 5.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -7.86 | loss:0.423 | 100 bands | 5.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -7.93 | loss:0.430 | 100 bands | 5.5s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -8.15 | loss:0.425 | 100 bands | 5.6s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -8.04 | loss:0.427 | 100 bands | 5.5s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -7.94 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -7.78 | loss:0.424 | 100 bands | 5.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -7.57 | loss:0.431 | 100 bands | 5.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -7.32 | loss:0.426 | 100 bands | 5.4s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -7.43 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -7.44 | loss:0.428 | 100 bands | 5.5s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -7.52 | loss:0.424 | 100 bands | 5.5s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -7.56 | loss:0.423 | 100 bands | 5.5s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -7.49 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -7.75 | loss:0.427 | 100 bands | 5.6s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -7.53 | loss:0.429 | 100 bands | 5.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -7.63 | loss:0.424 | 100 bands | 5.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -7.55 | loss:0.425 | 100 bands | 5.5s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -7.73 | loss:0.419 | 100 bands | 5.6s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -7.55 | loss:0.425 | 100 bands | 5.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -7.45 | loss:0.423 | 100 bands | 5.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -7.23 | loss:0.429 | 100 bands | 5.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -7.25 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -7.12 | loss:0.427 | 100 bands | 5.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -7.15 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -7.09 | loss:0.422 | 100 bands | 5.5s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -7.15 | loss:0.424 | 100 bands | 5.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -7.29 | loss:0.423 | 100 bands | 5.5s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -7.22 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -7.29 | loss:0.417 | 100 bands | 5.6s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -7.34 | loss:0.423 | 100 bands | 5.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -7.31 | loss:0.425 | 100 bands | 5.5s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -7.35 | loss:0.424 | 100 bands | 5.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -7.31 | loss:0.421 | 100 bands | 5.5s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -7.24 | loss:0.421 | 100 bands | 5.5s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -7.15 | loss:0.426 | 100 bands | 5.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -7.09 | loss:0.416 | 100 bands | 5.5s\n",
      "r_max, 0.42125459082308225\n",
      "Done\n",
      "time :224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 18:55:24.620940: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 18:55:24.623724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 18:55:24.623891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 18:55:25.060293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 18:55:25.060393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 18:55:25.060444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 18:55:25.060638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[20,   101] loss: 1.0885882  | loss_wrt: 0.11687  | loss_unl: 0.14258  | learning_rate: 0.00100\n",
      "OA: 0.8953  | AA:  0.8965  | Kappa:  0.8868  | Time: 16.3\n",
      "[40,   201] loss: 0.1838888  | loss_wrt: 0.07084  | loss_unl: 0.08075  | learning_rate: 0.00090\n",
      "OA: 0.9405  | AA:  0.9456  | Kappa:  0.9357  | Time: 16.3\n",
      "[60,   301] loss: 0.1087642  | loss_wrt: 0.05952  | loss_unl: 0.07252  | learning_rate: 0.00081\n",
      "OA: 0.9475  | AA:  0.9496  | Kappa:  0.9433  | Time: 16.3\n",
      "[80,   401] loss: 0.0609120  | loss_wrt: 0.03833  | loss_unl: 0.03648  | learning_rate: 0.00073\n",
      "OA: 0.9557  | AA:  0.9590  | Kappa:  0.9521  | Time: 16.3\n",
      "[100,   501] loss: 0.0618652  | loss_wrt: 0.02939  | loss_unl: 0.03803  | learning_rate: 0.00066\n",
      "OA: 0.9573  | AA:  0.9619  | Kappa:  0.9539  | Time: 16.3\n",
      "[120,   601] loss: 0.0295064  | loss_wrt: 0.01853  | loss_unl: 0.02616  | learning_rate: 0.00059\n",
      "OA: 0.9601  | AA:  0.9637  | Kappa:  0.9568  | Time: 16.3\n",
      "[140,   701] loss: 0.0218510  | loss_wrt: 0.01658  | loss_unl: 0.02387  | learning_rate: 0.00053\n",
      "OA: 0.9595  | AA:  0.9629  | Kappa:  0.9562  | Time: 16.3\n",
      "[160,   801] loss: 0.0162970  | loss_wrt: 0.01189  | loss_unl: 0.01339  | learning_rate: 0.00048\n",
      "OA: 0.9628  | AA:  0.9653  | Kappa:  0.9598  | Time: 16.4\n",
      "[180,   901] loss: 0.0122718  | loss_wrt: 0.00882  | loss_unl: 0.01173  | learning_rate: 0.00043\n",
      "OA: 0.9611  | AA:  0.9634  | Kappa:  0.9579  | Time: 16.3\n",
      "[200,  1001] loss: 0.0097531  | loss_wrt: 0.00566  | loss_unl: 0.01017  | learning_rate: 0.00039\n",
      "OA: 0.9630  | AA:  0.9647  | Kappa:  0.9600  | Time: 16.4\n",
      "[220,  1101] loss: 0.0080394  | loss_wrt: 0.00611  | loss_unl: 0.00856  | learning_rate: 0.00035\n",
      "OA: 0.9627  | AA:  0.9646  | Kappa:  0.9597  | Time: 16.4\n",
      "[240,  1201] loss: 0.0061251  | loss_wrt: 0.00491  | loss_unl: 0.00544  | learning_rate: 0.00031\n",
      "OA: 0.9632  | AA:  0.9653  | Kappa:  0.9602  | Time: 16.4\n",
      "[260,  1301] loss: 0.0050456  | loss_wrt: 0.00407  | loss_unl: 0.00563  | learning_rate: 0.00028\n",
      "OA: 0.9632  | AA:  0.9649  | Kappa:  0.9602  | Time: 16.4\n",
      "[280,  1401] loss: 0.0042152  | loss_wrt: 0.00308  | loss_unl: 0.00407  | learning_rate: 0.00025\n",
      "OA: 0.9635  | AA:  0.9657  | Kappa:  0.9606  | Time: 16.4\n",
      "[300,  1501] loss: 0.0034052  | loss_wrt: 0.00247  | loss_unl: 0.00337  | learning_rate: 0.00023\n",
      "OA: 0.9629  | AA:  0.9653  | Kappa:  0.9599  | Time: 16.4\n",
      "[320,  1601] loss: 0.0029696  | loss_wrt: 0.00271  | loss_unl: 0.00259  | learning_rate: 0.00021\n",
      "OA: 0.9632  | AA:  0.9649  | Kappa:  0.9602  | Time: 16.4\n",
      "[340,  1701] loss: 0.0024821  | loss_wrt: 0.00209  | loss_unl: 0.00266  | learning_rate: 0.00019\n",
      "OA: 0.9636  | AA:  0.9657  | Kappa:  0.9606  | Time: 16.4\n",
      "[360,  1801] loss: 0.0022849  | loss_wrt: 0.00243  | loss_unl: 0.00237  | learning_rate: 0.00017\n",
      "OA: 0.9631  | AA:  0.9655  | Kappa:  0.9601  | Time: 16.4\n",
      "[380,  1901] loss: 0.0019359  | loss_wrt: 0.00184  | loss_unl: 0.00239  | learning_rate: 0.00015\n",
      "OA: 0.9627  | AA:  0.9650  | Kappa:  0.9597  | Time: 16.4\n",
      "[400,  2001] loss: 0.0017059  | loss_wrt: 0.00168  | loss_unl: 0.00125  | learning_rate: 0.00014\n",
      "OA: 0.9633  | AA:  0.9656  | Kappa:  0.9603  | Time: 16.4\n",
      "[420,  2101] loss: 0.0016070  | loss_wrt: 0.00104  | loss_unl: 0.00239  | learning_rate: 0.00012\n",
      "OA: 0.9636  | AA:  0.9662  | Kappa:  0.9606  | Time: 16.4\n",
      "[440,  2201] loss: 0.0015172  | loss_wrt: 0.00091  | loss_unl: 0.00125  | learning_rate: 0.00011\n",
      "OA: 0.9631  | AA:  0.9655  | Kappa:  0.9601  | Time: 16.4\n",
      "[460,  2301] loss: 0.0013940  | loss_wrt: 0.00148  | loss_unl: 0.00142  | learning_rate: 0.00010\n",
      "OA: 0.9633  | AA:  0.9656  | Kappa:  0.9603  | Time: 16.4\n",
      "[480,  2401] loss: 0.0013232  | loss_wrt: 0.00084  | loss_unl: 0.00103  | learning_rate: 0.00009\n",
      "OA: 0.9630  | AA:  0.9655  | Kappa:  0.9601  | Time: 16.4\n",
      "[500,  2501] loss: 0.0012412  | loss_wrt: 0.00122  | loss_unl: 0.00116  | learning_rate: 0.00008\n",
      "OA: 0.9632  | AA:  0.9656  | Kappa:  0.9602  | Time: 16.4\n",
      "Finished Training\n",
      "(12774, 2)\n",
      "[0.94825964 0.96060038 1.         0.96310312 1.         0.96376812\n",
      " 0.96938776 0.96499527 0.93609023 0.97794823 0.93904762 0.93320611\n",
      " 0.9273183  1.         1.        ]\n",
      "0.9632065132299984 0.9655816502643859 0.9602229375362419\n",
      "(664845, 2)\n"
     ]
    }
   ],
   "source": [
    "#count results\n",
    "data_name = \"Houston\"\n",
    "###################################\n",
    "from evaluate_ss import RET\n",
    "results =[]\n",
    "for i in range(5):\n",
    "    !python get_prefile_ss.py --data_name \"Houston\" --pt 0.05 --pv 0.10\n",
    "    !python train_evalnet_ss_v2.py --data_name \"Houston\" \n",
    "    !python A3C_main.py --data_name \"Houston\" --num_band_selection 80 --eval_net_path \"./checkpoint/Houston.t7\" -- out_put_path \"./output/Houston\"\n",
    "    model = RET(data_name)\n",
    "    results.append(model.results)\n",
    "import numpy as np\n",
    "results = np.array(results)\n",
    "avarage = results.mean(axis=0)*100\n",
    "std = results.std(axis=0)*100\n",
    "avg = [\"%.1f±%.1f\"%(avarage[i],std[i])for i in range(avarage.shape[0])]\n",
    "import xlwt\n",
    "import time\n",
    "#创建一个Workbook对象，相当于创建了一个Excel文件\n",
    "book=xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "sheet = book.add_sheet(data_name, cell_overwrite_ok=True)\n",
    "clo_0 = [\"OA\",\"AA\",\"Kappa\"]+list(range(16))\n",
    "row_o = [data_name]+list(range(5))+[\"avg\"]\n",
    "for i in range(len(row_o)):\n",
    "    sheet.write(0, i,row_o[i])\n",
    "for j in range(len(clo_0)):\n",
    "    sheet.write(j+1, 0,clo_0[j])\n",
    "for i in range(len(results)):\n",
    "    for j in range(len(results[0])):\n",
    "        sheet.write(j+1, i+1,results[i][j])\n",
    "for j in range(len(results[0])):\n",
    "    sheet.write(j+1,6,avg[j])\n",
    "book.save(data_name+\"_BSRL_\"+avg[0]+'.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
