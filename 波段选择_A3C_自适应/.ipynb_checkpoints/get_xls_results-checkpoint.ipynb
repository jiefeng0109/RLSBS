{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本脚本用于HDCNN进行对比实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count results\n",
    "data_name = \"Indian_pines\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.3823496  | loss_wrt: 0.15833  | loss_unl: 0.19310  | learning_rate: 0.00050\n",
      "OA: 0.7759  | AA:  0.5768  | Kappa:  0.7448  | Time: 22.4\n",
      "[100,   201] loss: 0.3223661  | loss_wrt: 0.09160  | loss_unl: 0.12840  | learning_rate: 0.00050\n",
      "OA: 0.8409  | AA:  0.7058  | Kappa:  0.8179  | Time: 20.3\n",
      "[150,   301] loss: 0.1424224  | loss_wrt: 0.06714  | loss_unl: 0.08850  | learning_rate: 0.00050\n",
      "OA: 0.8520  | AA:  0.7041  | Kappa:  0.8306  | Time: 20.5\n",
      "[200,   401] loss: 0.1649571  | loss_wrt: 0.06588  | loss_unl: 0.08732  | learning_rate: 0.00050\n",
      "OA: 0.8524  | AA:  0.7172  | Kappa:  0.8312  | Time: 20.6\n",
      "[250,   501] loss: 0.0785716  | loss_wrt: 0.03088  | loss_unl: 0.05412  | learning_rate: 0.00050\n",
      "OA: 0.8738  | AA:  0.7389  | Kappa:  0.8558  | Time: 20.6\n",
      "[300,   601] loss: 0.0908236  | loss_wrt: 0.03398  | loss_unl: 0.05242  | learning_rate: 0.00050\n",
      "OA: 0.8819  | AA:  0.7468  | Kappa:  0.8650  | Time: 20.4\n",
      "[350,   701] loss: 0.0616524  | loss_wrt: 0.02696  | loss_unl: 0.08918  | learning_rate: 0.00050\n",
      "OA: 0.8862  | AA:  0.7569  | Kappa:  0.8697  | Time: 20.4\n",
      "[400,   801] loss: 0.0728651  | loss_wrt: 0.02232  | loss_unl: 0.03882  | learning_rate: 0.00050\n",
      "OA: 0.8828  | AA:  0.7360  | Kappa:  0.8660  | Time: 20.3\n",
      "[450,   901] loss: 0.0561388  | loss_wrt: 0.02109  | loss_unl: 0.03485  | learning_rate: 0.00050\n",
      "OA: 0.8309  | AA:  0.7148  | Kappa:  0.8085  | Time: 20.5\n",
      "[500,  1001] loss: 0.0790846  | loss_wrt: 0.02799  | loss_unl: 0.04001  | learning_rate: 0.00050\n",
      "OA: 0.8885  | AA:  0.7483  | Kappa:  0.8723  | Time: 20.3\n",
      "[550,  1101] loss: 0.0548308  | loss_wrt: 0.02170  | loss_unl: 0.03502  | learning_rate: 0.00045\n",
      "OA: 0.8644  | AA:  0.7164  | Kappa:  0.8450  | Time: 20.4\n",
      "[600,  1201] loss: 0.0447411  | loss_wrt: 0.01295  | loss_unl: 0.02886  | learning_rate: 0.00045\n",
      "OA: 0.8946  | AA:  0.7610  | Kappa:  0.8794  | Time: 20.7\n",
      "[650,  1301] loss: 0.0337166  | loss_wrt: 0.01302  | loss_unl: 0.02466  | learning_rate: 0.00045\n",
      "OA: 0.8774  | AA:  0.7416  | Kappa:  0.8594  | Time: 20.3\n",
      "[700,  1401] loss: 0.0228614  | loss_wrt: 0.00871  | loss_unl: 0.02140  | learning_rate: 0.00045\n",
      "OA: 0.8904  | AA:  0.7585  | Kappa:  0.8745  | Time: 20.6\n",
      "[750,  1501] loss: 0.0167699  | loss_wrt: 0.01031  | loss_unl: 0.02514  | learning_rate: 0.00045\n",
      "OA: 0.8989  | AA:  0.7778  | Kappa:  0.8842  | Time: 20.5\n",
      "[800,  1601] loss: 0.0197953  | loss_wrt: 0.00815  | loss_unl: 0.01705  | learning_rate: 0.00045\n",
      "OA: 0.8984  | AA:  0.7676  | Kappa:  0.8838  | Time: 20.4\n",
      "[850,  1701] loss: 0.0695932  | loss_wrt: 0.01730  | loss_unl: 0.02195  | learning_rate: 0.00045\n",
      "OA: 0.8816  | AA:  0.7434  | Kappa:  0.8643  | Time: 20.4\n",
      "[900,  1801] loss: 0.0425528  | loss_wrt: 0.01580  | loss_unl: 0.02491  | learning_rate: 0.00045\n",
      "OA: 0.8592  | AA:  0.7200  | Kappa:  0.8394  | Time: 20.5\n",
      "[950,  1901] loss: 0.0280030  | loss_wrt: 0.02424  | loss_unl: 0.01620  | learning_rate: 0.00045\n",
      "OA: 0.8997  | AA:  0.7811  | Kappa:  0.8854  | Time: 20.4\n",
      "[1000,  2001] loss: 0.0181616  | loss_wrt: 0.00804  | loss_unl: 0.01546  | learning_rate: 0.00045\n",
      "OA: 0.8896  | AA:  0.7577  | Kappa:  0.8738  | Time: 20.3\n",
      "[1050,  2101] loss: 0.0128167  | loss_wrt: 0.00535  | loss_unl: 0.01374  | learning_rate: 0.00041\n",
      "OA: 0.8990  | AA:  0.7637  | Kappa:  0.8844  | Time: 20.4\n",
      "[1100,  2201] loss: 0.0157763  | loss_wrt: 0.00617  | loss_unl: 0.01150  | learning_rate: 0.00041\n",
      "OA: 0.8974  | AA:  0.7698  | Kappa:  0.8826  | Time: 20.5\n",
      "[1150,  2301] loss: 0.0150226  | loss_wrt: 0.00493  | loss_unl: 0.01119  | learning_rate: 0.00041\n",
      "OA: 0.8949  | AA:  0.7706  | Kappa:  0.8799  | Time: 20.4\n",
      "[1200,  2401] loss: 0.0078968  | loss_wrt: 0.00516  | loss_unl: 0.00943  | learning_rate: 0.00041\n",
      "OA: 0.8991  | AA:  0.7651  | Kappa:  0.8846  | Time: 20.3\n",
      "[1250,  2501] loss: 0.0303143  | loss_wrt: 0.01207  | loss_unl: 0.01675  | learning_rate: 0.00041\n",
      "OA: 0.9005  | AA:  0.7660  | Kappa:  0.8863  | Time: 20.4\n",
      "[1300,  2601] loss: 0.0483105  | loss_wrt: 0.00886  | loss_unl: 0.01248  | learning_rate: 0.00041\n",
      "OA: 0.8879  | AA:  0.7537  | Kappa:  0.8719  | Time: 20.5\n",
      "[1350,  2701] loss: 0.0101452  | loss_wrt: 0.00505  | loss_unl: 0.00896  | learning_rate: 0.00041\n",
      "OA: 0.8579  | AA:  0.7144  | Kappa:  0.8373  | Time: 20.3\n",
      "[1400,  2801] loss: 0.0084210  | loss_wrt: 0.00430  | loss_unl: 0.00971  | learning_rate: 0.00041\n",
      "OA: 0.8931  | AA:  0.7642  | Kappa:  0.8778  | Time: 20.3\n",
      "[1450,  2901] loss: 0.0317881  | loss_wrt: 0.00584  | loss_unl: 0.01196  | learning_rate: 0.00041\n",
      "OA: 0.8804  | AA:  0.7562  | Kappa:  0.8631  | Time: 20.3\n",
      "[1500,  3001] loss: 0.0137254  | loss_wrt: 0.00837  | loss_unl: 0.02579  | learning_rate: 0.00041\n",
      "OA: 0.8899  | AA:  0.7574  | Kappa:  0.8741  | Time: 20.3\n",
      "[1550,  3101] loss: 0.0111479  | loss_wrt: 0.00406  | loss_unl: 0.00911  | learning_rate: 0.00036\n",
      "OA: 0.8978  | AA:  0.7667  | Kappa:  0.8831  | Time: 22.3\n",
      "[1600,  3201] loss: 0.0247534  | loss_wrt: 0.00604  | loss_unl: 0.01066  | learning_rate: 0.00036\n",
      "OA: 0.8972  | AA:  0.7543  | Kappa:  0.8824  | Time: 22.2\n",
      "[1650,  3301] loss: 0.0110515  | loss_wrt: 0.00296  | loss_unl: 0.00699  | learning_rate: 0.00036\n",
      "OA: 0.8939  | AA:  0.7685  | Kappa:  0.8787  | Time: 22.0\n",
      "[1700,  3401] loss: 0.0130125  | loss_wrt: 0.00394  | loss_unl: 0.00596  | learning_rate: 0.00036\n",
      "OA: 0.9000  | AA:  0.7795  | Kappa:  0.8857  | Time: 21.5\n",
      "[1750,  3501] loss: 0.0075538  | loss_wrt: 0.00591  | loss_unl: 0.00901  | learning_rate: 0.00036\n",
      "OA: 0.8912  | AA:  0.7675  | Kappa:  0.8756  | Time: 22.9\n",
      "[1800,  3601] loss: 0.0163992  | loss_wrt: 0.00467  | loss_unl: 0.00937  | learning_rate: 0.00036\n",
      "OA: 0.8994  | AA:  0.7722  | Kappa:  0.8850  | Time: 21.7\n",
      "[1850,  3701] loss: 0.0097484  | loss_wrt: 0.00571  | loss_unl: 0.00824  | learning_rate: 0.00036\n",
      "OA: 0.8969  | AA:  0.7736  | Kappa:  0.8821  | Time: 22.3\n",
      "[1900,  3801] loss: 0.0164847  | loss_wrt: 0.00727  | loss_unl: 0.00984  | learning_rate: 0.00036\n",
      "OA: 0.8877  | AA:  0.7497  | Kappa:  0.8715  | Time: 22.5\n",
      "[1950,  3901] loss: 0.0307488  | loss_wrt: 0.00547  | loss_unl: 0.01001  | learning_rate: 0.00036\n",
      "OA: 0.8901  | AA:  0.7674  | Kappa:  0.8742  | Time: 22.4\n",
      "[2000,  4001] loss: 0.0203744  | loss_wrt: 0.00367  | loss_unl: 0.00759  | learning_rate: 0.00036\n",
      "OA: 0.8914  | AA:  0.7640  | Kappa:  0.8757  | Time: 22.4\n",
      "Finished Training\n",
      "model saved\n",
      "[0.         0.87314662 0.85106383 0.77114428 0.71046229 0.92903226\n",
      " 0.875      0.99753695 0.         0.75544794 0.98802108 0.9047619\n",
      " 0.93103448 0.96837209 0.89939024 0.89873418]\n",
      "0.8978185993111366 0.7720717592846903 0.8830944930959637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([103, 200, 31, 31]) torch.Size([103, 200, 31, 31])\n",
      "=> all bands acc: 0.698\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: 3.98 | loss:0.708 | 109 bands | 8.4s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: 3.45 | loss:0.705 | 57 bands | 3.3s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -0.61 | loss:4.877 | 0 bands | 3.6s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: 0.74 | loss:0.691 | 44 bands | 4.1s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: 2.42 | loss:0.692 | 86 bands | 3.8s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: 2.39 | loss:0.689 | 72 bands | 3.8s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: 3.40 | loss:0.688 | 92 bands | 3.8s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: 3.26 | loss:0.677 | 103 bands | 3.9s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -0.79 | loss:0.677 | 101 bands | 3.7s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: 1.71 | loss:0.671 | 73 bands | 3.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: 3.06 | loss:0.686 | 82 bands | 3.8s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: 3.61 | loss:0.648 | 58 bands | 3.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: 4.45 | loss:0.620 | 48 bands | 3.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -0.03 | loss:0.669 | 73 bands | 3.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: 2.45 | loss:0.668 | 78 bands | 3.8s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: 2.01 | loss:0.645 | 28 bands | 3.3s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: 0.94 | loss:0.660 | 60 bands | 3.7s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -1.30 | loss:0.677 | 12 bands | 3.7s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: 1.87 | loss:0.654 | 84 bands | 3.5s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: 3.37 | loss:0.645 | 33 bands | 3.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: 4.53 | loss:0.667 | 39 bands | 3.2s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: 6.00 | loss:0.572 | 27 bands | 3.1s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: 6.04 | loss:0.635 | 61 bands | 2.9s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: 6.80 | loss:0.631 | 42 bands | 3.3s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: 7.52 | loss:0.628 | 28 bands | 3.1s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: 8.23 | loss:0.597 | 42 bands | 3.1s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: 7.63 | loss:0.605 | 45 bands | 3.0s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: 8.78 | loss:0.552 | 38 bands | 3.1s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: 9.58 | loss:0.596 | 37 bands | 2.9s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: 9.86 | loss:0.615 | 30 bands | 3.3s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: 10.13 | loss:0.602 | 35 bands | 3.2s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: 11.29 | loss:0.520 | 37 bands | 3.0s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: 11.98 | loss:0.542 | 35 bands | 3.2s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: 12.26 | loss:0.646 | 13 bands | 3.1s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: 11.00 | loss:0.939 | 2 bands | 3.1s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: 12.01 | loss:0.501 | 36 bands | 3.3s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: 13.29 | loss:0.550 | 25 bands | 2.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: 13.83 | loss:0.508 | 35 bands | 2.9s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: 14.50 | loss:0.532 | 17 bands | 2.9s\n",
      "r_max, 0.5104912198730744\n",
      "Done\n",
      "time :140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 00:02:53.611896: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-21 00:02:53.615284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-21 00:02:53.615492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-21 00:02:54.171995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-21 00:02:54.172118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-21 00:02:54.172181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-21 00:02:54.172438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.3132852  | loss_wrt: 0.12806  | loss_unl: 0.13044  | learning_rate: 0.00100\n",
      "OA: 0.9256  | AA:  0.7804  | Kappa:  0.9151  | Time: 21.4\n",
      "[50,   201] loss: 0.1436248  | loss_wrt: 0.05540  | loss_unl: 0.07124  | learning_rate: 0.00090\n",
      "OA: 0.9588  | AA:  0.8928  | Kappa:  0.9530  | Time: 19.9\n",
      "[75,   301] loss: 0.0544515  | loss_wrt: 0.02984  | loss_unl: 0.03834  | learning_rate: 0.00081\n",
      "OA: 0.9657  | AA:  0.8960  | Kappa:  0.9609  | Time: 22.0\n",
      "[100,   401] loss: 0.0722402  | loss_wrt: 0.03757  | loss_unl: 0.04358  | learning_rate: 0.00073\n",
      "OA: 0.9673  | AA:  0.9132  | Kappa:  0.9627  | Time: 21.4\n",
      "[125,   501] loss: 0.0338776  | loss_wrt: 0.01814  | loss_unl: 0.03132  | learning_rate: 0.00066\n",
      "OA: 0.9711  | AA:  0.9185  | Kappa:  0.9670  | Time: 21.6\n",
      "[150,   601] loss: 0.0220746  | loss_wrt: 0.01087  | loss_unl: 0.02195  | learning_rate: 0.00059\n",
      "OA: 0.9729  | AA:  0.9270  | Kappa:  0.9691  | Time: 23.8\n",
      "[175,   701] loss: 0.0163456  | loss_wrt: 0.00808  | loss_unl: 0.01621  | learning_rate: 0.00053\n",
      "OA: 0.9753  | AA:  0.9293  | Kappa:  0.9719  | Time: 21.5\n",
      "[200,   801] loss: 0.0128268  | loss_wrt: 0.00707  | loss_unl: 0.01540  | learning_rate: 0.00048\n",
      "OA: 0.9775  | AA:  0.9329  | Kappa:  0.9743  | Time: 20.9\n",
      "[225,   901] loss: 0.0101466  | loss_wrt: 0.00516  | loss_unl: 0.01064  | learning_rate: 0.00043\n",
      "OA: 0.9776  | AA:  0.9418  | Kappa:  0.9745  | Time: 21.6\n",
      "[250,  1001] loss: 0.0084387  | loss_wrt: 0.00484  | loss_unl: 0.00885  | learning_rate: 0.00039\n",
      "OA: 0.9775  | AA:  0.9502  | Kappa:  0.9743  | Time: 21.8\n",
      "[275,  1101] loss: 0.0069770  | loss_wrt: 0.00412  | loss_unl: 0.00912  | learning_rate: 0.00035\n",
      "OA: 0.9777  | AA:  0.9447  | Kappa:  0.9746  | Time: 21.4\n",
      "[300,  1201] loss: 0.0060936  | loss_wrt: 0.00297  | loss_unl: 0.00701  | learning_rate: 0.00031\n",
      "OA: 0.9786  | AA:  0.9455  | Kappa:  0.9756  | Time: 22.0\n",
      "[325,  1301] loss: 0.0050051  | loss_wrt: 0.00243  | loss_unl: 0.00743  | learning_rate: 0.00028\n",
      "OA: 0.9798  | AA:  0.9562  | Kappa:  0.9770  | Time: 21.1\n",
      "[350,  1401] loss: 0.0042022  | loss_wrt: 0.00317  | loss_unl: 0.00597  | learning_rate: 0.00025\n",
      "OA: 0.9808  | AA:  0.9625  | Kappa:  0.9781  | Time: 21.5\n",
      "[375,  1501] loss: 0.0036551  | loss_wrt: 0.00233  | loss_unl: 0.00365  | learning_rate: 0.00023\n",
      "OA: 0.9799  | AA:  0.9599  | Kappa:  0.9771  | Time: 21.4\n",
      "[400,  1601] loss: 0.0031327  | loss_wrt: 0.00175  | loss_unl: 0.00432  | learning_rate: 0.00021\n",
      "OA: 0.9808  | AA:  0.9634  | Kappa:  0.9781  | Time: 21.7\n",
      "[425,  1701] loss: 0.0028153  | loss_wrt: 0.00136  | loss_unl: 0.00318  | learning_rate: 0.00019\n",
      "OA: 0.9811  | AA:  0.9627  | Kappa:  0.9784  | Time: 21.3\n",
      "[450,  1801] loss: 0.0024480  | loss_wrt: 0.00119  | loss_unl: 0.00338  | learning_rate: 0.00017\n",
      "OA: 0.9808  | AA:  0.9621  | Kappa:  0.9781  | Time: 28.5\n",
      "[475,  1901] loss: 0.0022477  | loss_wrt: 0.00116  | loss_unl: 0.00262  | learning_rate: 0.00015\n",
      "OA: 0.9804  | AA:  0.9590  | Kappa:  0.9776  | Time: 27.7\n",
      "[500,  2001] loss: 0.0020736  | loss_wrt: 0.00117  | loss_unl: 0.00274  | learning_rate: 0.00014\n",
      "OA: 0.9806  | AA:  0.9617  | Kappa:  0.9779  | Time: 28.8\n",
      "Finished Training\n",
      "[0.94871795 1.         0.97588652 0.80597015 0.96107056 0.96935484\n",
      " 0.91666667 1.         1.         0.94673123 0.99760422 0.96626984\n",
      " 1.         1.         1.         0.89873418]\n",
      "0.9805970149253731 0.9616878848570065 0.9778729607697857\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1957441  | loss_wrt: 0.15823  | loss_unl: 0.21842  | learning_rate: 0.00050\n",
      "OA: 0.8225  | AA:  0.6611  | Kappa:  0.7967  | Time: 33.3\n",
      "[100,   201] loss: 0.2442240  | loss_wrt: 0.10215  | loss_unl: 0.13289  | learning_rate: 0.00050\n",
      "OA: 0.8364  | AA:  0.7406  | Kappa:  0.8133  | Time: 31.8\n",
      "[150,   301] loss: 0.1679372  | loss_wrt: 0.06356  | loss_unl: 0.10014  | learning_rate: 0.00050\n",
      "OA: 0.8656  | AA:  0.7944  | Kappa:  0.8456  | Time: 33.1\n",
      "[200,   401] loss: 0.0999500  | loss_wrt: 0.03864  | loss_unl: 0.06986  | learning_rate: 0.00050\n",
      "OA: 0.8906  | AA:  0.8225  | Kappa:  0.8751  | Time: 33.3\n",
      "[250,   501] loss: 0.0534121  | loss_wrt: 0.02314  | loss_unl: 0.05232  | learning_rate: 0.00050\n",
      "OA: 0.9017  | AA:  0.8321  | Kappa:  0.8877  | Time: 33.0\n",
      "[300,   601] loss: 0.0401960  | loss_wrt: 0.01877  | loss_unl: 0.03364  | learning_rate: 0.00050\n",
      "OA: 0.9010  | AA:  0.8253  | Kappa:  0.8870  | Time: 37.2\n",
      "[350,   701] loss: 0.0299645  | loss_wrt: 0.01240  | loss_unl: 0.03802  | learning_rate: 0.00050\n",
      "OA: 0.9026  | AA:  0.8410  | Kappa:  0.8889  | Time: 40.8\n",
      "[400,   801] loss: 0.1209472  | loss_wrt: 0.02846  | loss_unl: 0.04209  | learning_rate: 0.00050\n",
      "OA: 0.9072  | AA:  0.8445  | Kappa:  0.8940  | Time: 41.0\n",
      "[450,   901] loss: 0.0445945  | loss_wrt: 0.01633  | loss_unl: 0.03016  | learning_rate: 0.00050\n",
      "OA: 0.8910  | AA:  0.8208  | Kappa:  0.8753  | Time: 41.2\n",
      "[500,  1001] loss: 0.1231392  | loss_wrt: 0.02685  | loss_unl: 0.03800  | learning_rate: 0.00050\n",
      "OA: 0.8843  | AA:  0.7983  | Kappa:  0.8676  | Time: 39.2\n",
      "[550,  1101] loss: 0.0498714  | loss_wrt: 0.01714  | loss_unl: 0.03180  | learning_rate: 0.00045\n",
      "OA: 0.8992  | AA:  0.8328  | Kappa:  0.8848  | Time: 39.8\n",
      "[600,  1201] loss: 0.1063689  | loss_wrt: 0.02226  | loss_unl: 0.03475  | learning_rate: 0.00045\n",
      "OA: 0.8944  | AA:  0.8268  | Kappa:  0.8790  | Time: 39.9\n",
      "[650,  1301] loss: 0.0457668  | loss_wrt: 0.02131  | loss_unl: 0.03496  | learning_rate: 0.00045\n",
      "OA: 0.8946  | AA:  0.8335  | Kappa:  0.8801  | Time: 39.6\n",
      "[700,  1401] loss: 0.0333926  | loss_wrt: 0.01104  | loss_unl: 0.02937  | learning_rate: 0.00045\n",
      "OA: 0.9090  | AA:  0.8362  | Kappa:  0.8960  | Time: 40.5\n",
      "[750,  1501] loss: 0.0461125  | loss_wrt: 0.03851  | loss_unl: 0.03434  | learning_rate: 0.00045\n",
      "OA: 0.8921  | AA:  0.8657  | Kappa:  0.8766  | Time: 39.4\n",
      "[800,  1601] loss: 0.0506556  | loss_wrt: 0.02058  | loss_unl: 0.03285  | learning_rate: 0.00045\n",
      "OA: 0.8968  | AA:  0.8762  | Kappa:  0.8827  | Time: 39.4\n",
      "[850,  1701] loss: 0.0374387  | loss_wrt: 0.01831  | loss_unl: 0.02845  | learning_rate: 0.00045\n",
      "OA: 0.8967  | AA:  0.8351  | Kappa:  0.8823  | Time: 40.6\n",
      "[900,  1801] loss: 0.0279963  | loss_wrt: 0.01676  | loss_unl: 0.02459  | learning_rate: 0.00045\n",
      "OA: 0.8867  | AA:  0.8308  | Kappa:  0.8702  | Time: 40.9\n",
      "[950,  1901] loss: 0.0192810  | loss_wrt: 0.01068  | loss_unl: 0.02413  | learning_rate: 0.00045\n",
      "OA: 0.9067  | AA:  0.8466  | Kappa:  0.8934  | Time: 40.5\n",
      "[1000,  2001] loss: 0.0147056  | loss_wrt: 0.00660  | loss_unl: 0.01275  | learning_rate: 0.00045\n",
      "OA: 0.9082  | AA:  0.8432  | Kappa:  0.8950  | Time: 40.3\n",
      "[1050,  2101] loss: 0.0100752  | loss_wrt: 0.01151  | loss_unl: 0.01384  | learning_rate: 0.00041\n",
      "OA: 0.9108  | AA:  0.8300  | Kappa:  0.8980  | Time: 39.9\n",
      "[1100,  2201] loss: 0.0486099  | loss_wrt: 0.01233  | loss_unl: 0.02000  | learning_rate: 0.00041\n",
      "OA: 0.8963  | AA:  0.8272  | Kappa:  0.8816  | Time: 39.1\n",
      "[1150,  2301] loss: 0.0147417  | loss_wrt: 0.00555  | loss_unl: 0.01174  | learning_rate: 0.00041\n",
      "OA: 0.9106  | AA:  0.8426  | Kappa:  0.8978  | Time: 39.8\n",
      "[1200,  2401] loss: 0.0157873  | loss_wrt: 0.00604  | loss_unl: 0.01170  | learning_rate: 0.00041\n",
      "OA: 0.9100  | AA:  0.8421  | Kappa:  0.8971  | Time: 40.7\n",
      "[1250,  2501] loss: 0.0127676  | loss_wrt: 0.00540  | loss_unl: 0.01470  | learning_rate: 0.00041\n",
      "OA: 0.9087  | AA:  0.8529  | Kappa:  0.8957  | Time: 38.8\n",
      "[1300,  2601] loss: 0.0220223  | loss_wrt: 0.00635  | loss_unl: 0.01203  | learning_rate: 0.00041\n",
      "OA: 0.9060  | AA:  0.8175  | Kappa:  0.8925  | Time: 40.0\n",
      "[1350,  2701] loss: 0.0425052  | loss_wrt: 0.00990  | loss_unl: 0.01344  | learning_rate: 0.00041\n",
      "OA: 0.8976  | AA:  0.7827  | Kappa:  0.8829  | Time: 40.5\n",
      "[1400,  2801] loss: 0.0153901  | loss_wrt: 0.00536  | loss_unl: 0.01083  | learning_rate: 0.00041\n",
      "OA: 0.9022  | AA:  0.8316  | Kappa:  0.8882  | Time: 40.0\n",
      "[1450,  2901] loss: 0.0166898  | loss_wrt: 0.00693  | loss_unl: 0.01596  | learning_rate: 0.00041\n",
      "OA: 0.9121  | AA:  0.8843  | Kappa:  0.8996  | Time: 40.2\n",
      "[1500,  3001] loss: 0.0435051  | loss_wrt: 0.00784  | loss_unl: 0.01389  | learning_rate: 0.00041\n",
      "OA: 0.9075  | AA:  0.8341  | Kappa:  0.8944  | Time: 40.0\n",
      "[1550,  3101] loss: 0.0242500  | loss_wrt: 0.00921  | loss_unl: 0.01290  | learning_rate: 0.00036\n",
      "OA: 0.8994  | AA:  0.8269  | Kappa:  0.8852  | Time: 39.6\n",
      "[1600,  3201] loss: 0.0093196  | loss_wrt: 0.00566  | loss_unl: 0.00945  | learning_rate: 0.00036\n",
      "OA: 0.8978  | AA:  0.8263  | Kappa:  0.8833  | Time: 39.6\n",
      "[1650,  3301] loss: 0.0279406  | loss_wrt: 0.00899  | loss_unl: 0.01416  | learning_rate: 0.00036\n",
      "OA: 0.8683  | AA:  0.7962  | Kappa:  0.8490  | Time: 38.6\n",
      "[1700,  3401] loss: 0.0179298  | loss_wrt: 0.00551  | loss_unl: 0.00887  | learning_rate: 0.00036\n",
      "OA: 0.9034  | AA:  0.8233  | Kappa:  0.8895  | Time: 40.5\n",
      "[1750,  3501] loss: 0.0145382  | loss_wrt: 0.00492  | loss_unl: 0.01050  | learning_rate: 0.00036\n",
      "OA: 0.9022  | AA:  0.8640  | Kappa:  0.8883  | Time: 40.6\n",
      "[1800,  3601] loss: 0.0286473  | loss_wrt: 0.00672  | loss_unl: 0.01096  | learning_rate: 0.00036\n",
      "OA: 0.9065  | AA:  0.8426  | Kappa:  0.8932  | Time: 39.8\n",
      "[1850,  3701] loss: 0.0235728  | loss_wrt: 0.00581  | loss_unl: 0.00850  | learning_rate: 0.00036\n",
      "OA: 0.9021  | AA:  0.8479  | Kappa:  0.8882  | Time: 38.3\n",
      "[1900,  3801] loss: 0.0128591  | loss_wrt: 0.00369  | loss_unl: 0.00803  | learning_rate: 0.00036\n",
      "OA: 0.9094  | AA:  0.8426  | Kappa:  0.8965  | Time: 39.1\n",
      "[1950,  3901] loss: 0.0757292  | loss_wrt: 0.00534  | loss_unl: 0.00920  | learning_rate: 0.00036\n",
      "OA: 0.9122  | AA:  0.8464  | Kappa:  0.8997  | Time: 40.0\n",
      "[2000,  4001] loss: 0.0094332  | loss_wrt: 0.00370  | loss_unl: 0.00936  | learning_rate: 0.00036\n",
      "OA: 0.9096  | AA:  0.8455  | Kappa:  0.8968  | Time: 39.4\n",
      "Finished Training\n",
      "model saved\n",
      "[0.53846154 0.96293245 0.84822695 0.75621891 0.90997567 0.78870968\n",
      " 0.75       1.         0.64705882 0.74818402 0.93770963 0.92857143\n",
      " 1.         0.99813953 0.99695122 0.74683544]\n",
      "0.9086107921928818 0.8473734559661039 0.8955612035259399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([103, 200, 31, 31]) torch.Size([103, 200, 31, 31])\n",
      "=> all bands acc: 0.513\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: 1.57 | loss:0.487 | 60 bands | 9.2s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: 1.38 | loss:0.518 | 112 bands | 3.9s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: 2.37 | loss:0.495 | 34 bands | 3.7s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: 2.56 | loss:0.503 | 30 bands | 4.2s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: 3.10 | loss:0.518 | 104 bands | 4.0s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: 2.45 | loss:0.499 | 70 bands | 3.4s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: 3.45 | loss:0.491 | 84 bands | 3.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: 4.30 | loss:0.510 | 73 bands | 3.4s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: 2.20 | loss:0.489 | 117 bands | 3.8s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: 3.14 | loss:0.516 | 54 bands | 3.1s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: 1.20 | loss:0.489 | 103 bands | 3.5s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: 1.32 | loss:0.511 | 71 bands | 3.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: 2.70 | loss:0.490 | 90 bands | 4.0s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: 3.08 | loss:0.480 | 84 bands | 3.5s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: 2.45 | loss:0.504 | 47 bands | 3.4s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: 3.77 | loss:0.485 | 97 bands | 3.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: 4.69 | loss:0.471 | 44 bands | 3.4s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: 2.82 | loss:0.472 | 68 bands | 2.9s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: 4.39 | loss:0.480 | 25 bands | 3.1s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: 5.27 | loss:0.449 | 84 bands | 3.3s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: 5.97 | loss:0.445 | 57 bands | 3.1s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: 6.70 | loss:0.491 | 38 bands | 3.0s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: 6.22 | loss:1.898 | 1 bands | 2.7s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: 7.93 | loss:0.435 | 34 bands | 2.8s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: 9.40 | loss:0.377 | 41 bands | 2.7s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: 10.64 | loss:0.416 | 34 bands | 2.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: 8.56 | loss:0.374 | 30 bands | 2.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: 10.63 | loss:0.363 | 31 bands | 2.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: 10.74 | loss:0.397 | 36 bands | 2.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: 12.24 | loss:0.340 | 24 bands | 2.4s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: 13.31 | loss:0.364 | 12 bands | 2.3s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: 13.78 | loss:0.330 | 21 bands | 2.4s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: 14.38 | loss:0.405 | 19 bands | 2.4s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: 14.57 | loss:0.381 | 23 bands | 2.4s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: 14.26 | loss:0.422 | 10 bands | 2.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: 14.82 | loss:0.361 | 13 bands | 2.3s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: 15.17 | loss:0.315 | 19 bands | 2.2s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: 15.57 | loss:0.332 | 20 bands | 2.2s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: 16.01 | loss:0.308 | 18 bands | 2.2s\n",
      "r_max, 0.30844678333960474\n",
      "Done\n",
      "time :127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 00:39:08.055353: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-21 00:39:08.058687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-21 00:39:08.058890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-21 00:39:08.612187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-21 00:39:08.612313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-21 00:39:08.612381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-21 00:39:08.612689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.0683145  | loss_wrt: 0.11746  | loss_unl: 0.13043  | learning_rate: 0.00100\n",
      "OA: 0.9132  | AA:  0.7736  | Kappa:  0.9008  | Time: 21.0\n",
      "[50,   201] loss: 0.1035423  | loss_wrt: 0.05215  | loss_unl: 0.06052  | learning_rate: 0.00090\n",
      "OA: 0.9274  | AA:  0.8122  | Kappa:  0.9171  | Time: 21.5\n",
      "[75,   301] loss: 0.0458324  | loss_wrt: 0.02639  | loss_unl: 0.03786  | learning_rate: 0.00081\n",
      "OA: 0.9379  | AA:  0.8362  | Kappa:  0.9290  | Time: 21.4\n",
      "[100,   401] loss: 0.0518010  | loss_wrt: 0.07039  | loss_unl: 0.07510  | learning_rate: 0.00073\n",
      "OA: 0.9179  | AA:  0.8161  | Kappa:  0.9063  | Time: 21.1\n",
      "[125,   501] loss: 0.0429841  | loss_wrt: 0.01696  | loss_unl: 0.02773  | learning_rate: 0.00066\n",
      "OA: 0.9490  | AA:  0.8473  | Kappa:  0.9417  | Time: 20.4\n",
      "[150,   601] loss: 0.0199231  | loss_wrt: 0.01139  | loss_unl: 0.01868  | learning_rate: 0.00059\n",
      "OA: 0.9525  | AA:  0.8506  | Kappa:  0.9457  | Time: 21.3\n",
      "[175,   701] loss: 0.0140560  | loss_wrt: 0.00612  | loss_unl: 0.01398  | learning_rate: 0.00053\n",
      "OA: 0.9533  | AA:  0.8470  | Kappa:  0.9466  | Time: 21.7\n",
      "[200,   801] loss: 0.0105065  | loss_wrt: 0.00689  | loss_unl: 0.01302  | learning_rate: 0.00048\n",
      "OA: 0.9548  | AA:  0.8640  | Kappa:  0.9483  | Time: 21.2\n",
      "[225,   901] loss: 0.0084185  | loss_wrt: 0.00344  | loss_unl: 0.00864  | learning_rate: 0.00043\n",
      "OA: 0.9558  | AA:  0.8497  | Kappa:  0.9495  | Time: 21.4\n",
      "[250,  1001] loss: 0.0069147  | loss_wrt: 0.00329  | loss_unl: 0.00662  | learning_rate: 0.00039\n",
      "OA: 0.9561  | AA:  0.8456  | Kappa:  0.9499  | Time: 21.2\n",
      "[275,  1101] loss: 0.0056689  | loss_wrt: 0.00382  | loss_unl: 0.00634  | learning_rate: 0.00035\n",
      "OA: 0.9596  | AA:  0.8587  | Kappa:  0.9538  | Time: 20.6\n",
      "[300,  1201] loss: 0.0045851  | loss_wrt: 0.00226  | loss_unl: 0.00581  | learning_rate: 0.00031\n",
      "OA: 0.9582  | AA:  0.8552  | Kappa:  0.9523  | Time: 20.7\n",
      "[325,  1301] loss: 0.0037052  | loss_wrt: 0.00203  | loss_unl: 0.00555  | learning_rate: 0.00028\n",
      "OA: 0.9586  | AA:  0.8534  | Kappa:  0.9527  | Time: 22.1\n",
      "[350,  1401] loss: 0.0032312  | loss_wrt: 0.00187  | loss_unl: 0.00421  | learning_rate: 0.00025\n",
      "OA: 0.9598  | AA:  0.8705  | Kappa:  0.9541  | Time: 21.3\n",
      "[375,  1501] loss: 0.0027487  | loss_wrt: 0.00152  | loss_unl: 0.00396  | learning_rate: 0.00023\n",
      "OA: 0.9600  | AA:  0.8676  | Kappa:  0.9544  | Time: 21.0\n",
      "[400,  1601] loss: 0.0023715  | loss_wrt: 0.00106  | loss_unl: 0.00235  | learning_rate: 0.00021\n",
      "OA: 0.9611  | AA:  0.8834  | Kappa:  0.9555  | Time: 21.7\n",
      "[425,  1701] loss: 0.0021147  | loss_wrt: 0.00129  | loss_unl: 0.00215  | learning_rate: 0.00019\n",
      "OA: 0.9605  | AA:  0.8855  | Kappa:  0.9549  | Time: 21.3\n",
      "[450,  1801] loss: 0.0018793  | loss_wrt: 0.00080  | loss_unl: 0.00286  | learning_rate: 0.00017\n",
      "OA: 0.9607  | AA:  0.8794  | Kappa:  0.9552  | Time: 21.0\n",
      "[475,  1901] loss: 0.0017413  | loss_wrt: 0.00086  | loss_unl: 0.00219  | learning_rate: 0.00015\n",
      "OA: 0.9607  | AA:  0.8743  | Kappa:  0.9552  | Time: 22.1\n",
      "[500,  2001] loss: 0.0015836  | loss_wrt: 0.00081  | loss_unl: 0.00166  | learning_rate: 0.00014\n",
      "OA: 0.9612  | AA:  0.8883  | Kappa:  0.9557  | Time: 20.6\n",
      "Finished Training\n",
      "[0.82051282 0.99505766 0.94609929 1.         0.99026764 0.93709677\n",
      " 0.875      1.         0.23529412 0.83535109 0.97077144 1.\n",
      " 1.         1.         1.         0.60759494]\n",
      "0.9611940298507463 0.8883153607638208 0.9556742174985767\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.3122625  | loss_wrt: 0.14624  | loss_unl: 0.17638  | learning_rate: 0.00050\n",
      "OA: 0.7969  | AA:  0.6303  | Kappa:  0.7660  | Time: 31.6\n",
      "[100,   201] loss: 0.2351828  | loss_wrt: 0.09551  | loss_unl: 0.12055  | learning_rate: 0.00050\n",
      "OA: 0.8675  | AA:  0.8021  | Kappa:  0.8487  | Time: 29.6\n",
      "[150,   301] loss: 0.2379379  | loss_wrt: 0.07759  | loss_unl: 0.09541  | learning_rate: 0.00050\n",
      "OA: 0.8473  | AA:  0.7451  | Kappa:  0.8251  | Time: 29.9\n",
      "[200,   401] loss: 0.1011762  | loss_wrt: 0.05308  | loss_unl: 0.08196  | learning_rate: 0.00050\n",
      "OA: 0.8782  | AA:  0.7715  | Kappa:  0.8607  | Time: 29.6\n",
      "[250,   501] loss: 0.0814699  | loss_wrt: 0.06313  | loss_unl: 0.09262  | learning_rate: 0.00050\n",
      "OA: 0.8507  | AA:  0.7528  | Kappa:  0.8291  | Time: 29.5\n",
      "[300,   601] loss: 0.0732046  | loss_wrt: 0.04080  | loss_unl: 0.05426  | learning_rate: 0.00050\n",
      "OA: 0.8768  | AA:  0.8025  | Kappa:  0.8591  | Time: 29.9\n",
      "[350,   701] loss: 0.0644876  | loss_wrt: 0.03883  | loss_unl: 0.05302  | learning_rate: 0.00050\n",
      "OA: 0.8528  | AA:  0.7924  | Kappa:  0.8313  | Time: 29.6\n",
      "[400,   801] loss: 0.0359590  | loss_wrt: 0.02271  | loss_unl: 0.03497  | learning_rate: 0.00050\n",
      "OA: 0.8930  | AA:  0.7954  | Kappa:  0.8778  | Time: 29.5\n",
      "[450,   901] loss: 0.0272004  | loss_wrt: 0.01350  | loss_unl: 0.02472  | learning_rate: 0.00050\n",
      "OA: 0.9038  | AA:  0.8249  | Kappa:  0.8901  | Time: 30.1\n",
      "[500,  1001] loss: 0.0360982  | loss_wrt: 0.02138  | loss_unl: 0.02400  | learning_rate: 0.00050\n",
      "OA: 0.8960  | AA:  0.8165  | Kappa:  0.8811  | Time: 30.2\n",
      "[550,  1101] loss: 0.1201516  | loss_wrt: 0.02355  | loss_unl: 0.03316  | learning_rate: 0.00045\n",
      "OA: 0.8873  | AA:  0.8086  | Kappa:  0.8714  | Time: 34.3\n",
      "[600,  1201] loss: 0.0439906  | loss_wrt: 0.02178  | loss_unl: 0.02871  | learning_rate: 0.00045\n",
      "OA: 0.8982  | AA:  0.8220  | Kappa:  0.8837  | Time: 31.8\n",
      "[650,  1301] loss: 0.0415294  | loss_wrt: 0.03222  | loss_unl: 0.04216  | learning_rate: 0.00045\n",
      "OA: 0.8763  | AA:  0.7736  | Kappa:  0.8591  | Time: 32.9\n",
      "[700,  1401] loss: 0.0816475  | loss_wrt: 0.02897  | loss_unl: 0.03678  | learning_rate: 0.00045\n",
      "OA: 0.8790  | AA:  0.7973  | Kappa:  0.8617  | Time: 32.6\n",
      "[750,  1501] loss: 0.0293202  | loss_wrt: 0.01283  | loss_unl: 0.02366  | learning_rate: 0.00045\n",
      "OA: 0.8975  | AA:  0.8161  | Kappa:  0.8830  | Time: 32.0\n",
      "[800,  1601] loss: 0.0191673  | loss_wrt: 0.00787  | loss_unl: 0.01627  | learning_rate: 0.00045\n",
      "OA: 0.9028  | AA:  0.8266  | Kappa:  0.8889  | Time: 31.6\n",
      "[850,  1701] loss: 0.0166898  | loss_wrt: 0.00783  | loss_unl: 0.01714  | learning_rate: 0.00045\n",
      "OA: 0.9005  | AA:  0.8251  | Kappa:  0.8864  | Time: 31.6\n",
      "[900,  1801] loss: 0.0448252  | loss_wrt: 0.01152  | loss_unl: 0.02323  | learning_rate: 0.00045\n",
      "OA: 0.8958  | AA:  0.8129  | Kappa:  0.8809  | Time: 31.8\n",
      "[950,  1901] loss: 0.0598494  | loss_wrt: 0.02261  | loss_unl: 0.02688  | learning_rate: 0.00045\n",
      "OA: 0.8874  | AA:  0.7871  | Kappa:  0.8713  | Time: 33.1\n",
      "[1000,  2001] loss: 0.0233881  | loss_wrt: 0.00760  | loss_unl: 0.01392  | learning_rate: 0.00045\n",
      "OA: 0.9041  | AA:  0.8348  | Kappa:  0.8905  | Time: 31.5\n",
      "[1050,  2101] loss: 0.0128840  | loss_wrt: 0.00685  | loss_unl: 0.01396  | learning_rate: 0.00041\n",
      "OA: 0.8937  | AA:  0.8050  | Kappa:  0.8787  | Time: 38.6\n",
      "[1100,  2201] loss: 0.0164285  | loss_wrt: 0.00644  | loss_unl: 0.01329  | learning_rate: 0.00041\n",
      "OA: 0.8906  | AA:  0.8215  | Kappa:  0.8751  | Time: 37.7\n",
      "[1150,  2301] loss: 0.0293359  | loss_wrt: 0.01350  | loss_unl: 0.01777  | learning_rate: 0.00041\n",
      "OA: 0.8980  | AA:  0.8041  | Kappa:  0.8838  | Time: 38.6\n",
      "[1200,  2401] loss: 0.0153585  | loss_wrt: 0.00932  | loss_unl: 0.01549  | learning_rate: 0.00041\n",
      "OA: 0.8987  | AA:  0.8140  | Kappa:  0.8843  | Time: 38.5\n",
      "[1250,  2501] loss: 0.0102098  | loss_wrt: 0.00330  | loss_unl: 0.00954  | learning_rate: 0.00041\n",
      "OA: 0.9015  | AA:  0.8286  | Kappa:  0.8875  | Time: 37.9\n",
      "[1300,  2601] loss: 0.0372200  | loss_wrt: 0.00863  | loss_unl: 0.01778  | learning_rate: 0.00041\n",
      "OA: 0.8968  | AA:  0.8291  | Kappa:  0.8821  | Time: 38.2\n",
      "[1350,  2701] loss: 0.0323287  | loss_wrt: 0.01051  | loss_unl: 0.01654  | learning_rate: 0.00041\n",
      "OA: 0.8865  | AA:  0.7944  | Kappa:  0.8703  | Time: 38.8\n",
      "[1400,  2801] loss: 0.0122099  | loss_wrt: 0.00375  | loss_unl: 0.00937  | learning_rate: 0.00041\n",
      "OA: 0.9006  | AA:  0.8218  | Kappa:  0.8865  | Time: 38.3\n",
      "[1450,  2901] loss: 0.0130622  | loss_wrt: 0.00746  | loss_unl: 0.01346  | learning_rate: 0.00041\n",
      "OA: 0.9025  | AA:  0.8328  | Kappa:  0.8888  | Time: 38.4\n",
      "[1500,  3001] loss: 0.0163043  | loss_wrt: 0.00632  | loss_unl: 0.02490  | learning_rate: 0.00041\n",
      "OA: 0.9009  | AA:  0.8401  | Kappa:  0.8870  | Time: 38.3\n",
      "[1550,  3101] loss: 0.0112670  | loss_wrt: 0.00330  | loss_unl: 0.00698  | learning_rate: 0.00036\n",
      "OA: 0.9049  | AA:  0.8314  | Kappa:  0.8915  | Time: 37.4\n",
      "[1600,  3201] loss: 0.0059636  | loss_wrt: 0.00218  | loss_unl: 0.00703  | learning_rate: 0.00036\n",
      "OA: 0.8958  | AA:  0.8200  | Kappa:  0.8810  | Time: 37.8\n",
      "[1650,  3301] loss: 0.0051480  | loss_wrt: 0.00188  | loss_unl: 0.00537  | learning_rate: 0.00036\n",
      "OA: 0.9018  | AA:  0.8249  | Kappa:  0.8880  | Time: 38.1\n",
      "[1700,  3401] loss: 0.0758562  | loss_wrt: 0.00724  | loss_unl: 0.01476  | learning_rate: 0.00036\n",
      "OA: 0.8785  | AA:  0.7709  | Kappa:  0.8609  | Time: 38.6\n",
      "[1750,  3501] loss: 0.0081771  | loss_wrt: 0.00298  | loss_unl: 0.00646  | learning_rate: 0.00036\n",
      "OA: 0.8992  | AA:  0.8136  | Kappa:  0.8849  | Time: 37.5\n",
      "[1800,  3601] loss: 0.0075709  | loss_wrt: 0.00285  | loss_unl: 0.00562  | learning_rate: 0.00036\n",
      "OA: 0.9039  | AA:  0.8318  | Kappa:  0.8904  | Time: 37.2\n",
      "[1850,  3701] loss: 0.0209531  | loss_wrt: 0.00465  | loss_unl: 0.00790  | learning_rate: 0.00036\n",
      "OA: 0.8855  | AA:  0.8124  | Kappa:  0.8694  | Time: 38.4\n",
      "[1900,  3801] loss: 0.0114707  | loss_wrt: 0.00536  | loss_unl: 0.00897  | learning_rate: 0.00036\n",
      "OA: 0.9001  | AA:  0.8201  | Kappa:  0.8859  | Time: 37.5\n",
      "[1950,  3901] loss: 0.0057126  | loss_wrt: 0.00211  | loss_unl: 0.00613  | learning_rate: 0.00036\n",
      "OA: 0.9054  | AA:  0.8252  | Kappa:  0.8921  | Time: 38.4\n",
      "[2000,  4001] loss: 0.0043100  | loss_wrt: 0.00128  | loss_unl: 0.00418  | learning_rate: 0.00036\n",
      "OA: 0.9034  | AA:  0.8250  | Kappa:  0.8898  | Time: 38.3\n",
      "Finished Training\n",
      "model saved\n",
      "[0.66666667 0.93492586 0.90496454 0.76119403 0.81751825 0.89032258\n",
      " 0.875      1.         0.         0.85230024 0.94968855 0.93055556\n",
      " 0.85057471 0.83162791 0.97865854 1.        ]\n",
      "0.9028702640642939 0.8277498394563487 0.8891739589650997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([103, 200, 31, 31]) torch.Size([103, 200, 31, 31])\n",
      "=> all bands acc: 0.711\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -18.52 | loss:0.702 | 115 bands | 8.2s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -9.26 | loss:0.693 | 39 bands | 3.8s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -3.41 | loss:0.597 | 1 bands | 3.5s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -3.62 | loss:0.693 | 68 bands | 3.2s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -0.18 | loss:0.691 | 64 bands | 3.6s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: 1.35 | loss:0.975 | 10 bands | 3.7s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -3.82 | loss:0.660 | 60 bands | 3.1s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: 0.12 | loss:0.689 | 99 bands | 3.4s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: 0.22 | loss:0.688 | 95 bands | 3.0s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: 1.82 | loss:0.685 | 50 bands | 2.8s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: 3.80 | loss:0.659 | 11 bands | 2.9s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: 4.90 | loss:0.687 | 60 bands | 3.1s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: 5.99 | loss:0.669 | 29 bands | 2.7s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: 3.72 | loss:0.670 | 51 bands | 2.4s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: 2.24 | loss:0.591 | 20 bands | 2.4s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: 1.93 | loss:0.577 | 49 bands | 2.6s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: 5.16 | loss:0.568 | 42 bands | 2.6s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: 5.79 | loss:0.553 | 11 bands | 2.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: 7.70 | loss:0.625 | 22 bands | 2.4s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: 9.67 | loss:0.575 | 20 bands | 2.2s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: 10.53 | loss:0.570 | 32 bands | 2.4s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: 11.09 | loss:0.575 | 31 bands | 2.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: 9.25 | loss:0.573 | 5 bands | 2.3s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: 8.05 | loss:0.571 | 27 bands | 2.4s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: 5.89 | loss:0.576 | 37 bands | 2.9s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: 8.83 | loss:0.569 | 28 bands | 2.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: 10.69 | loss:0.580 | 17 bands | 2.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: 11.19 | loss:0.555 | 25 bands | 2.3s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: 9.27 | loss:0.628 | 9 bands | 2.6s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: 11.12 | loss:0.561 | 20 bands | 2.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: 12.11 | loss:0.572 | 19 bands | 2.3s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: 8.64 | loss:0.583 | 20 bands | 2.4s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: 11.32 | loss:0.562 | 21 bands | 2.3s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: 12.82 | loss:0.565 | 15 bands | 2.3s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: 13.97 | loss:0.559 | 15 bands | 2.2s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: 14.01 | loss:0.537 | 17 bands | 2.3s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: 14.47 | loss:0.558 | 19 bands | 2.2s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: 5.95 | loss:0.585 | 13 bands | 2.4s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: 10.15 | loss:0.549 | 20 bands | 2.2s\n",
      "r_max, 0.5232829550222959\n",
      "Done\n",
      "time :112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 01:11:46.603065: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-21 01:11:46.606947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-21 01:11:46.607161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-21 01:11:47.183400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-21 01:11:47.183516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-21 01:11:47.183577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-21 01:11:47.183830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.3838741  | loss_wrt: 0.12131  | loss_unl: 0.14810  | learning_rate: 0.00100\n",
      "OA: 0.9009  | AA:  0.7476  | Kappa:  0.8868  | Time: 22.5\n",
      "[50,   201] loss: 0.1403213  | loss_wrt: 0.04984  | loss_unl: 0.07290  | learning_rate: 0.00090\n",
      "OA: 0.9454  | AA:  0.8823  | Kappa:  0.9377  | Time: 20.5\n",
      "[75,   301] loss: 0.0518929  | loss_wrt: 0.02388  | loss_unl: 0.04311  | learning_rate: 0.00081\n",
      "OA: 0.9544  | AA:  0.8876  | Kappa:  0.9481  | Time: 20.9\n",
      "[100,   401] loss: 0.0415297  | loss_wrt: 0.02068  | loss_unl: 0.03718  | learning_rate: 0.00073\n",
      "OA: 0.9602  | AA:  0.8985  | Kappa:  0.9546  | Time: 20.4\n",
      "[125,   501] loss: 0.0246161  | loss_wrt: 0.01262  | loss_unl: 0.02447  | learning_rate: 0.00066\n",
      "OA: 0.9654  | AA:  0.9271  | Kappa:  0.9606  | Time: 20.7\n",
      "[150,   601] loss: 0.0180050  | loss_wrt: 0.00968  | loss_unl: 0.01570  | learning_rate: 0.00059\n",
      "OA: 0.9693  | AA:  0.9430  | Kappa:  0.9651  | Time: 20.5\n",
      "[175,   701] loss: 0.0137411  | loss_wrt: 0.00717  | loss_unl: 0.01503  | learning_rate: 0.00053\n",
      "OA: 0.9710  | AA:  0.9300  | Kappa:  0.9669  | Time: 20.8\n",
      "[200,   801] loss: 0.0290938  | loss_wrt: 0.00892  | loss_unl: 0.01781  | learning_rate: 0.00048\n",
      "OA: 0.9689  | AA:  0.9316  | Kappa:  0.9646  | Time: 21.3\n",
      "[225,   901] loss: 0.0115853  | loss_wrt: 0.00509  | loss_unl: 0.01344  | learning_rate: 0.00043\n",
      "OA: 0.9700  | AA:  0.9309  | Kappa:  0.9659  | Time: 20.8\n",
      "[250,  1001] loss: 0.0090418  | loss_wrt: 0.00462  | loss_unl: 0.00973  | learning_rate: 0.00039\n",
      "OA: 0.9698  | AA:  0.9370  | Kappa:  0.9656  | Time: 20.6\n",
      "[275,  1101] loss: 0.0077085  | loss_wrt: 0.00387  | loss_unl: 0.00946  | learning_rate: 0.00035\n",
      "OA: 0.9700  | AA:  0.9401  | Kappa:  0.9659  | Time: 20.5\n",
      "[300,  1201] loss: 0.0066229  | loss_wrt: 0.00399  | loss_unl: 0.00863  | learning_rate: 0.00031\n",
      "OA: 0.9707  | AA:  0.9365  | Kappa:  0.9667  | Time: 21.0\n",
      "[325,  1301] loss: 0.0057447  | loss_wrt: 0.00251  | loss_unl: 0.00866  | learning_rate: 0.00028\n",
      "OA: 0.9734  | AA:  0.9538  | Kappa:  0.9697  | Time: 20.3\n",
      "[350,  1401] loss: 0.0050171  | loss_wrt: 0.00267  | loss_unl: 0.00619  | learning_rate: 0.00025\n",
      "OA: 0.9732  | AA:  0.9465  | Kappa:  0.9695  | Time: 20.4\n",
      "[375,  1501] loss: 0.0044855  | loss_wrt: 0.00281  | loss_unl: 0.00661  | learning_rate: 0.00023\n",
      "OA: 0.9736  | AA:  0.9515  | Kappa:  0.9699  | Time: 20.8\n",
      "[400,  1601] loss: 0.0039009  | loss_wrt: 0.00229  | loss_unl: 0.00510  | learning_rate: 0.00021\n",
      "OA: 0.9755  | AA:  0.9554  | Kappa:  0.9722  | Time: 20.9\n",
      "[425,  1701] loss: 0.0034771  | loss_wrt: 0.00180  | loss_unl: 0.00416  | learning_rate: 0.00019\n",
      "OA: 0.9745  | AA:  0.9532  | Kappa:  0.9710  | Time: 20.5\n",
      "[450,  1801] loss: 0.0031578  | loss_wrt: 0.00145  | loss_unl: 0.00257  | learning_rate: 0.00017\n",
      "OA: 0.9750  | AA:  0.9567  | Kappa:  0.9715  | Time: 20.8\n",
      "[475,  1901] loss: 0.0027251  | loss_wrt: 0.00140  | loss_unl: 0.00355  | learning_rate: 0.00015\n",
      "OA: 0.9746  | AA:  0.9566  | Kappa:  0.9711  | Time: 21.0\n",
      "[500,  2001] loss: 0.0025786  | loss_wrt: 0.00118  | loss_unl: 0.00315  | learning_rate: 0.00014\n",
      "OA: 0.9752  | AA:  0.9599  | Kappa:  0.9718  | Time: 21.3\n",
      "Finished Training\n",
      "[1.         0.98682043 1.         0.97014925 1.         1.\n",
      " 0.95833333 1.         0.70588235 1.         0.96597988 0.88492063\n",
      " 1.         0.94976744 1.         0.93670886]\n",
      "0.9752009184845005 0.9599101363313618 0.9717729336137315\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2705399  | loss_wrt: 0.14576  | loss_unl: 0.18300  | learning_rate: 0.00050\n",
      "OA: 0.7726  | AA:  0.6442  | Kappa:  0.7421  | Time: 33.3\n",
      "[100,   201] loss: 0.2180579  | loss_wrt: 0.07593  | loss_unl: 0.10744  | learning_rate: 0.00050\n",
      "OA: 0.8009  | AA:  0.6960  | Kappa:  0.7727  | Time: 31.2\n",
      "[150,   301] loss: 0.1482050  | loss_wrt: 0.05118  | loss_unl: 0.07997  | learning_rate: 0.00050\n",
      "OA: 0.8651  | AA:  0.7684  | Kappa:  0.8460  | Time: 31.4\n",
      "[200,   401] loss: 0.0992607  | loss_wrt: 0.03763  | loss_unl: 0.06499  | learning_rate: 0.00050\n",
      "OA: 0.8728  | AA:  0.7714  | Kappa:  0.8546  | Time: 31.2\n",
      "[250,   501] loss: 0.1253652  | loss_wrt: 0.07067  | loss_unl: 0.08280  | learning_rate: 0.00050\n",
      "OA: 0.8447  | AA:  0.7456  | Kappa:  0.8226  | Time: 31.3\n",
      "[300,   601] loss: 0.0805063  | loss_wrt: 0.03118  | loss_unl: 0.05319  | learning_rate: 0.00050\n",
      "OA: 0.8659  | AA:  0.7670  | Kappa:  0.8466  | Time: 31.6\n",
      "[350,   701] loss: 0.0374416  | loss_wrt: 0.01859  | loss_unl: 0.03564  | learning_rate: 0.00050\n",
      "OA: 0.8815  | AA:  0.7806  | Kappa:  0.8648  | Time: 31.2\n",
      "[400,   801] loss: 0.0444128  | loss_wrt: 0.02457  | loss_unl: 0.04080  | learning_rate: 0.00050\n",
      "OA: 0.8889  | AA:  0.7926  | Kappa:  0.8731  | Time: 31.2\n",
      "[450,   901] loss: 0.0836842  | loss_wrt: 0.04685  | loss_unl: 0.06273  | learning_rate: 0.00050\n",
      "OA: 0.8815  | AA:  0.7756  | Kappa:  0.8645  | Time: 32.8\n",
      "[500,  1001] loss: 0.0466636  | loss_wrt: 0.01762  | loss_unl: 0.03124  | learning_rate: 0.00050\n",
      "OA: 0.8967  | AA:  0.7936  | Kappa:  0.8819  | Time: 34.8\n",
      "[550,  1101] loss: 0.0572150  | loss_wrt: 0.02238  | loss_unl: 0.03573  | learning_rate: 0.00045\n",
      "OA: 0.8760  | AA:  0.7697  | Kappa:  0.8585  | Time: 35.5\n",
      "[600,  1201] loss: 0.0232704  | loss_wrt: 0.01231  | loss_unl: 0.03227  | learning_rate: 0.00045\n",
      "OA: 0.8979  | AA:  0.7916  | Kappa:  0.8835  | Time: 35.2\n",
      "[650,  1301] loss: 0.0642320  | loss_wrt: 0.02199  | loss_unl: 0.02961  | learning_rate: 0.00045\n",
      "OA: 0.8832  | AA:  0.7754  | Kappa:  0.8669  | Time: 41.2\n",
      "[700,  1401] loss: 0.0432403  | loss_wrt: 0.01016  | loss_unl: 0.02388  | learning_rate: 0.00045\n",
      "OA: 0.8935  | AA:  0.7862  | Kappa:  0.8782  | Time: 41.6\n",
      "[750,  1501] loss: 0.0304694  | loss_wrt: 0.00978  | loss_unl: 0.01970  | learning_rate: 0.00045\n",
      "OA: 0.9025  | AA:  0.7929  | Kappa:  0.8887  | Time: 32.6\n",
      "[800,  1601] loss: 0.0393506  | loss_wrt: 0.01364  | loss_unl: 0.02701  | learning_rate: 0.00045\n",
      "OA: 0.8894  | AA:  0.7868  | Kappa:  0.8737  | Time: 29.9\n",
      "[850,  1701] loss: 0.0231556  | loss_wrt: 0.00685  | loss_unl: 0.02271  | learning_rate: 0.00045\n",
      "OA: 0.8930  | AA:  0.7839  | Kappa:  0.8778  | Time: 29.8\n",
      "[900,  1801] loss: 0.0132715  | loss_wrt: 0.00467  | loss_unl: 0.01405  | learning_rate: 0.00045\n",
      "OA: 0.8914  | AA:  0.7852  | Kappa:  0.8760  | Time: 30.3\n",
      "[950,  1901] loss: 0.0142998  | loss_wrt: 0.00771  | loss_unl: 0.01526  | learning_rate: 0.00045\n",
      "OA: 0.8907  | AA:  0.7849  | Kappa:  0.8753  | Time: 30.4\n",
      "[1000,  2001] loss: 0.0115348  | loss_wrt: 0.00592  | loss_unl: 0.01386  | learning_rate: 0.00045\n",
      "OA: 0.8887  | AA:  0.7844  | Kappa:  0.8729  | Time: 30.3\n",
      "[1050,  2101] loss: 0.0122768  | loss_wrt: 0.00868  | loss_unl: 0.02258  | learning_rate: 0.00041\n",
      "OA: 0.8948  | AA:  0.7800  | Kappa:  0.8799  | Time: 30.8\n",
      "[1100,  2201] loss: 0.0098075  | loss_wrt: 0.00355  | loss_unl: 0.00940  | learning_rate: 0.00041\n",
      "OA: 0.8955  | AA:  0.7901  | Kappa:  0.8807  | Time: 30.4\n",
      "[1150,  2301] loss: 0.0175914  | loss_wrt: 0.01077  | loss_unl: 0.01854  | learning_rate: 0.00041\n",
      "OA: 0.9016  | AA:  0.7972  | Kappa:  0.8878  | Time: 38.8\n",
      "[1200,  2401] loss: 0.0087311  | loss_wrt: 0.00425  | loss_unl: 0.00774  | learning_rate: 0.00041\n",
      "OA: 0.9002  | AA:  0.7958  | Kappa:  0.8862  | Time: 40.6\n",
      "[1250,  2501] loss: 0.0060778  | loss_wrt: 0.00298  | loss_unl: 0.00629  | learning_rate: 0.00041\n",
      "OA: 0.9002  | AA:  0.7973  | Kappa:  0.8862  | Time: 41.2\n",
      "[1300,  2601] loss: 0.0059611  | loss_wrt: 0.00168  | loss_unl: 0.00525  | learning_rate: 0.00041\n",
      "OA: 0.8982  | AA:  0.7932  | Kappa:  0.8838  | Time: 38.9\n",
      "[1350,  2701] loss: 0.0539681  | loss_wrt: 0.00994  | loss_unl: 0.01288  | learning_rate: 0.00041\n",
      "OA: 0.8953  | AA:  0.7822  | Kappa:  0.8803  | Time: 41.2\n",
      "[1400,  2801] loss: 0.0454945  | loss_wrt: 0.00830  | loss_unl: 0.01018  | learning_rate: 0.00041\n",
      "OA: 0.8916  | AA:  0.7828  | Kappa:  0.8762  | Time: 41.2\n",
      "[1450,  2901] loss: 0.0105699  | loss_wrt: 0.00498  | loss_unl: 0.00972  | learning_rate: 0.00041\n",
      "OA: 0.8955  | AA:  0.7849  | Kappa:  0.8807  | Time: 41.4\n",
      "[1500,  3001] loss: 0.0694287  | loss_wrt: 0.01150  | loss_unl: 0.01615  | learning_rate: 0.00041\n",
      "OA: 0.8738  | AA:  0.7699  | Kappa:  0.8557  | Time: 41.3\n",
      "[1550,  3101] loss: 0.0239074  | loss_wrt: 0.00788  | loss_unl: 0.01049  | learning_rate: 0.00036\n",
      "OA: 0.8949  | AA:  0.7908  | Kappa:  0.8801  | Time: 40.8\n",
      "[1600,  3201] loss: 0.0081033  | loss_wrt: 0.00333  | loss_unl: 0.00876  | learning_rate: 0.00036\n",
      "OA: 0.8855  | AA:  0.7764  | Kappa:  0.8695  | Time: 41.7\n",
      "[1650,  3301] loss: 0.0061834  | loss_wrt: 0.00243  | loss_unl: 0.00702  | learning_rate: 0.00036\n",
      "OA: 0.8962  | AA:  0.7892  | Kappa:  0.8816  | Time: 41.6\n",
      "[1700,  3401] loss: 0.0046586  | loss_wrt: 0.00240  | loss_unl: 0.00541  | learning_rate: 0.00036\n",
      "OA: 0.8830  | AA:  0.7759  | Kappa:  0.8666  | Time: 40.1\n",
      "[1750,  3501] loss: 0.0083781  | loss_wrt: 0.00422  | loss_unl: 0.00753  | learning_rate: 0.00036\n",
      "OA: 0.8964  | AA:  0.7892  | Kappa:  0.8818  | Time: 32.0\n",
      "[1800,  3601] loss: 0.0402437  | loss_wrt: 0.00472  | loss_unl: 0.00887  | learning_rate: 0.00036\n",
      "OA: 0.8896  | AA:  0.7812  | Kappa:  0.8739  | Time: 32.0\n",
      "[1850,  3701] loss: 0.0101314  | loss_wrt: 0.00442  | loss_unl: 0.00878  | learning_rate: 0.00036\n",
      "OA: 0.8914  | AA:  0.7878  | Kappa:  0.8759  | Time: 32.4\n",
      "[1900,  3801] loss: 0.0065401  | loss_wrt: 0.00219  | loss_unl: 0.00584  | learning_rate: 0.00036\n",
      "OA: 0.9029  | AA:  0.7996  | Kappa:  0.8891  | Time: 31.4\n",
      "[1950,  3901] loss: 0.0086854  | loss_wrt: 0.00536  | loss_unl: 0.00883  | learning_rate: 0.00036\n",
      "OA: 0.8999  | AA:  0.7880  | Kappa:  0.8858  | Time: 31.9\n",
      "[2000,  4001] loss: 0.0120013  | loss_wrt: 0.00336  | loss_unl: 0.00717  | learning_rate: 0.00036\n",
      "OA: 0.8962  | AA:  0.7884  | Kappa:  0.8815  | Time: 32.1\n",
      "Finished Training\n",
      "model saved\n",
      "[1.         0.83443163 0.7929078  0.90547264 0.9756691  0.91129032\n",
      " 0.         1.         0.         0.77723971 0.94106373 0.85515873\n",
      " 0.99425287 0.99534884 0.99085366 0.62025316]\n",
      "0.8977037887485648 0.7871213870531619 0.8832484995753047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([103, 200, 31, 31]) torch.Size([103, 200, 31, 31])\n",
      "=> all bands acc: 0.665\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: 3.41 | loss:0.668 | 135 bands | 8.4s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: 3.48 | loss:0.744 | 22 bands | 3.6s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: 4.07 | loss:0.666 | 74 bands | 3.3s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: 4.47 | loss:0.647 | 95 bands | 3.4s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: 2.36 | loss:0.610 | 16 bands | 3.5s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: 3.49 | loss:0.645 | 37 bands | 3.3s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: 4.39 | loss:0.640 | 94 bands | 2.9s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: 5.02 | loss:0.624 | 86 bands | 3.1s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: 5.39 | loss:0.639 | 59 bands | 3.0s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: 6.32 | loss:0.586 | 64 bands | 3.0s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: 6.45 | loss:0.649 | 59 bands | 3.4s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: 1.55 | loss:0.631 | 38 bands | 3.3s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: 3.92 | loss:0.599 | 67 bands | 3.2s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: 5.97 | loss:0.618 | 31 bands | 2.8s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: 7.11 | loss:0.554 | 32 bands | 2.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: 5.40 | loss:0.547 | 46 bands | 3.0s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: 7.09 | loss:0.546 | 52 bands | 3.0s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: 5.16 | loss:0.568 | 28 bands | 2.7s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: 6.31 | loss:0.581 | 39 bands | 3.1s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: 5.56 | loss:0.615 | 25 bands | 2.9s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: 7.85 | loss:0.551 | 36 bands | 2.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: 9.89 | loss:0.542 | 24 bands | 2.4s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: 10.99 | loss:0.535 | 40 bands | 2.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: 11.92 | loss:0.524 | 33 bands | 2.4s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: 12.21 | loss:0.518 | 41 bands | 2.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: 12.78 | loss:0.517 | 25 bands | 2.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: 11.86 | loss:0.541 | 31 bands | 2.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: 12.73 | loss:0.551 | 39 bands | 2.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: 11.70 | loss:0.513 | 23 bands | 2.4s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: 12.64 | loss:0.532 | 29 bands | 2.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: 12.86 | loss:0.528 | 29 bands | 2.7s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: 13.75 | loss:0.512 | 21 bands | 2.4s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: 14.15 | loss:0.533 | 13 bands | 2.2s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: 13.25 | loss:0.505 | 27 bands | 2.4s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: 13.82 | loss:0.518 | 29 bands | 2.6s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: 14.51 | loss:0.501 | 27 bands | 2.4s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: 15.00 | loss:0.509 | 19 bands | 2.4s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: 15.34 | loss:0.489 | 23 bands | 2.3s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: 15.75 | loss:0.522 | 20 bands | 2.3s\n",
      "r_max, 0.4935060161224101\n",
      "Done\n",
      "time :117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 01:44:13.569620: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-21 01:44:13.572802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-21 01:44:13.572995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-21 01:44:14.112847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-21 01:44:14.112962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-21 01:44:14.113022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-21 01:44:14.113275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.1067173  | loss_wrt: 0.12318  | loss_unl: 0.12313  | learning_rate: 0.00100\n",
      "OA: 0.9439  | AA:  0.8567  | Kappa:  0.9359  | Time: 36.7\n",
      "[50,   201] loss: 0.0929769  | loss_wrt: 0.04176  | loss_unl: 0.05659  | learning_rate: 0.00090\n",
      "OA: 0.9646  | AA:  0.9044  | Kappa:  0.9596  | Time: 20.7\n",
      "[75,   301] loss: 0.0423411  | loss_wrt: 0.02803  | loss_unl: 0.03175  | learning_rate: 0.00081\n",
      "OA: 0.9687  | AA:  0.9258  | Kappa:  0.9642  | Time: 21.1\n",
      "[100,   401] loss: 0.0268557  | loss_wrt: 0.01478  | loss_unl: 0.02506  | learning_rate: 0.00073\n",
      "OA: 0.9695  | AA:  0.9148  | Kappa:  0.9652  | Time: 20.7\n",
      "[125,   501] loss: 0.0192736  | loss_wrt: 0.01399  | loss_unl: 0.02087  | learning_rate: 0.00066\n",
      "OA: 0.9737  | AA:  0.9287  | Kappa:  0.9700  | Time: 22.0\n",
      "[150,   601] loss: 0.0150704  | loss_wrt: 0.00885  | loss_unl: 0.01394  | learning_rate: 0.00059\n",
      "OA: 0.9750  | AA:  0.9396  | Kappa:  0.9714  | Time: 21.4\n",
      "[175,   701] loss: 0.0118914  | loss_wrt: 0.00688  | loss_unl: 0.01283  | learning_rate: 0.00053\n",
      "OA: 0.9767  | AA:  0.9507  | Kappa:  0.9734  | Time: 21.0\n",
      "[200,   801] loss: 0.0096448  | loss_wrt: 0.00592  | loss_unl: 0.01092  | learning_rate: 0.00048\n",
      "OA: 0.9784  | AA:  0.9597  | Kappa:  0.9754  | Time: 20.7\n",
      "[225,   901] loss: 0.0077465  | loss_wrt: 0.00523  | loss_unl: 0.00755  | learning_rate: 0.00043\n",
      "OA: 0.9775  | AA:  0.9543  | Kappa:  0.9743  | Time: 20.9\n",
      "[250,  1001] loss: 0.0064868  | loss_wrt: 0.00381  | loss_unl: 0.00691  | learning_rate: 0.00039\n",
      "OA: 0.9772  | AA:  0.9541  | Kappa:  0.9739  | Time: 20.3\n",
      "[275,  1101] loss: 0.0053222  | loss_wrt: 0.00331  | loss_unl: 0.00562  | learning_rate: 0.00035\n",
      "OA: 0.9774  | AA:  0.9457  | Kappa:  0.9742  | Time: 20.5\n",
      "[300,  1201] loss: 0.0045134  | loss_wrt: 0.00290  | loss_unl: 0.00560  | learning_rate: 0.00031\n",
      "OA: 0.9774  | AA:  0.9471  | Kappa:  0.9742  | Time: 20.7\n",
      "[325,  1301] loss: 0.0038666  | loss_wrt: 0.00255  | loss_unl: 0.00451  | learning_rate: 0.00028\n",
      "OA: 0.9776  | AA:  0.9624  | Kappa:  0.9744  | Time: 20.5\n",
      "[350,  1401] loss: 0.0032956  | loss_wrt: 0.00183  | loss_unl: 0.00350  | learning_rate: 0.00025\n",
      "OA: 0.9788  | AA:  0.9620  | Kappa:  0.9758  | Time: 20.7\n",
      "[375,  1501] loss: 0.0028939  | loss_wrt: 0.00174  | loss_unl: 0.00294  | learning_rate: 0.00023\n",
      "OA: 0.9781  | AA:  0.9561  | Kappa:  0.9750  | Time: 20.2\n",
      "[400,  1601] loss: 0.0024287  | loss_wrt: 0.00163  | loss_unl: 0.00363  | learning_rate: 0.00021\n",
      "OA: 0.9781  | AA:  0.9603  | Kappa:  0.9750  | Time: 20.6\n",
      "[425,  1701] loss: 0.0022354  | loss_wrt: 0.00144  | loss_unl: 0.00318  | learning_rate: 0.00019\n",
      "OA: 0.9781  | AA:  0.9629  | Kappa:  0.9750  | Time: 20.3\n",
      "[450,  1801] loss: 0.0020563  | loss_wrt: 0.00105  | loss_unl: 0.00247  | learning_rate: 0.00017\n",
      "OA: 0.9778  | AA:  0.9560  | Kappa:  0.9747  | Time: 20.4\n",
      "[475,  1901] loss: 0.0018634  | loss_wrt: 0.00091  | loss_unl: 0.00255  | learning_rate: 0.00015\n",
      "OA: 0.9785  | AA:  0.9607  | Kappa:  0.9755  | Time: 20.3\n",
      "[500,  2001] loss: 0.0017286  | loss_wrt: 0.00097  | loss_unl: 0.00245  | learning_rate: 0.00014\n",
      "OA: 0.9784  | AA:  0.9591  | Kappa:  0.9754  | Time: 20.4\n",
      "Finished Training\n",
      "[0.97435897 0.95963756 0.97730496 1.         0.97810219 0.9983871\n",
      " 0.66666667 1.         1.         0.92615012 0.99952084 0.94047619\n",
      " 1.         1.         0.97560976 0.94936709]\n",
      "0.9784156142365098 0.9590988408413496 0.9753583537307209\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.3576969  | loss_wrt: 0.15124  | loss_unl: 0.17172  | learning_rate: 0.00050\n",
      "OA: 0.7517  | AA:  0.5465  | Kappa:  0.7156  | Time: 87.2\n",
      "[100,   201] loss: 0.3160836  | loss_wrt: 0.09620  | loss_unl: 0.12927  | learning_rate: 0.00050\n",
      "OA: 0.8246  | AA:  0.6708  | Kappa:  0.7995  | Time: 85.9\n",
      "[150,   301] loss: 0.1266075  | loss_wrt: 0.05333  | loss_unl: 0.08794  | learning_rate: 0.00050\n",
      "OA: 0.8587  | AA:  0.7406  | Kappa:  0.8376  | Time: 83.7\n",
      "[200,   401] loss: 0.0729009  | loss_wrt: 0.04116  | loss_unl: 0.06092  | learning_rate: 0.00050\n",
      "OA: 0.8540  | AA:  0.7169  | Kappa:  0.8322  | Time: 86.6\n",
      "[250,   501] loss: 0.0868681  | loss_wrt: 0.04627  | loss_unl: 0.05914  | learning_rate: 0.00050\n",
      "OA: 0.8659  | AA:  0.7967  | Kappa:  0.8469  | Time: 80.9\n",
      "[300,   601] loss: 0.0585279  | loss_wrt: 0.02286  | loss_unl: 0.03828  | learning_rate: 0.00050\n",
      "OA: 0.8816  | AA:  0.7638  | Kappa:  0.8641  | Time: 83.8\n",
      "[350,   701] loss: 0.0559111  | loss_wrt: 0.04941  | loss_unl: 0.07220  | learning_rate: 0.00050\n",
      "OA: 0.8111  | AA:  0.7260  | Kappa:  0.7851  | Time: 83.3\n",
      "[400,   801] loss: 0.1008809  | loss_wrt: 0.03976  | loss_unl: 0.05369  | learning_rate: 0.00050\n",
      "OA: 0.7932  | AA:  0.6147  | Kappa:  0.7628  | Time: 87.8\n",
      "[450,   901] loss: 0.0699177  | loss_wrt: 0.01870  | loss_unl: 0.03322  | learning_rate: 0.00050\n",
      "OA: 0.8768  | AA:  0.7896  | Kappa:  0.8588  | Time: 80.8\n",
      "[500,  1001] loss: 0.0649142  | loss_wrt: 0.02339  | loss_unl: 0.04119  | learning_rate: 0.00050\n",
      "OA: 0.8959  | AA:  0.8149  | Kappa:  0.8806  | Time: 78.3\n",
      "[550,  1101] loss: 0.0457453  | loss_wrt: 0.03203  | loss_unl: 0.03918  | learning_rate: 0.00045\n",
      "OA: 0.8730  | AA:  0.8034  | Kappa:  0.8547  | Time: 84.3\n",
      "[600,  1201] loss: 0.0609666  | loss_wrt: 0.01836  | loss_unl: 0.02841  | learning_rate: 0.00045\n",
      "OA: 0.8923  | AA:  0.7834  | Kappa:  0.8766  | Time: 81.9\n",
      "[650,  1301] loss: 0.0240228  | loss_wrt: 0.01102  | loss_unl: 0.02306  | learning_rate: 0.00045\n",
      "OA: 0.8804  | AA:  0.7651  | Kappa:  0.8629  | Time: 86.5\n",
      "[700,  1401] loss: 0.0368775  | loss_wrt: 0.01738  | loss_unl: 0.02684  | learning_rate: 0.00045\n",
      "OA: 0.8723  | AA:  0.7605  | Kappa:  0.8536  | Time: 79.0\n",
      "[750,  1501] loss: 0.0226544  | loss_wrt: 0.00844  | loss_unl: 0.02095  | learning_rate: 0.00045\n",
      "OA: 0.8870  | AA:  0.7610  | Kappa:  0.8705  | Time: 85.6\n",
      "[800,  1601] loss: 0.0241083  | loss_wrt: 0.00731  | loss_unl: 0.01637  | learning_rate: 0.00045\n",
      "OA: 0.8801  | AA:  0.7537  | Kappa:  0.8626  | Time: 86.9\n",
      "[850,  1701] loss: 0.0381543  | loss_wrt: 0.01359  | loss_unl: 0.01960  | learning_rate: 0.00045\n",
      "OA: 0.8935  | AA:  0.7833  | Kappa:  0.8780  | Time: 78.5\n",
      "[900,  1801] loss: 0.0272560  | loss_wrt: 0.01227  | loss_unl: 0.01622  | learning_rate: 0.00045\n",
      "OA: 0.8931  | AA:  0.7747  | Kappa:  0.8775  | Time: 79.1\n",
      "[950,  1901] loss: 0.0150630  | loss_wrt: 0.01228  | loss_unl: 0.02567  | learning_rate: 0.00045\n",
      "OA: 0.8829  | AA:  0.7675  | Kappa:  0.8656  | Time: 88.7\n",
      "[1000,  2001] loss: 0.0132346  | loss_wrt: 0.00693  | loss_unl: 0.01447  | learning_rate: 0.00045\n",
      "OA: 0.8908  | AA:  0.7739  | Kappa:  0.8749  | Time: 79.7\n",
      "[1050,  2101] loss: 0.0138299  | loss_wrt: 0.00751  | loss_unl: 0.01019  | learning_rate: 0.00041\n",
      "OA: 0.8813  | AA:  0.7551  | Kappa:  0.8640  | Time: 80.3\n",
      "[1100,  2201] loss: 0.0408946  | loss_wrt: 0.01055  | loss_unl: 0.01935  | learning_rate: 0.00041\n",
      "OA: 0.8992  | AA:  0.7851  | Kappa:  0.8845  | Time: 83.9\n",
      "[1150,  2301] loss: 0.0123829  | loss_wrt: 0.00456  | loss_unl: 0.01125  | learning_rate: 0.00041\n",
      "OA: 0.8951  | AA:  0.7758  | Kappa:  0.8798  | Time: 83.7\n",
      "[1200,  2401] loss: 0.0138733  | loss_wrt: 0.00497  | loss_unl: 0.00971  | learning_rate: 0.00041\n",
      "OA: 0.8974  | AA:  0.7783  | Kappa:  0.8825  | Time: 83.6\n",
      "[1250,  2501] loss: 0.0647374  | loss_wrt: 0.00884  | loss_unl: 0.01596  | learning_rate: 0.00041\n",
      "OA: 0.8831  | AA:  0.7812  | Kappa:  0.8666  | Time: 84.8\n",
      "[1300,  2601] loss: 0.0373803  | loss_wrt: 0.00577  | loss_unl: 0.01068  | learning_rate: 0.00041\n",
      "OA: 0.8976  | AA:  0.7807  | Kappa:  0.8827  | Time: 76.1\n",
      "[1350,  2701] loss: 0.0093136  | loss_wrt: 0.01448  | loss_unl: 0.00984  | learning_rate: 0.00041\n",
      "OA: 0.8992  | AA:  0.7819  | Kappa:  0.8846  | Time: 78.9\n",
      "[1400,  2801] loss: 0.0127569  | loss_wrt: 0.00345  | loss_unl: 0.00812  | learning_rate: 0.00041\n",
      "OA: 0.8964  | AA:  0.7770  | Kappa:  0.8814  | Time: 83.6\n",
      "[1450,  2901] loss: 0.0430339  | loss_wrt: 0.00874  | loss_unl: 0.01344  | learning_rate: 0.00041\n",
      "OA: 0.8730  | AA:  0.7611  | Kappa:  0.8546  | Time: 82.6\n",
      "[1500,  3001] loss: 0.0091556  | loss_wrt: 0.00350  | loss_unl: 0.00733  | learning_rate: 0.00041\n",
      "OA: 0.8974  | AA:  0.7731  | Kappa:  0.8824  | Time: 83.5\n",
      "[1550,  3101] loss: 0.0064445  | loss_wrt: 0.00250  | loss_unl: 0.00636  | learning_rate: 0.00036\n",
      "OA: 0.8933  | AA:  0.7698  | Kappa:  0.8778  | Time: 80.3\n",
      "[1600,  3201] loss: 0.0101091  | loss_wrt: 0.00428  | loss_unl: 0.00720  | learning_rate: 0.00036\n",
      "OA: 0.8956  | AA:  0.7785  | Kappa:  0.8804  | Time: 76.8\n",
      "[1650,  3301] loss: 0.0125693  | loss_wrt: 0.00276  | loss_unl: 0.00797  | learning_rate: 0.00036\n",
      "OA: 0.8978  | AA:  0.7786  | Kappa:  0.8830  | Time: 81.7\n",
      "[1700,  3401] loss: 0.0050949  | loss_wrt: 0.00171  | loss_unl: 0.00557  | learning_rate: 0.00036\n",
      "OA: 0.8955  | AA:  0.7809  | Kappa:  0.8804  | Time: 83.8\n",
      "[1750,  3501] loss: 0.0207311  | loss_wrt: 0.00562  | loss_unl: 0.00959  | learning_rate: 0.00036\n",
      "OA: 0.8978  | AA:  0.7722  | Kappa:  0.8829  | Time: 78.3\n",
      "[1800,  3601] loss: 0.0080349  | loss_wrt: 0.00262  | loss_unl: 0.00656  | learning_rate: 0.00036\n",
      "OA: 0.8938  | AA:  0.7781  | Kappa:  0.8784  | Time: 83.2\n",
      "[1850,  3701] loss: 0.0070725  | loss_wrt: 0.00299  | loss_unl: 0.00572  | learning_rate: 0.00036\n",
      "OA: 0.8967  | AA:  0.7766  | Kappa:  0.8817  | Time: 82.5\n",
      "[1900,  3801] loss: 0.0040834  | loss_wrt: 0.00147  | loss_unl: 0.00445  | learning_rate: 0.00036\n",
      "OA: 0.8966  | AA:  0.7796  | Kappa:  0.8815  | Time: 86.2\n",
      "[1950,  3901] loss: 0.0091929  | loss_wrt: 0.00493  | loss_unl: 0.01358  | learning_rate: 0.00036\n",
      "OA: 0.9018  | AA:  0.7947  | Kappa:  0.8877  | Time: 82.5\n",
      "[2000,  4001] loss: 0.0045697  | loss_wrt: 0.00155  | loss_unl: 0.00451  | learning_rate: 0.00036\n",
      "OA: 0.8999  | AA:  0.7836  | Kappa:  0.8854  | Time: 87.1\n",
      "Finished Training\n",
      "model saved\n",
      "[0.76923077 0.87808896 0.93049645 0.59701493 0.67153285 0.92580645\n",
      " 0.66666667 0.9729064  0.35294118 0.80750605 0.98706277 0.91071429\n",
      " 0.83908046 0.94697674 0.99085366 0.34177215]\n",
      "0.9002296211251435 0.7867906736824928 0.8857971995185159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([103, 200, 31, 31]) torch.Size([103, 200, 31, 31])\n",
      "=> all bands acc: 0.610\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: 1.23 | loss:0.669 | 11 bands | 8.0s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: 2.29 | loss:0.590 | 77 bands | 4.2s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: 2.99 | loss:0.599 | 105 bands | 3.8s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: 3.33 | loss:0.605 | 112 bands | 3.7s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -2.32 | loss:0.638 | 68 bands | 3.2s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: 0.48 | loss:0.604 | 106 bands | 3.6s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: 2.29 | loss:0.627 | 35 bands | 3.7s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: 2.92 | loss:0.604 | 71 bands | 3.8s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: 3.69 | loss:0.575 | 77 bands | 3.6s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: 1.85 | loss:0.598 | 90 bands | 3.4s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: 0.83 | loss:0.596 | 105 bands | 3.3s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: 0.69 | loss:0.600 | 27 bands | 3.1s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: 2.63 | loss:0.579 | 59 bands | 3.3s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: 3.68 | loss:0.651 | 4 bands | 3.1s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: 4.22 | loss:0.571 | 22 bands | 3.2s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: 4.75 | loss:0.586 | 40 bands | 3.0s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: 2.46 | loss:3.246 | 0 bands | 2.8s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: 4.06 | loss:0.578 | 35 bands | 2.9s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: 5.31 | loss:0.530 | 19 bands | 2.9s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: 4.45 | loss:0.570 | 34 bands | 2.8s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: 5.75 | loss:0.593 | 33 bands | 2.5s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: 6.77 | loss:0.537 | 47 bands | 2.7s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: 7.37 | loss:0.559 | 26 bands | 2.6s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: 7.75 | loss:0.543 | 47 bands | 2.6s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: 8.59 | loss:0.571 | 16 bands | 2.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: 6.45 | loss:3.246 | 0 bands | 2.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: 7.70 | loss:0.556 | 27 bands | 2.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: 6.58 | loss:0.532 | 37 bands | 2.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: 6.50 | loss:0.515 | 36 bands | 2.7s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: 8.31 | loss:0.508 | 29 bands | 2.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: 9.90 | loss:0.498 | 27 bands | 2.4s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: 11.18 | loss:0.455 | 12 bands | 2.4s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: 12.19 | loss:0.437 | 26 bands | 2.4s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: 13.14 | loss:0.451 | 17 bands | 2.3s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: 14.23 | loss:0.458 | 18 bands | 2.1s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: 14.52 | loss:0.439 | 26 bands | 2.3s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: 15.12 | loss:0.452 | 14 bands | 2.4s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: 13.38 | loss:0.455 | 20 bands | 2.4s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: 14.13 | loss:0.628 | 14 bands | 2.3s\n",
      "r_max, 0.42483108764281496\n",
      "Done\n",
      "time :120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-21 02:49:17.962830: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-21 02:49:17.965780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-21 02:49:17.965963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-21 02:49:18.458011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-21 02:49:18.458125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-21 02:49:18.458185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-21 02:49:18.458402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2083771  | loss_wrt: 0.13022  | loss_unl: 0.14873  | learning_rate: 0.00100\n",
      "OA: 0.9140  | AA:  0.7839  | Kappa:  0.9020  | Time: 22.7\n",
      "[50,   201] loss: 0.1155924  | loss_wrt: 0.04910  | loss_unl: 0.06792  | learning_rate: 0.00090\n",
      "OA: 0.9439  | AA:  0.9020  | Kappa:  0.9360  | Time: 20.9\n",
      "[75,   301] loss: 0.0505406  | loss_wrt: 0.02649  | loss_unl: 0.04014  | learning_rate: 0.00081\n",
      "OA: 0.9475  | AA:  0.9134  | Kappa:  0.9402  | Time: 20.9\n",
      "[100,   401] loss: 0.0295094  | loss_wrt: 0.01387  | loss_unl: 0.02630  | learning_rate: 0.00073\n",
      "OA: 0.9498  | AA:  0.9335  | Kappa:  0.9428  | Time: 20.9\n",
      "[125,   501] loss: 0.0193468  | loss_wrt: 0.01173  | loss_unl: 0.01928  | learning_rate: 0.00066\n",
      "OA: 0.9540  | AA:  0.9360  | Kappa:  0.9475  | Time: 22.1\n",
      "[150,   601] loss: 0.0470278  | loss_wrt: 0.02775  | loss_unl: 0.03477  | learning_rate: 0.00059\n",
      "OA: 0.9503  | AA:  0.9310  | Kappa:  0.9433  | Time: 21.3\n",
      "[175,   701] loss: 0.0219536  | loss_wrt: 0.01028  | loss_unl: 0.01646  | learning_rate: 0.00053\n",
      "OA: 0.9565  | AA:  0.9355  | Kappa:  0.9504  | Time: 20.8\n",
      "[200,   801] loss: 0.0135226  | loss_wrt: 0.00688  | loss_unl: 0.01499  | learning_rate: 0.00048\n",
      "OA: 0.9571  | AA:  0.9417  | Kappa:  0.9511  | Time: 21.2\n",
      "[225,   901] loss: 0.0101449  | loss_wrt: 0.00542  | loss_unl: 0.01226  | learning_rate: 0.00043\n",
      "OA: 0.9588  | AA:  0.9421  | Kappa:  0.9530  | Time: 20.9\n",
      "[250,  1001] loss: 0.0082381  | loss_wrt: 0.00376  | loss_unl: 0.01295  | learning_rate: 0.00039\n",
      "OA: 0.9600  | AA:  0.9454  | Kappa:  0.9545  | Time: 20.9\n",
      "[275,  1101] loss: 0.0069367  | loss_wrt: 0.00292  | loss_unl: 0.00870  | learning_rate: 0.00035\n",
      "OA: 0.9600  | AA:  0.9488  | Kappa:  0.9545  | Time: 20.8\n",
      "[300,  1201] loss: 0.0060220  | loss_wrt: 0.00292  | loss_unl: 0.00685  | learning_rate: 0.00031\n",
      "OA: 0.9608  | AA:  0.9507  | Kappa:  0.9554  | Time: 20.7\n",
      "[325,  1301] loss: 0.0052745  | loss_wrt: 0.00267  | loss_unl: 0.00666  | learning_rate: 0.00028\n",
      "OA: 0.9628  | AA:  0.9582  | Kappa:  0.9576  | Time: 20.7\n",
      "[350,  1401] loss: 0.0045298  | loss_wrt: 0.00261  | loss_unl: 0.00472  | learning_rate: 0.00025\n",
      "OA: 0.9630  | AA:  0.9694  | Kappa:  0.9579  | Time: 20.9\n",
      "[375,  1501] loss: 0.0038743  | loss_wrt: 0.00166  | loss_unl: 0.00428  | learning_rate: 0.00023\n",
      "OA: 0.9623  | AA:  0.9655  | Kappa:  0.9571  | Time: 20.5\n",
      "[400,  1601] loss: 0.0034158  | loss_wrt: 0.00157  | loss_unl: 0.00391  | learning_rate: 0.00021\n",
      "OA: 0.9635  | AA:  0.9708  | Kappa:  0.9584  | Time: 20.9\n",
      "[425,  1701] loss: 0.0030386  | loss_wrt: 0.00156  | loss_unl: 0.00376  | learning_rate: 0.00019\n",
      "OA: 0.9631  | AA:  0.9683  | Kappa:  0.9580  | Time: 20.7\n",
      "[450,  1801] loss: 0.0026621  | loss_wrt: 0.00150  | loss_unl: 0.00374  | learning_rate: 0.00017\n",
      "OA: 0.9633  | AA:  0.9706  | Kappa:  0.9581  | Time: 20.8\n",
      "[475,  1901] loss: 0.0024193  | loss_wrt: 0.00128  | loss_unl: 0.00279  | learning_rate: 0.00015\n",
      "OA: 0.9634  | AA:  0.9691  | Kappa:  0.9583  | Time: 21.0\n",
      "[500,  2001] loss: 0.0022226  | loss_wrt: 0.00160  | loss_unl: 0.00289  | learning_rate: 0.00014\n",
      "OA: 0.9631  | AA:  0.9699  | Kappa:  0.9580  | Time: 20.7\n",
      "Finished Training\n",
      "[0.97435897 0.94398682 0.9106383  1.         0.96593674 0.99677419\n",
      " 1.         1.         1.         0.87530266 0.99233349 0.96428571\n",
      " 1.         0.97302326 0.99695122 0.92405063]\n",
      "0.9631458094144661 0.9698526253050715 0.9580178060684542\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "from evaluate_ss import RET\n",
    "results =[]\n",
    "for i in range(5):\n",
    "#     !python get_prefile_ss.py --data_name \"Indian_pines\" --pt 0.05 --pv 0.1\n",
    "#     !python train_evalnet_ss_v2.py --data_name \"Indian_pines\" \n",
    "    !python A3C_main.py --data_name \"Indian_pines\" --eval_net_path \"./checkpoint/Indian_pines.t7\" -- out_put_path \"./output/Indian_pines\"\n",
    "#     model = RET(data_name)\n",
    "#     results.append(model.results)\n",
    "# import numpy as np\n",
    "# results = np.array(results)\n",
    "# avarage = results.mean(axis=0)*100\n",
    "# std = results.std(axis=0)*100\n",
    "# avg = [\"%.1f±%.1f\"%(avarage[i],std[i])for i in range(avarage.shape[0])]\n",
    "# import xlwt\n",
    "# import time\n",
    "# #创建一个Workbook对象，相当于创建了一个Excel文件\n",
    "# book=xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "# sheet = book.add_sheet(data_name, cell_overwrite_ok=True)\n",
    "# clo_0 = [\"OA\",\"AA\",\"Kappa\"]+list(range(16))\n",
    "# row_o = [data_name]+list(range(5))+[\"avg\"]\n",
    "# for i in range(len(row_o)):\n",
    "#     sheet.write(0, i,row_o[i])\n",
    "# for j in range(len(clo_0)):\n",
    "#     sheet.write(j+1, 0,clo_0[j])\n",
    "# for i in range(len(results)):\n",
    "#     for j in range(len(results[0])):\n",
    "#         sheet.write(j+1, i+1,results[i][j])\n",
    "# for j in range(len(results[0])):\n",
    "#     sheet.write(j+1,6,avg[j])\n",
    "# book.save(data_name+\"_BSRL_\"+avg[0]+'.xls')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
